{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "692e25c2-5048-4816-b5a8-8c0dc496a8e0",
   "metadata": {},
   "source": [
    "## Initial Import of my Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5a4f47a-f862-4cc5-b4b9-31fa299083b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import OS lib\n",
    "import os\n",
    "\n",
    "# Prepare for OCR to get information from the initial images\n",
    "import easyocr\n",
    "\n",
    "# Prepare for crawling\n",
    "from googlesearch import search\n",
    "\n",
    "# Prepare language data\n",
    "import csv\n",
    "\n",
    "# Webscraping\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6a265e0-ae33-4690-9885-e1860dea5cad",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "languages = {}\n",
    "async_tools = {}\n",
    "ai_tools = {}\n",
    "cloud_tools = {}\n",
    "development_environment = {}\n",
    "frameworks = {}\n",
    "web_frameworks = {}\n",
    "sync_tools = {}\n",
    "tools = {}\n",
    "\n",
    "with open(\"languages.csv\", \"r\") as file:\n",
    "    language_dict = csv.DictReader(file)\n",
    "\n",
    "    for row in language_dict:\n",
    "        if row[\"type\"] == \"pl\":\n",
    "            key_id = row[\"pldb_id\"]\n",
    "            languages[key_id] = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99157b1d-7654-4b34-a335-f7e25ecaad85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['popular-languages.png', 'popular-web-framework.png', 'popular-sync-tools.png', 'popular-development-environment.png', 'popular-async-tools.png', 'popular-ai-tools.png', 'popular-frameworks.png', 'popular-cloud-tools.png', 'popular-tools.png']\n"
     ]
    }
   ],
   "source": [
    "files = [f for f in os.listdir('./images/') \n",
    "         if os.path.isfile(os.path.join('./images/', f))]\n",
    "\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "482e6f6d-f4dd-46ab-8e7f-74b0d0f3b99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_list_of_languages = []\n",
    "\n",
    "def process_languages(text: str):\n",
    "    if '%' in text or len(text.split()) > 1:\n",
    "        return\n",
    "\n",
    "    match text:\n",
    "        case 'JS' : temp_list_of_languages.append('JavaScript')\n",
    "        case 'C+-': temp_list_of_languages.append('Cpp')\n",
    "        case 'PY' : temp_list_of_languages.append('Python')\n",
    "        case 'TS' : temp_list_of_languages.append('TypeScript')\n",
    "        case 'C#' : temp_list_of_languages.append('CSharp')\n",
    "        case '2024' : return\n",
    "        case _ : temp_list_of_languages.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6c3336c-68d3-4a47-8bff-6351e3ecc6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_web_frameworks(text:str):\n",
    "        if '%' in text:\n",
    "            return\n",
    "\n",
    "        print(text)\n",
    "        match text:\n",
    "            case 'Source: surveystackoverflow.co/2024' : return\n",
    "            case 'Developer': return\n",
    "            case 'Survey' : return\n",
    "            case 'Data licensed under Open Database License (ODbL)' : return\n",
    "            case '2024' : return\n",
    "            case _ : temp_list_of_languages.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c214ea3d-c5c4-4ff8-98f0-0c63e713ac86",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = easyocr.Reader([\"en\"])\n",
    "\n",
    "files = [f for f in os.listdir('./images/') \n",
    "         if os.path.isfile(os.path.join('./images/', f))]\n",
    "\n",
    "for file in files:\n",
    "    result = reader.readtext(\"./images/\" + file)\n",
    "    \n",
    "    # Fix data given from the image - only extract the programming languages\n",
    "    for (bbox, text, prob) in result:\n",
    "        match file:\n",
    "            case \"popular-languages.png\": process_languages(text)\n",
    "            case \"popular-web-framework.png\": process_web_frameworks(text)\n",
    "            case \"popular-sync-tools.png\": process_web_frameworks(text)\n",
    "            case \"popular-development-environment.png\": process_web_frameworks(text)\n",
    "            case \"popular-async-tools.png\": process_web_frameworks(text)\n",
    "            case \"popular-ai-tools.png\": process_web_frameworks(text)\n",
    "            case \"popular-frameworks.png\": process_web_frameworks(text)\n",
    "            case \"popular-cloud-tools.png\": process_web_frameworks(text)\n",
    "            case \"popular-tools.png\": process_web_frameworks(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "921278b2-cf19-429b-ac8d-685e1606e8f6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['JavaScript', 'Python', 'TypeScript', 'Java', 'CSharp', 'Cpp', 'PHP', 'PowerShell', 'Rust', 'Kotlin']\n"
     ]
    }
   ],
   "source": [
    "# Get the top 10 languages - this excludes things like SQL\n",
    "languages_for_analysis = [lang for lang in temp_list_of_languages if lang.lower() in languages][:10]\n",
    "\n",
    "print(languages_for_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fdca7049-bec0-44f8-8942-c426b4315ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_reddit_data(url: str):\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(url)\n",
    "\n",
    "    # Wait for comments to load\n",
    "    try:\n",
    "        comments = WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.CSS_SELECTOR, 'div[id=\"-post-rtjson-content\"]')))\n",
    "    \n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "        paragraphs = soup.select('div[id=\"-post-rtjson-content\"] p')\n",
    "    \n",
    "        texts = [p.get_text(strip=True) for p in paragraphs]\n",
    "\n",
    "        driver.close()\n",
    "    \n",
    "        return texts\n",
    "    except:\n",
    "        driver.close()\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5a3b129f-ab27-4bc9-b3d2-fb98ed7214bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_hackernews_data(url: str):\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(url)\n",
    "\n",
    "    # Wait for comments to load\n",
    "    try:\n",
    "        \n",
    "        comments = WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.CSS_SELECTOR, 'div.comment div.commtext.c00')))\n",
    "        \n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "        paragraphs = soup.select('div.comment div.commtext.c00')     \n",
    "        \n",
    "        texts = [p.get_text(strip=True) for p in paragraphs]\n",
    "\n",
    "        driver.close()\n",
    "    \n",
    "        return texts\n",
    "    except:\n",
    "        driver.close()\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c5b398fc-032f-4766-a480-ead9d27e2c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "977\n"
     ]
    }
   ],
   "source": [
    "# Perform the search\n",
    "# Reddit\n",
    "# Hacknews i.e. Hackernews\n",
    "\n",
    "opinion_dict = {}\n",
    "\n",
    "# Get a wide range of opinions from developers\n",
    "for lang in languages_for_analysis:\n",
    "    # # Looking for developer sentiment on the given technology\n",
    "    query =  \"Opinion on \" + lang + \" :site reddit\"\n",
    "    search_results = search(query, num_results=5)\n",
    "\n",
    "    for result in search_results:\n",
    "        data = scrape_reddit_data(result)\n",
    "\n",
    "        # Skip the data that can't be extracted\n",
    "        if data is None:\n",
    "            continue\n",
    "\n",
    "        if lang not in opinion_dict:\n",
    "            opinion_dict[lang] = data\n",
    "        else:\n",
    "            opinion_dict[lang] += data\n",
    "\n",
    "    query =  \"Opinion on \" + lang + \" :site hacknews\"\n",
    "    search_results = search(query, num_results=5)\n",
    "\n",
    "    for result in search_results:\n",
    "        data = scrape_hackernews_data(result)\n",
    "        # Skip the data that can't be extracted\n",
    "        if data is None:\n",
    "            continue\n",
    "\n",
    "        if lang not in opinion_dict:\n",
    "            opinion_dict[lang] = data\n",
    "        else:\n",
    "            opinion_dict[lang] += data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb17169c-864e-41d5-8736-dab38fe4218c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
