I don't hate Python. I hate the attitude that many Python programmers have about it and other languages.
Too many people think Python can replace everything, they think python is the future of programming or some sh**.
Don't get me wrong, it's a fantastic language at leveraging multiple technologies and binding them together into something bigger. It's also a decent introduction into programming and also a great tool to aid data scientists, as well as good to prototype certain things, but that's where the buck stops.
If I want to build software that leverages the hardware as efficiently as possible (Which is my whole discipline), Python is the very last thing I'd ever use to do it, unless I want to turn my PC into an expensive heater.
I don't hate python; it is a fine scripting/prototyping language. Things I dislike it as a general-purpose programming language are:
Slow runtimes
All integers are of arbitrarily large size (this is occasionally useful, but otherwise it just consumes additional memory and execution time)
No fixed decimal type (it seems like if the language is going to support arbitrarily large integers, it ought to also support fixed decimal fractions to a specified number of fractional digits - this would actually be useful, e.g. for money calculations)
Everything is a reference - if I need a large array of booleans, each element of the array will consume 8 bytes of memory (assuming a 64 bit architecture) as opposed to 1 byte in java or C
I prefer strongly typed languages
The language is supposed to be simple, but it's not. There's 50 ways to do the same thing, and they keep introducing new syntax. I also dislike syntax for multi line and formatted strings. It's also slow, even compared to other slow languages (e.g. node js).
Hating a language is a baby thing.
My main dislike about python is no line endings. Just annoying having to tab/space perfectly, Other than that it's not much different than most languages, simple enough tho.
Lack of enforced type check makes it totally useless in big projects. It is good as integration tool or as sh replacement.
It is much easier to start with, but its GUI, Tkinter, is not maintained well, and it does not look modern, and lack certain features. You can use 3rd party GUI, but you need to add it to the dependencies list, but when you want to create your final application, you will go to the dependencies' hell.
I have written multiple backends with python and it’s a great language. It’s simple for new programmers to pick up.
There are shortcomings but they can be somewhat solved with the right set of tools, automated testing and correct guidelines for coding.
I have been programming for a long time and in my opinion python is well suited for production usage for a lot of use cases.
Obviously there are a lot of haters for anything. Especially if something is popular number of haters is proportionally larger. There isn’t a single language that is perfect for everyone and every use case.
Do I wish there was some type safety option in python? Yes. Is it enough of a concern for me to not use python? No.
I like statically-typed languages where indentation doesn't matter. I don't hate any language, Python is just not something that interests me professionally. I've worked with it and I tend to choose other languages if possible. It's just not my thing.
It’s a great learning language. It seems to be strong in the ML community.
Personally, it’s my go to for throwaway scripts like large scale data transformations and modeling.
I’m leery of using it to build apps with large codebases. Not having static typing bothers the crap out of me.
There are two types of languages. Those which are hated, and those which aren't used.
"There are only two kinds of languages: the ones people complain about and the ones nobody uses" -Bjarne Stroustrup
Corollary: the more widely used a language, the larger its army of haters.
Flak for what? Python is one of the most recommended languages around here, mainly because you can do a lot with very little code, and it's platform-independent, so anyone with any hardware/OS can pick it up.
I’m sure there are legit criticisms of Python, but most of the stuff you see on the internet is just gate-keeping.
There is no such thing as a universally-loved language. Considering that Python is one of the most recommended languages for beginners, and that it's used to power a lot of things (Reddit's back-end is at least partially Python), I think you can safely ignore the haters.
Everyone hates Python because it is weak sauce pseudo code. Real programmers program in Assembly and the REAL old ones program in machine code. Are you really a man if you haven’t turned on your punch cards to Rita at the software library?
People get upset over lots of things.  Back in the 1990s, people who used a PC hated Mac users and vice versa.  It was stupid.  There was even a recent Reddit post where some girl told some guy that Android wasn't a real phone.  She didn't want anything to do with him because she used a real phone (IPhone).  Clearly, a little braindead and superficial.
Python is real coding, people get jobs using Python.  As they say, haters gonna to hate.  They hate because they went through some hard way to learn programming and need to pat themselves on the back that they went through that route.
Ignore them.
Back in the 1990s, people who used a PC hated Mac users and vice versa.
I feel like this still happens now.
My opinion only, Python is hated predominantly by those with a heavy CS background, who have worked on highly engineered systems with strongly typed languages which produces less exceptions. For medium to small projects, they don't mind, but anything where the cost is in the millions, they prefer Java, C#, or C++. While these languages are more difficult to manipulate, the strongly typed nature makes for cleaner code, less mistakes, less debugging. Remember, that Python is not a compiled language, same with JS, so errors, exceptions, and type checking is a big deal.
Research Programming Paradigmns.
Not particularly. Python has some nice parts, like using English words for some features. It's definitely easier to do stuff once you know about the options, but learning it isn't much different than any other language.
The trick to programming is that once you know one language, it's exponentially easier to learn another. Just figure out the syntax for loop, input, accessing files, and defining functions, and you're pretty much set.
but learning it isn't much different than any other language.
Well it does allow you not to have to know and manage certain technical aspects other languages require. Be that memory management, stack VS heap, variable lifetimes, or forcing a specific paradigm (like Java and OOP or Haskell and FP). So it helps to lower the barrier of entry by overloading a new student with less concepts.
Python is relatively easy. But programming is hard, it requires a lot of time and effort to learn.
You can learn a good chunk of Python in a weekend, if you already know programming. But if you don't, it will take longer, because you have to learn Python and learn programming at the same time.
This is valuable, drawing a distinction between the programming language and the art of programming itself. You are right that these are not the same thing, and you can’t have one without the other, so they must be learned in parallel.
pfff I learned that language over a weekend
Tell me you don't know python without saying you don't know python.
When people who don't know Python very well say it's "simple", what they're really talking about is frankly stuff that doesn't matter. It uses whitespace instead of braces. It doesn't use semicolons. You don't need to declare the types of variables.
What actually makes pythonpowerfuland popular is that it's got so many features built-in, and those features that aren't built in are all available via pip. Chances are that if you need to do something there's already a module that makes it easy.
Need to do stuff with HTTP? Userequests. Need to do data manipulation? Usepandas. Need to do math on big data? Usenumpy. You get the pattern: you rarely need to roll your own entirely custom solution. In this way, the language is "simple" and expressive.
When people who are advanced at Python say the language is "simple" they're probably talking about the mechanics of how the language itself runs. "Everything is an object" is a nice abstraction that makes some things simpler. The way namespaces and local/global variables work is fairly straightforward when compared to some other languages. The type system in general uses only a few basic rules. All these "simple" components combine in a very elegant way.
Of all these interpretations of "simple,"noneof them mean the language is easy to learn (especially as a first language). Those syntactic "simplifications" might make it easier to learn than, say C, where there is a lot more minutiae to keep track of. Those library/packaging simplifications make it easier to get up-and-running with some quickly prototyped solution. And the object model simplifications can make it easier to extend python and build expressive libraries.
Just because the fundamental rules are (relatively) simple doesn't mean it's easy, or that you can't build complexity using it. "Easy to learn, lifetime to master" and all that. When people say "oh I learned Python in a week" it gives me the same impression as people who say "oh chess is too simple, I stopped playing as a child" or "oh, electronic music is not interesting because you just make the computer do it". I instantly lose some respect for that person as they demonstrate they don't/can't recognize the emergent complexity of the thing, or the effort that people put in to master the thing.
What actually makes pythonpowerfuland popular is that it's got so many features built-in
I strongly disagree. What gives Python its appeal is the fact that its developers are so focused on making the language asintuitiveas they possibly can without making it complicated, and just as importantly is the fact that much of its community is also heavily focused on that goal. Plenty of languages have large ecosystems providing every tool you can imagine, but they still fail to achieve what Python has: being a great language for both experienced and new developers. It is that attraction combined with that focus that has led to the creation of so many incredibly useful libraries.
requestsis a fantastic example of that mindset in action. Its entire purpose is to give you a an interface for HTTP requests that matcheshow you actually think about themwithout all the minutiae involved in network connections and the HTTP standard, and it succeeds masterfully at doing that. The result is an API that is incredibly simple for simple and common requests, but it still makes sure to provide you with all the tools you need for more complex cases. This means that people with simple problems can grab it and get their task done quickly and easily, but as they become more experienced and encounter more difficult problems, they can expand on what they already know as soon as they need to. Python as a language is exactly like that: easy to figure out for simple problems, but not lacking in power and not forcing overly complex approaches for more difficult cases.
I'm a 55 year old dumbass and I picked it up, now mind you i'm not looking to change careers I was just goofing off. I've always done IT support so some of it makes since, I lack imagination in solving some of the problems, I am more comfortable creating files from databases and text files. I really enjoyed the CS50 course from Harvard which I'm still working on.
Python is easy. Programming is hard.
The language is irrelevant, tbh. There are things Python does that makes writing code faster, but you’d till have to solve problems using logic and data structures etc
IMO many are missing the point in programming. Every language has it strength and weakness. Only a few can be compared 1 on 1. I see Python as the best language to get things done quick for example prototyping or proof of concepts, data science and countless of other ways. However when you have something good in Python you can speed it up by building it in C++ or Java for example and let Python use it which in the end is much much faster. That way you can have the best of of many worlds and then continue to use Python as an interactive programming language or build a module and help others build even faster code.
I love both Python and C++. Programming in Python is very enjoying, especially when you learn some neat tricks and shorten a code in a clever way. I learn something new in Python everyday and I have to admit I really like it.
"Python is the second-best language for any project"
-[--->+<]>-------.-[--->+<]>.[->+++++<]>+++.
-[--->+<]>-------.-[--->+<]>.[->+++++<]>+++.
That is beautiful.
I don't quite understand, could someone please explain this?
Ah yes BrainFuck,
I've written so many interpreters for BrainFuck in pretty much every language. I actually decided to modify it and create my own version with extras like if/else and things like that to make it more useful.
As a programmer, you should focus less about programming languages perse - instead, make a lot of efforts to truly master the fundamentals and you will notice that many programming languages share the same concepts but with just different syntax styles. - If you follow this strategy you will notice at some point, it will not longer take you long to learn any new programming language in situations where you need to, because a specific language happens to be the best tool for the specific job you are trying to do. -
For instance, it only took me 3 days to learn JavaScript and start using it - another example will be when I needed PHP, it literally took me 4hrs to learn the basics and the next day I was already able to code in PHP and finish the task that I specifically needed it for!
This might sound extraordinary if you're new to programming - but the reality is that this is very common among Sr software engineers - this is why it's very important to master the fundamentals because it will make your life easy afterwards!
Programming languages are just tools - so, you should always let the project that you're working on dictate the language you should use and not the other way around - There's not a programming language that's better than the others - it's all circumstantial.
Could you elaborate what you think are those fundamentals? I am relatively new to programming and I heard this sentence often, but always struggle to understand it! Do you mean things like flow control? OOP? Or are we talking about something completely different.
I enjoy Python very much. Some people hate code block separation by indentation as part of the syntax but honestly I don't know what is so terrible about it.
I work with data pipelines a lot and the ecosystem is quite developed on this regard with lots of nice data oriented libraries.
My only grip with it is that it has such a long history, so many changes between versions and stuff...so it sometimes can feel a bit disordered and confusing. Also, the fact that a class can be named just like its module so it generates nonsense syntax like this:
from datetime import datetime
PD: I am beginning Rust now and I am liking it a lot so far. Check it out too if you can.
If you are about to ask a question about how to do something in python, please check outr/LearnPython.
It is a very helpful community that is focused on helping people get answers that they understand.
Please use other subreddits for things that are more generally programmer related, or for things that involve large snakes.
When posting a project please include an image showing your project if applicable, a textual description of your project including how Python is relevant to it and a link to source code.
We do not want an arbitrary link that we then have to go read to understand.
When posting a project you must use a showcase flair & use a text post, not an image post, video post or similar.
Using new Reddit you may embed these media types within the post body, including multiple images in one post.
Please write a bit about your project instead of just dumping links since it will increase the relevance of your project to the Python subreddit.
Titles for all submissions should describe the topic of the post and offer redditors an idea of what the link or text covers. Vague titles which require clicking through to clarify the subject matter of the post will be removed.
This also goes for just posting abstract links with no description about what it is you are sharing.
All shared resources in posts and comments must be freely accessible without payment or subscription. This includes, but is not limited to, articles, courses, tutorials, and code repositories. Redirect paywalled content to anywhere but here.
Banned links can include Medium.com and similar content and paywalled content.
Low quality blogs and similar (similar to what is hosted on many Medium.com articles) is not allowed.
To ensure effective communication and ease of moderation within the community, all posts and comments must be in English. All non-English content should translated before posting.
This is mostly due to the capabilities and time constraints of the moderation staff and the predominance of English-speaking users in our community.
Obviously we can't enforce this one very easily, it more is a level of trust we have in our users. Please do not downvote comments without providing valid reasoning for doing so. This rule helps maintain a positive atmosphere on the subreddit with both posts and comments.
Showcase posts must have these sections in order to give a good idea for target audience, intended use, goals, etc.
What My Project Does
Target Audience(e.g., Is it meant for production, just a toy project, etc.
Comparison(A brief comparison explaining how it differs from existing alternatives.)
Due to an increase of showcases featuring AI content such as working with multiple AI models or wrappers around APIs, this is no longer allowed. Please post your showcases in the appropriate daily thread instead.
I wish people could be honest and say they don't care for some language or framework or OS for personal or aesthetic reasons, rather than having to round it up to being objectively bad, but then I suppose nobody probably would click on "I don't like Python and have got some nits to pick".Oh and he just says what is supposed to be quiet part at the end:>And, not to put too fine a point on it, but if you can code Python but not Go (or another decent programming language), you probably have no business writing software for a living. I know it sounds harsh and I apologize for that, but writing software is a profession and hence you should have the knowledge, skill, and experience to use professional tools.Hear that all data scientists, flask devs, systems engineers, and ML folks? Python is bad so you should quit. ;)
I see this sort of person as an extremely rigid, unbending, dime a dozen type person even if they’re very intelligent. I’m in this business to succeed and build and create things, there is very much an “energetic” aspect and his energy is dead as fuck. It’s a very simple fact that some see it, and some don’t. He’s one who doesn’t, and all those that see it can see it so clearly. He’s most definitely not someone I would want on my team.The amount of idiotic … implications of his statement is so excruciating it’s physically painful to me. But I encounter this unadaptive unawareness all the time with working with programmers from other teams, etc so I’m used to it.
He published an article in June titled "It is not cool to be unkind!".Interesting contradiction.I know someone like that, very energetic, full of ideas, but so stubborn I'm sure it holds him back.
Aha, you pointed outthe disease.This is the biggest problem in software and it's kind of intractable.The ideal world has tools that empower everyone to do what they need to do, which to some extent must include an activity like programming.But, and this may be unconscious, "people who program for a living" have a strong incentive to gatekeep.
What's amazing is people who program for a living, who people would normally think of as being "experts", have so little knowledge of all the different types of programming that is done by, well, people who program for a living, and the tools they use to do that programming.Not only then is it gatekeeping, it's also a sign of an inexperienced programmer.I'll give one thing to Python programmers, they tend to work directly with their end users and build solutions that matter to them. Anyone that's done that kind of work knows it's difficult, regardless of programming language being used.
And arguably, is the more "important" work, or at least the stuff requiring the most attention?I know that's a tough thing to say -- but yeah, the irony is that a really really good "low-level programmer" is destined for obscurity, because things just work and once they're working people forget about it. Shouts to Linus Torvalds.
You're saying that specialization is bad and that specialists can't be experts.
No. I'm saying people that make these ignorant statementsaren'texperts.
I see, thanks.
Clearly a Go enthusiast who never mastered Python. And, really, Go? If your were pushing Rust mayyyybe I could give you the benefit of the doubt.
> I wish people could be honest and say they don’t care for some language or framework or OS for personal or aesthetic reasons, rather than having to round it up to being objectively bad, but then I suppose nobody probably would click on “I don’t like Python and have got some nits to pick”.Yeah, this kind of hyperbolic headline article repeating mostly dead-horse arguments is just low-effort click farming, not a serious contribution to the discussion of anything. All it adds to what is a well-trodden debate is…factual errors, like the claim that Python prominently features “lazy evaluation” (while, as in any language, you can arrange laziness in Python, it is very much eager normally.)
I really think that Python is not a good language for ML, it just got "there" first.The ecosystem is the real plus, of course. But the language is a headache for this. I agree with the "false economy" angle. I would happily trade the "agility" of dynamic "gluing" with some kind of real type safety, human-readable error messages and performance[0].[0] - hiding C in Python's clothes doesn't count :)
Python is the de facto glue language with one of the biggest ecosystems out there, that makes it possible to use any kind of over-the-top library that does 1093 things after a single `import antigravity`. Also, ML absolutely makes sense for python, it’s not like most PLs have actual support for video cards — ML is very specifically about manipulating data (a fundamentally dynamic task) and calling out to specific libraries for training, a very glue-task. Give me any language better than python for that.Quoting Brooks (butchered): “the only significant productivity improvement comes from relying on code that is already written”. Your fancy “better” language has not even 1/10th of what python has, it won’t replace it.
> Python is the de facto glue language with one of the biggest ecosystems out thereI never contested that.>  ML is very specifically about manipulating data (a fundamentally dynamic task)I disagree strongly with using dynamic languages for data. Data has dimensions, units, types. You need to know that you're not adding coats to horses or USD to EUR. You need to know that you didn't silently sliced by the wrong axis.
You may want formal verifications. You may to transform data without worrying about silent errors.All the "metadata" and wrapper classes ML in Python are just trying to give you what the language can't.> a very glue-task. Give me any language better than python for thatThat's my point exactly. ML has evolved beyond glueing a few C libraries. It needs complex, big programs, which is an area where Python is terrible. Also the different nature of the "glued" components (each with its own data formats, protocols and calling conventions) makes the glue a mish-mash of untyped mixed magic idioms.
Training and using ML is different. It has been relatively common to bundle the trained weights with a different programming language system - but training can be a more exploratory phase, so python is not a bad fit for that.
> And, not to put too fine a point on it, but if you can code Python but not Go (or another decent programming language), you probably have no business writing software for a living. I know it sounds harsh and I apologize for that, but writing software is a profession and hence you should have the knowledge, skill, and experience to use professional tools.Part of the profession of software engineering is maintaining software that's already written. Should the people who maintain python code, not be paid for their work?Another part is choosing the right tool for the job. Python has its flaws, but it is better than Go in some ways. For example, it has a richer ecosystem of libraries.
Let me ask the obvious question.Why hasn’t the go community, of professional software engineers built an even richer ecosystem of libraries?Is it ennui, incompetence, or attitude?As Go came from Google, is that the attitude was, “I am a professional I’ll just write my own code to solve X”, rather than considering building a library that others can use?Are libraries harder to build in Go? Is adoption of libraries by the Go community different?Is it a mindset, that libraries are uninteresting?Or is it something else entirely?
Compare the number of programmer-hours on Python to Go. Having a ~15 year head start helps a lot.Plus, I've been programming in Go professionally for a while and it's been a while since I reached for a critical library and it was missing.Go ends up needing fewer libraries anyhow; in Python you have the pure-Python version, no, wait, the Twisted version (which may not be current but are still all there, increasing the library count), no, wait, the async version, no, wait, the Python 2 version, no, wait, the one that binds to a C library.... and actually this isn't specific to Go, it's really more specific to Python. Library count gets bloated up over the decades by the fact that when, for example, Python went to async, all non-async libraries in which async was relevant suddenly needed a clone. Go has had effectively no language changes which create such parallel libraries (notechanges, notadditions; Go has hadadditionswhich create opportunities for more libraries but don't create lots of parallel libraries). I don't know that Python isuniquelychanging, "best practices C++" is arguably up there, Javascript has had a lot of churn, but it's in the higher tier of such things. Languages that don't churn like that should be able to cover the same amount of "need" for libraries in fewer libraries by the numbers.
Yes.  Go has a culture that avoids using libraries (the axiom is "a little copying is better than a little dependency" (see, e.g.https://www.efekarakus.com/2021/09/23/a-little-copying-is-be...)
Having used go professionally, I would comment it's not just a little copying, but can be rather substantial.
It hasn't been around as long as Python.
That is true, but where are the go libraries for machine learning, tensors, LLMs, equivalents to PyTorch that I see bandied about?Others have stated that they don’t need such libraries in Go, or that Python just has a glut of libraries that are a sort of detritus obsolete or language version specific.Why isn’t Go then, THE language of choice for machine learning, analytics, fast prototyping, data conversion, ETL, etc.What I’ve heard of Rust in comparison is that the syntax of the language & the learning curve is counterintuitive for engagement by non-computer scientists or systems programmers.Seems expected then that, non comp-sci folks will choose a language that is more accessible, with an ecosystem that lets them get things done in a short period of time.I would wonder if it it that the experts & heavy users of Go or language architects moving Go forward see any need for a parallel course of engagement to bring Pythonists into the fold or to allow Go to become the language people choose over Python or TypeScript, et al, by providing a best of class approach to quickly prototyping and extending into well architected systems as an underlying function.
Why do people use Microsoft Windows on x86?The computer industry has a bizarre reputation for moving fast and breaking things. In fact the industry is shockingly conservative. You will encounter many,manyprogrammers who flat-out refuse to learn new things.
Most companies & universities aren’t exposed to cutting edge or even modern technology. They stay in their bubble.Leaving Silicon Valley, I’ve found the engineering management culture can be averse to training and allowing active skill building via development projects.Just code that shit in Java or C++, doesn’t matter if you haven’t been trained in SQL properly or are even aware of best practices.That culture leads to some gruesome product implementations & upgrade scenarios.Hell, our IT department blocks this very website from being accessed.I access it from my personal devices.
What's the Go community? Google employees?
There's no Go community, it's a corporate language.Why hasn't the Visual Basic for Office community produced more libraries?
Not sure if rhetoric question only, but Go has the expressivity of C. Let’s not compare it to python that is often textbook pseudo code like.
If the “expressivity of C was such a wonderful thing why was Go even needed? Why was Java & J2EE promoted to enterprise development?Might it be that coding in C was and is hard and further that memory management pointer issues and more led to unstable code?
I wrote my comment as a negative — C is terribly inexpressive, just as Go.
Terrible is using a dynamic programming language and expecting static features from it. Besides, linters and type hinting have come a long way.
>Besides, linters and type hinting have come a long way.You acknowledge that the kinds of static analysis that are feasible in Python are valuable, but it's "terrible" to want the kinds of static analysis that are infeasible. How interesting that the two boundaries line up exactly.
They have, but I find they still lag behind the state of the art. Python insistence on optional, second thought support for type hints is frustrating.Linting has saved my bacon more than once, granted.
There's an evaporative cooling effect. Ten years ago it was obvious that Python was going to have a very hard time in the multicore world. People who needed that performance and knew they needed that performance left somewhere in the intervening years. It has been obvious for a while that Python was not going to be capable of a general solution to that problem no matter what it did. Now those people are no longer in the Python community.What's left are people who don't need that performance, which is sometimes me and is when I still am happy to use Python for something, and people who do need that performance, butdon't know it. Those are the ones who get into trouble.I do wish that the Python developer community would be more open about the fact that Python performance is really quite bad in many cases and that while there are some tools to peck around the edges, it is still fundamentally a low performance language, things like NumPy notwithstanding (it is, ultimately, still a "peck around the edges" tool, even if the particular edge it pecks it doesextremelywell, but that only makes the performance delta worse when you fall out of its accelerated code path). I feel like maybe back in the 200Xs the community as a whole was more open to that. Now "Python is slow" is perceived by the community as an attack. Maybe because the ones who did understand what that issue was are mostly gone.But in the 2020s, yes, Python ought to be straight-up eliminated from many tasks people want to do today on straight-up performance grounds. Overcoming a ~40x disadvantage in the single core era was sometimes tough, but often doable. But nowadays basically that gets multiplied by each core on the system, and overcoming a multi-hundred-factor disadvantage is just not worth your timeIFthat is a level of performance you need. Python is nice, but not nice enough to pay for multiple-hundred-factor performance penalties. Static languages have come a long way since 1995.
If the only problem with Python was its slowness, I could live with it! Its other problems are worse (like tooling, bad type hinting, etc).
Agreed, but I think slowness is the one that is impossible to fix without making Python into something other than Python. Since the day it was born we were promised that Sufficient Smart Compilers would come along and make it as perfomant as C. We know what that looks like in the limit now, which is basically PyPy; it doesn't get to C except in small cases and eats a ton more memory in the process, and there's no reason to believe it will ever happen.The semantics of Python are fundamentally slow. To fix that requires changing semantics. Such a change would dwarf 2 -> 3 in size and be effectively a new language, like "Perl 6" was.
"there are only two kinds of languages: the ones people complain about and the ones nobody uses".
Every single "This language is good" or "This language is bad" take really needs to always come with a "for what, exactly.""This wrench is really bad for hammering nails!"
Agreed. But I also think it's fair to criticizegeneral purposelanguages ongeneralgrounds :)It's just that this article isn't very good at it.
It's fair, but the other thing happens WAY more.It honestly just strikes me as very odd how e.g. even "just use multiple languages" is done a whole lot, but not really talked about as a good idea (as much as MY LANGUAGE IS GOOD AND YOURS IS NOT)
The author of this article does highlight the cases where using Python didn't work out well for them, in fact multiple times.
The context the author was working in was a large corporation with a demanding collection of services that needed to be managed.  Many of the tools to manage those servers were written in Python, since many people know it, it was already widely used at the org, it had good support for C++ interop (also widely used at the org), and Java was found to be really clunky for sysadmin tooling.I've seen both sides of it- I worked in the same sub-org as Jos, and my very first job was cleaning up a large pile of incredibly important and variable-quality Python code used to manage a fleet of database servers.  the code was tools to do useful things like implement failover of the replication master (across ~90-120 shards) from one region to another for maintainence.  Or apply schema changes across all those master shards.  Or monitor the shards at runtime.At times, the code would Exception (literally, crash with a Python exception) during the middle of an important but routine maintainence, and the migration would be half-done.  I was hired- literally, this was my job- to add tests to the code until it was much more reliable.   Working on that convinced me that rather than type-safety (which is nice, and can be used optionally in python),high test qualityandhigh test coverage of paths used in productionwere more important to keep the code running smoothly.I just wish Python hadn't made strings a sequence type, as one of the most common errors at the org was accidentally e m a i l i n g   e v e r y  s i n g l e letter in a To: string.  IE, if it was "To: bore-sre@stoogle.com", then b@, o@, r@, e@, etc, would all get an email saying "Process failed..."  And r@ would reply (because he's rob pike) saying "your python program has a bug...."
Python is one of my least favorite languages and I avoid it wherever I can. I agree with several of the criticisms here, but I disagree with this part:> The problem with Python is of course that it is an interpreted language with lazy evaluationThat isn't "the problem" with Python. There's nothing wrong with these sorts of languages. However, it does limit the sorts of problems the language is suited for, and I do see places where Python was used where another language would have produced far better results.Perhaps using Python inappropriately leads to some thinking that the fault is with the language?
> with lazy evaluationI know it has functions that are lazy, but it's not lazy as in a sense that Haskell is right? I never use it as I find it a ghastly horror show (my taste, other people like it, that's fine), but I had to use it a few times and found that (also from the article) some parts are lazy, but not python as a language. Is that not correct?> it does limit the sorts of problems the language is suited for,Interpreted (...) is the implementation, there is no reason why it should be interpreted.
You are right, the article is wrong. It is most certainly not lazy. f(g(), h()) will always call both h and g regardless of whether f uses their results.Iteration in a sense can be "lazy", but that laziness is via data structures built on top of a strict core language. Python is not alone in having lazy iteratable data structures, but it leans into them relatively hard in its standard library.Many of us love this, as it lets for loops work elegantly over all sorts of abstractions, but I could see some folks disliking it. Still, the author does not explain this nuance, which makes me think he does not quite know what he is talking about.
Almost every mainstream language has a way to "lazily" (in the sense you mean) iterate over lists, so this can't be what the author was singling out. I think he's just confused.
But that's just libraries though. A language that actually evaluates outer to inner is different. And yes, indeed confused I would say.
Almost surely the author of TFA meant "dynamic", not lazy.Nobody uses "lazy" in the sense of TFA.
It’s just plain wrong. The Wikipedia link points to “lazy” in the  Haskell sense. Python is not that.
Agreed. It's so evidently wrong my guess is that the author thinks "lazy" means "dynamic", searched Wikipedia and pasted a link to the article without reading it (in which case he would have found it didn't match his understanding).It's the less insane explanation. The alternative, that the author read and understood what lazy evaluation is, but somehow still thinks Python does it this way, is too crazy to consider.
The article meant Dynamic instead of Lazy? Ah.. Well, that's terrible use of words that mean something then.
Yes and yes.It doesn't bode well for a bit of criticism when it starts by grossly misusing a technical term.
Not Haskell style lazy but more of declarations are just another statement that aren't evaluated until those lines are executed.  This means you can have function definitions inside of ifs which can be very useful for conditional programming / meta programming.  Similarly, all variable accesses happen at runtime.  This makes it so you can't truly statically verify the program but that the only way to know for sure how it will behave is to run it.In an odd twist, function argument defaults are evaluated at function definition execution time rather than call-time (so half-way in laziness) so a `[]` as a default is shared between all users of that function and if you modify it you are changing a global.  I heard that this led to a vulnerability within some security software.
What you describe is not lazy evaluation in any accepted sense of the term. I bet you it's also not what the author meant; he was probably thinking of dynamic typing.Alternatively, maybe the author (and you) meant "interpreted language"? Lazy/strict evaluation is an orthogonal aspect.
Yes, pretty much agree with this word for word. It is very, very difficult to refactor a python application in any sort of reliable way. The standard way of error handling in python appears to be to present the user with a stack trace. Very user friendly (not!). Now people will say that, for instance, mypy can help with this. That is true but since projects can be started without type checking chances are that your project was started without type checking and that introducing mypy is somewhere on the backlog and when it comes off the backlog it will be enabled only partially because otherwise there will be too many errors and so on. It is such a garbage programming environment.
I couldn’t (and still can’t) believe that non-exceptional situations are considered exceptional. Such as, there not being a way to parse a string into a number and return a value indicating if it was successful or not. With Python everything is an exception. Messy and inelegant. Of course this mess is called “pythonic” so everything is fine…https://blog.codinghorror.com/exception-driven-development/a...https://stackoverflow.com/questions/2184935/performance-cost...
> parse a string into a number and return a value indicating if it was successful or not.Eric Lippert had a decent blog post[1] back in 2008 on this titled "Vexing Exceptions" with regards to .NET.[1]:https://ericlippert.com/2008/09/10/vexing-exceptions/
Whether or not you agree with it the argument for exception handling, rather than return values, is it lets the code more naturally flow for the successful case. The alternative is go's repetitivef, err := fn(...)if err != nil {
    ...
}pattern. Which is better is really a matter of taste. To have error handling smattered all over the code seems more inelegant and messy to me.
What?  You can return Exceptions instead of raising them.  Since the language is dynamic, the caller can introspect.Personally, from the perspective of a number parsing function, I think being passed an unparseable number counts as an "exceptional" situation- InvalidArgumentError- and I don't care which way it's returned- as an raised exception, or as an error object- as long as it's clearly documented, and the use matches the semantics of the function (NetworkNotAvailable is a better example of an exception where you're want to put something in the exception block)
> The standard way of error handling in python appears to be to present the user with a stack trace.What do you expect it to do? Silently fail and move on?
No.  How about something that isneither"silently fail" or "print a stack trace"?  How about something that lets the programmer handle the error?
Yea python should introduce try except.
Python has proper error-handling since 20+ years.
A few weeks ago I was working on a small wildfire smoke and fire perimeter API, and I hit a few annoying snags due to tooling issues. I needed to process a lot of different formats of layered geographic datasets, and converting one thing to another, processing the data into various buckets, cleaning, aggregating, etc. all wound up being extremely cumbersome and verbose.I write a lot of Go and I’m used to that. But when I hit snags in the less familiar territory of geographic data processing, it was a slog. Terrible documentation for the libraries was a major barrier, and otherwise it seemed as though essential features simply didn’t exist and I’d have to invent them.I got the idea to explore Python for the project because people use it for data processing. I’ve used it in the past, though never for this. Whatever, I thought, at the very least I can validate that Go is a suitable tool.Within a day I had rebuilt everything with Python. I built a flask app around the forecasting and fire perimeter tools, and had it deployed the same evening. It was mind blowing.As an ecosystem I was absolutely blown away by Python. Do I like the language? Not really. I encountered so many cases where something could be so much faster and more efficient with Go. Deployment would be easier. I’d get more API from the same resources. Scaling would be ten times easier. Static typing tools kept blowing up my IDE because this library doesn’t support this, or the type tool is wrong about that. It was very janky at times.Yet Python got it done. It’s live right now, and development is steady. Go was not steady and I didn’t see any solution to that in sight without reinventing countless wheels.
By the way, another nice thing about python is that you can force your program to drop into a debugger with an interactive shell at runtime- and inspect/print objects.  In today's complex world of generic types, it can often be hard to see exactly which method is handling your data.
My favourite things about Python are the huge community and the rapid iteration. Don't got me wrong, I like Go, too. It was the primary language I worked in at my previous job. But sometimes you just need the big community and the huge pool of documentation, or you want something to worknowinstead of fiddling with it, and Python is great for that feedback loop.
My experience with Python can be summed up as: it's tempting to start something with it, since it has such low (initial) friction and hey, "this is just a small throwaway project anyway".Months or years later, it's a beast, hard to understand or refactor, full of holes and pitfalls, and Python's terrible tooling doesn't help either.And I never learn the lesson!
What tooling are you missing?
I've been down this road before on HN, so let's agree I don't find the existing tooling satisfying at all.The linter is ok, and an occasional lifesaver (but it shouldn't even be needed! It requires extra work to catch problems that other languages catch "for free"). And it shouldn't be a separate tool. It's also cumbersome to use, silence what is not needed (way too noisy) and fine-tune it. Inline comments to enable/disable it for specific warnings look ugly, too. Python devs tend to suppress whatever bothers them instead of fixing it because it's not in their culture.The type hinting checking is terrible. It's getting better, but it still misses obvious things and requires too much hand-holding. In my experience, average Python devs don't use it because they don't understand it, or don't find the ROI worthwhile. And because it's optional, they can just pretend it doesn't exist (or complain if you make it mandatory).The mess that is dependency management has been discussed multiple times. In Python's defense, it's in "good" company with other messes from different languages. But Python's case seems particularly horrifying.In general, with tooling, Python lives in a special hell where every blog and article will tell you "it's awful because you're doing it wrong, you should instead [use|avoid] pip, pyenv, pipenv, poetry, <my custom script>, <some deprecated tool that nobody else recommends>, <cutting edge tool that is incompatible with everything else>".
The author of the post seems like an evangelist for the Go programming language.> And, not to put too fine a point on it, but if you can code Python but not Go (or another decent programming language), you probably have no business writing software for a living.
What's funny is that (in a different Python rant from another author), it was pointed out thatGooglewas the heaviest pusher of Python in the early 2000s. It probably would have been Java (from Android and elsewhere) had it not been all the legal stuff with Oracle brewing. So, Python here, Python there, Python everywhere... then Google invented Go and Dart and other shiny new toys and began pushing them everywhere.
Go was written to replace C++ and Java at Google, not Python.  But after it launched many Python developers in SRE switched to Go- for good reasons.  Initially it was a bit of surprise to the Go creators.Python (fronting C++ code) still plays a huge role at Google.  I don't see that changing.  Go has almost zero story for scientific computing.
> It probably would have been Java (from Android and elsewhere) had it not been all the legal stuff with Oracle brewing.Oracle started buying Sun (and consequently Java) in 2009; the merger was completed in 2010. So I fail to see how that could have influenced Google's purported aversion to Java in the early 2000s, even as late as 2007 or 2008.
> And, not to put too fine a point on it, but if you can code Python but not Go (or another decent programming language), you probably have no business writing software for a living.Come on man. There's being opionated, and then there'sthis.
I’m not a fan of Python, but this article is insufferable in tone. If Python doesn’t meet your needs, don’t use it. There’s plenty of oddities to gripe about in Python, but this article doesn’t attempt to learn something or make a larger point beyond “my favored approach is the only valid approach”. Sorry, but that’s not an opinion worth considering.
As much as I personally dislike python, I completely agree with this, but want to flip it.  If pythong meets your needs, absolutely use it.  Don't complain about how Visual BASIC doesn't work for you on your way to downloading whatever version of python is current this month.
No enforced static typing and no proper debugger make Python painful for large code bases. It’s good for scripts, prototyping, and gluing libraries together to make utilities, but if something expands beyond a single file I stop wanting to use Python. Convincing my employer of this is another matter and why I would rather avoid it completely.
The problem with Python is of course that it is an interpreted language with lazy evaluation […]Huh?
They probably mean dynamic.
It doesn't bode well when an article starts with such a gross misuse of a technical term.Far from me to defend Python, but this rant didn't start well.
Came here to make that exact comment.  But I didn't see this comment, so I said the same thing.
I have grown to like Python for small programs and scripts because of libraries like TensorFlow, PyTorch, LangChain, etc.I agree with the author that there are better languages for large applications.
I have developed insanely complicated software with Python that works pretty well.If you expect to find Java or C in Python you are looking at the wrong place.
I did 2 to 3 migrations. It was fine. I would rather deal with these types of issues once in a while than work everyday with Java.
Yeah.  I did 90kloc of python porting.  Twice.  Never working for a company that allows developers to use python again.I'm glad you were able to port your scripts, but python is absolutely not appropriate for mission critical software.
> I once worked with a service in Python that forked worker processes to handle requests, ensuring that all cores could be used.> > Unfortunately these workers ran out of memory quickly so we decided to have workers terminate themselves after a configurable number of requests had been handled so that Linux would do our memory management for us.I once worked with a service in Python that was essentially an image server for a special biomedical image format. The decoder was a proprietary C library written by a vendor and, unsurprisingly, had tons of memory leak issues. This exact feature of Gunicorn [0] saved us months of going back and forth with the vendor to get the library to stop killing our servers.Python has it's flaws, but so does anything touched by humans.[0]https://docs.gunicorn.org/en/stable/settings.html#max-reques...
Really for all the complaints about JS/NPM/Electron it looks absolutely genius next to Python tooling and PyInstall.It's extremely frustrating that you're forced into using it to access technology that doesn't even use Python really it's just the composing glue sticking the native C++ or GPGPU code blobs together.
>Using Python for a large application is like building a nuclear reactor using Lego bricksI like this comparison. Anyway, it's interesting to note that it took the author "many years of experience running large applications written in Python" to come to his conclusions. The advantages of static typing and the disadvantages of dynamic or duck typing are well known since decades. The problem is less Python as a language, but the fly-by-night decisions to just use it for anything. To stick with the example: what prevents people from using "Lego bricks" (or a high-temperature proof version thereof) to build a reactor? Sound engineering decisions and, most importantly, safety regulations.
>forked worker processes to handle requestsFile this one under "things that UNIX systems programmers think will work in principle but end up being massive black-holes of attempting to quiesce any non-trivial application in a way that results in a sensible post-fork state".
Python is a horrible language, but not for the reasons the author gives.  Just because range() returns a generator doesn't mean the whole language is lazy.  Several Lisps allow something like duck typing and they're not horrible.  Itispossible to reason about program behaviour in dynamic languages, but JavaScript certainly makes it hard.Python is a horrible language because it is not a language.  It is a family of languages that changes every October.  Sure, 3.x doesn't introduce as many backwards-incompatible changes per version as 2.x did, but that's like saying World War I wasn't horrible because towards the end fewer people seemed to be dying every week.
I've been programming in Python for most of the past 10 years, and I've never experienced a regression in backwards-compatibility between minor releases. What problems have you had?
The syntax of the language changes every version in non-backwards-compatible ways.If you have a couple scripts, sure, maybe you're not affected.  But when you buy a company that shat out 90kloc of python and then all the employees quit, it's not a happy day.And sure... I shouldn't have used those features.  I get it.  I'm the one who's bad because I'm calling your baby ugly.  Even though I wasn't the one that originally wrote that code.Though I did write some code that used package variables. And then the syntax for package variables changed, but that was an easy fix.  And then the scope of package variables changed to be class variables, which is totally fine, but harder to find.  Then the syntax changed again, but in a way that made it harder to fine.  And then the debugger stopped working if you enabled async io for a few versions.Python is for total amateur code fluffers.
Which syntactic features have changed in ways that aren't backwards compatible? I've had some minor headaches, don't get me wrong, but in each case those headaches are a result of interface changes to common objects, like Exception-types. Python has added some syntactic sugar between minor releases, sure, but never at the expense of backwards compatibility.
Package variables.  Class variables.  Syntax changed between 2.3, 2.5 and 2.7.  And the semantics changed somewhere between 2.3 and 2.7.
Wow, didn't realize folks were still actively developing on Python 2.x. FWIW, the Python steering committee takes backwards-compatibility pretty seriously these days. Here's a recent mailing list discussion on it's decision to reject a popular PEP on the grounds that it would have broken Pydantic:https://mail.python.org/archives/list/python-dev@python.org/...
I used to love python. It made me productive.Until it introduced the haphazard type system. Now I need to import types in every file, use IF to guard it in CI in every file, and use a powerful IDE to be able to use the benefits of typing.
> Now I needYou don't need to do anything, you can ignore all type hints> use IF to guard it in CI in every fileAre you talking about "if TYPE_CHECKING:"?Your other option is to put "from __future__ import annotations" at the top of the file, or wait for Python 3.13 when PEP 649 lands and type annotations become lazily evaluated.
typing brings me no happiness either, because it's a lot of work without being complete anyway. Annotations that are not checked vs actual behaviour at runtime can always, by the laws of programming, be subtly incorrect.I still use python. The recently introduced match statement is a great addition, IMO.
Can someone explain this part to me, please?
I don't follow what's going on.> Python's use of reference counting defeated copy-on-write because even memory blocks holding variables that were read-only were actually written to in order to manipulate the reference counts, thereby blowing up the combined physical memory footprint of the workers. We solved this by smurfing the interpreter to use a magic reference count number for all variables that were created by the master process and inherited by the workers, and then not touching reference counts that had the magic value.Thanks
You have a program that for whatever reason (the Python runtime in this case) only works single-threaded, although its workload could be easily parallelized (say, it’s a web server where requests are processed independently). An old established way to accomplish this is to start a “master” process which forks N “worker” processes, each of which can happily run single-threaded.This would be a nonstarter if it required N+1 times the memory of the single process, so the OS uses an optimization called copy-on-write. When a process forks, all its physical memory is shared by the new process so it takes almost no new memory to start. If the new process writes to a memory page, that physical page is copied so it has its own version. (Thus “copy on write”.)For most programs this works fine, but if you have a runtime that does garbage collection using a technique that requires writing to an object even if the code doesn’t change any of its values, trouble ensues. With reference counting, you have to write a new reference count for an object anytime a pointer to the object is assigned. If you store the reference countinthe object, that means its physical page has to be copied. So now the CoW optimization totally doesn’t work, because justreferencingan object causes it to take up additional new memory.Ruby used to have this same problem, and after Ruby webservers became popular (hello Rails) they eventually incorporated a patch to move the GC information somewhere outside the actual object heap. Other systems like the JVM use similar techniques to store the bookkeeping bits somewhere other than the object field bits.So what the OP did is patch the runtime so the objects created in the master process (pre-forking) have special reference counts that are never altered. This mostly works, because the master process generally does a bunch of setup so its objects were mostly not going to be garbage anyway.
Thank you, this is a great explanation - much appreciated
I don't understand the "smurfing" solution he references, but CPython's runtime uses reference counts in each referenced value to detect garbage (when a value can be freed), which means even read-only values can be modified in memory by the runtime as object references come and go.Those modifications force pages which were created on forking a child process as copy-on-write (meaning they share the same physical page until the page is modified by the child) to be copied and thus blow out any memory savings that would normally happen with copy-on-write.
It's almost like curly braces make for better languages :-PMy problem with python is its package system, and the mess around the fact it was designed to be global. (I have a similar gripe with Ruby).
> because the value of a good programming language is that it will not allow you to write programs that are structurally deficient.Ummm... okay.I'm not going to cheerlead for Python here (in fact I do not like it at all and also avoid it whenever possible) but many of this author's points seem to boil down down to "screwdrivers are bad, here's why you should always use hammers instead".Different tools exist for different purposes.
Python is a gravity pool attracting unexperienced programmers. And very often (in my experience) , it shows.Lack of static typing is nothing in comparison with lack of common sense and unwillingness to learn ("why force oneself ? The job market swallows everything anyway") .
Well said!
Another way of putting it: Python isn't a production-ready language, due to the way people are using it.Whenever some project I find doesn't just work, or works and then a few weeks later stops working, it always seems to be python. People cannot semver properly (even python itself? or is that some programs work on 3.9 and not 3.10 the programmers fault again?) and also cannot lock their dependency versions properly.  Same problem that can happen to nodejs code, and yet, I rarely see such basic failures there.I also just don't understand why anyone would even want to use python, anyway.
I've tried to debug python code, or write new python code, but I could never get into it, nor was it easy to read code others had written. Whitespace sensitivity? Special __ files for package purposes? No JIT (no idea why pypy is a separate thing rather than rolled in)? I just don't see the advantage over JS which seems to do everything better. It even has the benefit of being syntactically intuitive for users of other languages, and typescript really has saved JS from chaos. It's fine to be different from C syntactically, but it I don't see the benefit of python to justify that syntax taking up another spot in my brain I could use for learning rust or something.
> Lack of static typing is nothing in comparison with lack of common sense and unwillingness to learnI have never found any language community to lack that, and if anything its more where people have lots of experience exclusively in one language than with inexperienced programmers picking up their first (who tend to, by nature, have a willingness to learn, even if they have a lack of the common base of experience that gets labelled “common sense”.)
Everything is terrible if you use it long enough. Some things are more terrible than others for certain use cases - a thoughtful developer understands the weak points of the tooling, and selects the proper tool for the job at hand.
Interesting timing given the massive increase in Python for ML and data science applications lately.Pytorch is a great library too. It is hard to imagine Python decreasing in usage any time soon.
Wow, saying python programmers are unprofessional.... that's amazing.  Just completely and totally out of touch with the real world.I'm glad I never reported to him while at Google.
I thought it was just the whitespace.
> Of course Go is not perfect (hint: no programming language is)This is the only relevant statement.
How does running a Python 3.4 app in docker help?  3.4 is deprecated and will get no more security patches.  Running it in docker doesn't change this.
It is 2023 and we have Ruff and Pyright.
One thing I’d add to this conversation, though I’m certain it’s already been stated: As many have mentioned, there is a large subset of the user base that uses Python for applied purposes in unrelated fields that couldn’t care less about more granular aspects of optimization. I work as a research assistant for international finance faculty and I would say that compared to the average Hackernews reader, I’m technologically illiterate, but compared to the average 60-80 y/o econ/finance faculty member, I’m practically a Turing award winner.Most of these applied fields are using Python and R as no more than data gathering tools and fancy calculators. something for which the benefits of other languages are just not justified.The absolute beauty of Python for what I do is that I can write code and hand it off to a first year with a semester of coding experience. Even if they couldn’t write it themselves, they can still understand what it does after a bit of study. Additionally, I can hand it off to 75 year old professors who still sends Fax memos to the federal reserve and they’ll achieve a degree of comprehension.For these reasons, Python, although not perfect, has been so incredibly useful.
I just want to add to this, I had this exact same experience when working with journalists and other non-technical background programmers.You’ll find everyone from philosophy PhDs to Biologists to Journalists who use pandas because its so easy to learn it and work with it. It’s amazing how you can become productive in python/pandas without any experience or even basic understanding of programming because of how accessible jupyter, colab and blogs/docs on pandas are.The other thing people don’t talk about is that a lot of these organizations can hire a CS student part time or a full time software engineer/data engineer/data scientist who can optimize their scripts once they are written. Pretty much any software engineer can read and debug python code without needing to learn python. So for example, I know some engineers working in genomics who have turned biologist-written scripts that take several days to run in python into scripts that take hours or minutes to run by doing basic optimizations like removing quadratic algorithms from the script or applying pyspark or dask to add parallelism.The fact that python can be used as a bridge between technical and non-technical people is amazing and I think it has provided a better bridge between these groups than SQL was ever able to provide.
I couldn’t agree more. And I must say, now that it’s being used as a bridge between technical and nontechnical talent it’s becoming ever more vital from a career perspective. Most people recognize the value of fundamental coding skills and if you’re even just above average at coding in a non-CS field, you seem magnitudes more valuable than you really are. In both industry and research, ears immediately perk up when they realize I have a background in economics but competencies in coding beyond the standard regressions in R that everyone does in econometrics. It’s hilarious because as mentioned prior, I’m rather pathetic compared to most people on this forum.
Yeah, Python is widely used where I work for just that. The "hierarchy" of tools look somewhat like this - from most to least technical competent users1) Languages like Python / R / Julia / etc. + SQL2) PowerBI, Tableau, or similar tools3) ExcelThe number of users of those tools will be the inverse, with Excel being number 1.If you're competent using the "stack" above, you could probably work as an analyst anywhere - given that you can pick up domain knowledge.
I hate to admit that I very often start the python repl to just do some simple calculations. I always have multiple terminals open so instead of opening a calculator I just use python in one of the terminals.
Agreed. Python's REPL has basically totally replaced my usage of Emacs calc as a desk calculator, mainly because it is always there and if I don't know the big-brain closed-form solution for something like compound interest, I can just write a loop and figure it out that way.
So what you are saying is that Python is Excel for programmers :D
This is a really good line, the VAST VAST majority of programming in the world is done in Excel by people who would be horrified if you told them they were programming.And I wouldn't be surprised if a large number of python programmers would say they're not programming, it's just scripting.
I also use a python repl as an alternative to excel or SQL. I find myself just downloading the data as a CSV and then quickly cooking up some pandas to get a graph or aggregate some stats, it’s just so much quick easier imo.
I’ve migrated to the tidyverse for most of my EDA and plotting - I’ve found dplyr and ggplot to be noticeably more expressive. Pandas always added a ton of friction for me.It’s still my choice for quick and non-graphical analysis when I’m on a remote.
An alternative to pandas/Python for similar uses ishttps://www.visidata.org/. You can use Python in it also.
A bit off topic, but what would you use for data "mangling"? Like joining csvs on complex conditions, cleaning tables etc. Pandas seems to be the wrong tool for this, but I still often find myself using it as in contrast to something like Excel, my steps are at least clearly documented for future use or verification.
If you asked this question 6 or 8 years ago the answer would be it depends on the volume of data (10s of gb, 100s of gb etc.) and I could give you just a single tool that would help you in most cases.Today honestly most tools are pretty capable, pandas is a great choice and if you have really high volumes of data you might try koalas (spark) or polars.Honestly the biggest design considerations for data science today are things things external to your project: what do you and others on your team know, what tools does your company already have setup, what volume of data are you processing, what are your SLAs, who or what else needs to run this script/workflow, what softwares do you need to integrate with, how often does it need to be processed, how are you going to assure the quality of your data and what tools are you using for reporting?I tend to use pandas and SQLite for most use cases cause I can cook up a script in 2 hours and be done, I just code it interactively in a notebook and most people are able to work on a pandas or SQLite script productively if it needs to be maintained even if they don't know python. If its a large volume of data or a rapid schedule (minutes, seconds) or tight SLAs on quality or processing time, then I start to consider whether pyspark, Apache beam, dask or bigquery might be a good fit.So it really just depends but for most people who are processing < 100 GB on a 1+ day schedule or ad hoc I would recommend just using pandas or tidyverse in R and getting really good at writing those scripts fast. Today you’ll get the most mileage out of those two tools.
I still use perl for some of that stuff, or even awk, but those are barely reusable or readable.
This is a letter to the general community: please stop writing these scripts in perl and bash one liners. That one off script you thought would only be used once or twice at this nonprofit has been in continuous use for 12 years and every year a biologist or journalist runs your script having no idea how it actually works. Eventually the script breaks after 8 years and some poor college student interns there and has to figure out how perl works, what your spaghetti is doing and eventually is tasked with rewriting it in python as an intern project (true story).
I think your complaint isn't really about perl and bash. It's about knowing your audience.When writing code that will be used by a particular sort of user base, the code should be written in whatever way best suits that user base. If your users are academics, researchers, journalists, etc. -- yes, avoid anything with complex or obscure semantics like perl or bash.But if your code is going to be used by programmers or people who are already comfortable with perl/bash/whatever, those tools may be just the ticket.
one line spaghetti ... I remain unsympathetic.
He has a valid point, though. I've seen (and written!) one-liners that were so complex that nobody, even devs, can deal with them without decoding them first.They aren't technically "spaghetti", but they are technically impenetrable.I argue that one-liners like that aren't good for anybody, dev or otherwise.
Do you reply on any GitHub repo or gist w/ code snippets?
> I very often start the python repl to just do some simple calculations.If you use the python repl a lot and haven't heard of it, ptpython is worth checking out as a repl replacement. I find it to be much more ergonomic.
yup, from decimal import Decimal, and get better accuracy than any default calculator
You may like xonshhttps://xon.sh/No need to fire up a python repl.
I don't see why that's something to be ashamed of. I frequently pop open a Ruby on Rails console for this purpose. (Basically ruby's repl + libraries and language extensions.)
Eh, I type basic operations in Spolight or Google, whichever is lying on my screen!
I have python on my phone and use it to calculate tips sometimes.
Have you tried ipython?  Python repl on steriods!
from time to time yes. Ideally I would also have a jupyter notebook running at all times, but in the end it mostly comes down to vanilla python because that's installed on everything I am using
I do too if I already have a repl open, but otherwise I mostly use bc so I don’t have to wait for the slight lag of the repl to start
What’s to hate about that?  It’s a perfectly good use of Python and I do it all the time.
I've seen this too. Python has supplanted what used to be done in a spreadsheet entirely, even the custom VBA macro stuff that was once a high level spreadsheet. Python with/plus viz is more enjoyable experience than trying to wrangle some general purpose spreadsheet into doing this stuff. And, it's relatively portable and transferrable which are major advantages of the spreadsheets.
I'm one of Python's biggest critics (to me it's a Monkey's Paw of software development), but I think this is exactly the appropriate situation to use it. It's great for one-off fancy calculations, system scripts, ideally with no dependencies and/or a short lifetime
>to me it's a Monkey's Paw of software developmentThis piqued my curiosity. I've worked with Python on and off for the last ~20 years, and while I'm not a fanboy or apologist, and use other tools when appropriate, there's also a reason it remains in my toolbox and sees regular use while many other tools have come/gone/been replaced by something better.Can you share an example scenario where it's a Monkey's Paw? My suspicion is that this is more of an org issue than a tech issue?
Dependency management/tooling. Python (philosophically) treats the whole system as a dependency by default, in contrast with other modern languages that operate at the project/workspace level. This means it's very hard to isolate separate projects under the same system, or to reproducibly get a project running on a different system (even the same OS, because the system-wide state of one machine vs the next matters so much).People work around these issues with various kludges like virtual environments, Docker (just ship the whole system!), and half a dozen different package managers, each with their own manifest format. But this is a problem that simplydoesn't existin Go, JavaScript, Rust, and others.For code that never needs anything except the standard library, or for a script that never needs to be maintained or run on a different machine, Python is fine. Maybe even nice. But I've watched my coworkers waste so many hundreds of developer-hours just trying to wrangle their Python services into running locally, managing virtual environments, keeping them from trampling on each other's global dependencies, following setup docs that don't work consistently, and fixing deployments that fail every other week because the house is built on sand.
No.Virtualenvs, and requirements are a thing in Python for ages.I’ve used tons of languages and while not the best, Python dependency management and project isolation is decent. IMO certainly better than JavaScript.
It's decent if you've been in the loop enough to use it. It's not built-in. It's a good practice, for sure, but it not being built-in at the language level makes it insanely easy for a newcomer to just... Not use virtualenvs at all.In contrast to Javascript/Node.js/NPM/Yarn/whatever-you-want-to-call-server-js, which maintains a local folder with dependencies for your project, instead of installing everything globally by default.Heck, a virtual env is literally a bundled python version with the path variables overriden so that the global folder is actually a project folder, basically tricking Python into doing things The Correct Way.
Virtualenvs are a part of the standard library since v3.3[0] and most READMEs do reference them btw.[0]:https://docs.python.org/3/library/venv.html
It's been said, quite correctly, that Python is the second best language for everything.I feel that it has recently - like many really mature platforms - become very much like the elephant from that old apocryphal story [0]. It is being used for many different purposes, with very different requirements and needs, with users being so focused on their own use that anything outside that is considered "bloat" and "waste".[0]https://en.wikipedia.org/wiki/Blind_men_and_an_elephant
when it comes to slightly more non simple use cases involving parallelism and concurrency python and their imperative kin starts falling quite short of basic needs that are easily satisfied byfp languages likeocamlhaskellracketcommon lisperlangelixiror rust/golangbut even if the code is single threaded and not hampered by GIL limitations python tends to be super slow imho; also debugging dynamic python and imperative stateful python after a certain code base size >10k LOC gets extremely painful
A lot of these problem spaces can get away with single threaded performance because maybe they're generating a report or running an analysis once a day or at even slower frequency. I work in a field where numerical correctness and readability is important for prototyping control algorithms (I work on advanced sensors) and python satisfies for those properties for our analysis and prototyping work.When we really want or need performance we rewrite the slow part in C++ and use pybind to call into it. For all the real implementations that run in a soft real time system, everything is done in C++ or C depending on the ecosystem.
debugging dynamic python and imperative stateful python after a certain code base size >10k LOC gets extremely painfulfor any meaningful scale you are better served by basic FP hygiene as evidenced inhaskellelixirCL/racketor rust/golang
Because you say it doesn't make it true. It's not that painful or painful at all really. Good abstractions and planning make writing and maintaining a python easy, just like in any language.
I don’t get it. Go is as imperative as a language can be.
go is imperative but there are functional elegant styles borrowed from otp/erlang in ergohttps://github.com/ergo-services/ergohttps://memo.barrucadu.co.uk/three-months-of-go.html
Common Lisp, paragon of FP:(loop for x across numbers
        when (evenp x)
          do (setf result (+ result x)))I mean yeah, you can do FP in CL, but it allows you to program in any paradigm which you prefer.
I agree. But most people just need a pick up truck, not forming railway consists.
Python is ideal for the non-professional programmer who wants to put their skills and knowledge on wheels.
>As many have mentioned, there is a large subset of the user base that uses Python for applied purposes in unrelated fields that couldn’t care less about more granular aspects of optimization.Nobody cares about this that much. Even a straight up software developer in python doesn't care. The interpreter is so slow that most optimization tricks are irrelevant to the overall bottleneck. Really optimizing python involves the FFI and using C or C++, which is a whole different ball game.For the average python developer (not a data scientist) most frameworks have already done this for you.
Python keeps growing in number of users because it’s easy to get started, has libraries to load basically any data, and to perform any task. It’s frequently the second best language but it’s the second best language for anything.By the time a python programmer has «graduated» to learning a second language, exponential growth has created a bunch of new python programmers, most of which don’t consider themselves programmers.There are more non-programmers in this world, and they don’t care - or know about - concurrency, memory efficiency, L2 cache misses due to pointer chasing. These people all use python. This seems to be a perspective missing from most hackernews discussions, where people work on high performance Big corp big data web scale systems.
I fully agree with the description.What worries me, though, is that the features that make Python quite good at prototyping make it rather bad at auditing for safety and security. And we live in a world in which production code is prototyping code, which means that Python code that should have remained a quick experiment – and more often than not, written by people who are not that good at Python or don't care about code quality – ends up powering safety/security-critical infrastructures. Cue in the thousands of developer-hours debugging or attempting to scale code that is hostile to the task.I would claim that the same applies to JavaScript/Node, btw.
I sometimes think about what Python would be like if it were written today, with the hindsight of the last thirty years.Immutability would be the default, but mutability would be allowed, marked in some concise way so that it was easy to calculate things using imperative-style loops. Pervasive use of immutable instances would make it impossible for libraries to rely on mutating objects a la SQLAlchemy.The language would be statically type-checked, with optional type annotations and magic support for duck typing (magic because I don't know how that would work.) The type system would prioritize helpful, legible feedback, and it would not support powerful type-level programming, to keep the ecosystem accessible to beginners.It would still have a REPL, but not everything allowed in the REPL would be allowed when running code from a file.There would be a strong module system that deterred libraries from relying on global state.Support for at least one fairly accessible concurrency paradigm would be built in.I suspect that the error system would be exception-based, so that beginners and busy people could write happy path code without being nagged to handle error values and without worrying that errors could be invisibly suppressed, but there might be another way.
I think free mutability and not really needing to know about types are two things that make the language easier for beginners.If someone who's not familiar with programming runs into an error like "why can't I change the value of X" that might take them multiple hours to figure out, or they may never figure it out. Even if the error message is clear, total beginners often just don't know how to read them and use them.They provide longer term advantages once your program becomes larger but the short term advantages are more important as a scripting language imo
The type system I want would just be a type system that tells you that your code will fail, and why. Pretty much the same errors you get at runtime. Hence the need for my hypothetical type system to handle duck typing.I don't think mutability by default is necessary for beginners. They just need obvious ways of getting things done. There are two places beginners use mutability a lot. The first is gradual transformation of a value:line = "The best of times, the worst "
    line = line.trim()
    line = line[:line.find(' ')]This is easily handled by using a different name for each value. The second is in loops:word_count = 0
    for line in lines():
        word_count += num_words(line)I think in a lot of cases beginners will have no problem using a map or list comprehension idiom if they've seen examples:word_counts = [num_words(line) for line in lines]
    # or word_counts = map(num_words, line)
    word_count = sum(word_counts)But for cases where the immutable idiom is a bit tricker (like a complicated fold) they could use a mutable variable using the mutability marker I mentioned. Let's make the mutability marker @ since it tells you that the value can be different "at" different times, and let's require it everywhere the variable is used:word_count @= 0
    for line in lines():
        word_count @= word_count + num_words(line)Voila. The important thing is not to mandate immutability, but to ensure that mutability is the exception, and immutability the norm. That ensures that library writers won't assume mutability and rely on it (coughSQLAlchemycough), and the language will provide good ergonomic support for immutability.It's a common claim that immutability only pays off in larger programs, but I think the mental tax of mutability starts pretty immediately for beginners. We're just used to it. Consider this example:dog_name = Name(first='Rusty', last='Licks')
    dog1.name = favorite_name
    dog_name.last = 'Barksalot'
    dog2.name = favorite_name
    print(dog1.name) # It's not Rusty Licks!Beginners shouldn't have to constantly wrestle with the difference between value semantics and reference semantics! This is the simplest possible example, and it's already a mind-bender for beginners. In slightly more complicated guises, it even trips up professionals programmers. I inherited a Jupyter notebook from a poor data scientist who printed out the same expression over and over again in different places in the notebook trying to pinpoint where and why the value changed. (Lesson learned: never try to use application code in a data science calculation... lol.) Reserving mutability for special cases protects beginners from wrestling with strange behavior from mistakes like these.
You should check out Julia (https://julialang.org/), that's very close to what you describe.
You beat me to it!Julia is both dynamic and fast. It doesn’t solve all issues but uniquely solves the problem of needing 2 languages if you want flexibility and performance.
Exception error handling - and their extensive use in the standard library -is the fundamental design mistake that prevented Python becoming a substantial programing language.Coupled with the dynamic typing and mutability by default, it guarantees Python programs won't scale, relegating the language to the role of a scratchpad for rough drafts and one off scripts, a toy beginner's language.
I have no idea why you say that it's a scratchpad or a toy language consdering that far more production lines of code are getting written in Python nowadays than practically any other language with the possible exception of Java.
But that's the same with Excel: massive usage for throwaway projects with loose or non-existing requirements or performance bounds that end-up in production. Python is widely used, but not for substantial programming in large projects - say, projects over 100 kloc. Python hit the "quick and dirty" sweet spot of programming.
This is absolutely not true. I’ve made my living working with Python and there’s an astounding amount of large Python codebases. Onstage and YouTube alone have millions of lines of code. Hedge funds and fintechs base their entire data processing workflows around Python batch jobs. Django is about as popular as Rails and powers millions of websites and backends.None of those applications are toys. I have no idea where your misperception is coming from.
I guess I'm more than a little prejudiced from trying to maintain all sorts of CI tools, web applications and other largeish programs somebody initially hacked in Python in an afternoon and which grew to become "vital infrastructure". The lack of typing bytes you hard and the optional typing that has been shoehorned into the language is irrelevant in practice.All sorts of problems would simply have not existed if the proper language was used from the beginning, as opposed to the one where anyone can hack most easily.
Statically typed with duck typing is called structural typing. (As opposed to nominal typing, with inheritance hierarchies).It’s already what you get with python and mypy. Using typing.Protocol or Unions.
This is pretty much what nim is btw. Very fun language in my experience.
Nim is fun, but it needs to be more popular.
Aren't you kinda describing OCaml?
We still live in a world where many outward facing networked applications are written in C. Dynamic languages with safe strings are far from the floor for securable tools.
That is true.However, I hope that these C applications are written by people who are really good at C. I know that some of these Python applications are written by people who discovered the language as they deployed into production.
That’s a measure of programming prowess, not the actual security concern at hand.If the masterful C developer still insists on using a language that has so many footguns and a weird culture of developers pretending that they’re more capable than they are, then their C mastery could very well’ve not been worth much against someone throwing something together in Python, which will at the very least immediately bypass the vast majority of vulnerabilities found in C code. Plus, my experience with such software is that the sort of higher level vulnerabilities that you’d still see in Python code aren’t ones that the C developer has necessarily dealt with.
That's entirely possible.How could we check?
Python code can be production code. There are many people and companies shipping Python production code and generating substantial value.
You are correct, there are absolutely huge companies shipping Python production code and generating substantial value.Do we agree that this somewhat orthogonal to what I'm writing, though?
A popular opinion in game development is that you should write a prototype first to figure out what works and is fun, and once you reach a good solution throw away that prototype code and write a proper solution with the insigts gained. The challenge is that many projects just extend the prototype code to make the final product, and end up with a mess.Regular sofware development is a lot like that as well. But you can kind of get around that by having Python as the "prototyping language", and anything that's proven to be useful gets converted to a language that's more useful for production.
Hey, it is better than programs written as Excel functions.
It is.But I fear that the same folks that decried the use of excel by "the masses" are now just as horrified by the widespread usage of Python! :-)
> the features that make Python quite good at prototyping make it rather bad at auditing for safety and securityWhat's an example that makes it bad?  Is it a case of the wrong tool for the job?For example I understand that garbage collection languages shouldn't be used with real time systems like flight controllers.
What audits need most is some ability to analyze the system discretely and really "take it apart" into pieces that they can apply metrics of success or failure  to(e.g. pass/fail for a coding style, numbers of branches and loops, when memory is allocated and released).Python is designed to be highly dynamic and to allow more code paths to be taken at runtime, through interpreting and reacting to the live data - "late binding" in the lingo, as opposed to the "early binding" of a Rust or Haskell, where you specify as much as you can up front and have the compiler test that specification at build time. Late binding creates an explosion of potential complexity and catastrophic failures because it tends to kick the can down the road - the program fails in one place, but the bug shows up somewhere else because the interpreter is very permissive and assumes what you meant was whatever allows the program to continue running, even if it leads to a crash or bad output later.Late binding is very useful - we need to assume some of it to have a live, interactive system instead of a punchcard batch process. And writing text and drawing pictures is "late binding" in the sense of the information being parsed by your eyes rather than a machine. But late binding also creates a large surface area where "anything can happen" and you don't know if you're staying in your specification or not.
Interesting.  What kinds of software get this level of audit scrutiny?
There are many examples, but let's speak for instance of the fact that Python has privacy by convention and not by semantics.This is very useful when you're writing unit tests or when you want to monkey-patch a behavior and don't have time for the refactoring that this would deserve.On the other hand, this means that a module or class, no matter how well tested and documented and annotated with types, could be entirely broken because another piece of code is monkey-patching that class, possibly from another library.Is it the case? Probably not. But how can you be sure?Another (related) example: PyTorch. Extremely useful library, as we have all witnessed for a few years. But that model you just downloaded (dynamically?) from Hugging Face (or anywhere else) can actually run arbitrary code, possibly monkey-patching your classes (see above).Is it the case? Probably not. But how can you be sure?Cue in supply chain attacks.That's what I mean by auditing for safety and security. With Python, you can get quite quickly to the result you're aiming for, or something close. But it's really, really, really hard to be sure that your code is actually safe and secure.And while I believe that Python is an excellent tool for many tasks, I am also something of an expert in safety, with some experience in security, and I consider that Python is a risky foundation to develop any safety- or security-critical application or service.
Thanks for this, super insightful perspective
There's also the argument that at a certain scale the time of a developer is simply more expensive than time on a server.If I write something in C++ that does a task in 1 second and it takes me 2 days to write, and I write the same thing in Python that takes 2 seconds but I can write it in 1 day, the 1 day of extra dev time might just pay for throwing a more high performance server against it and calling it a day. And then I don't even take the fact that a lot of applications are mostly waiting for database queries into consideration, nor maintainability of the code and the fact that high performance servers get cheaper over time.If you work at some big corp where this would mean thousands of high performance servers that's simply not worth it, but in small/medium sized companies it usually is.
Realistically something that takes 1 second in C++ will take 10 seconds (if you write efficient python and lean heavily on fast libraries) to 10 minutes in python. But the rest of your point stands
I spend most of my time waiting on IO, something like C++ isn't going to improve my performance much. If C++ takes 1ms to transform data and my Python code takes 10ms, it's not much of a win for me when I'm waiting 100ms for IO.With Python I can write and test on a Mac or Windows and easily deploy on Linux. I can iterate quickly and if I really need "performance" I can throw bigger or more VPSes at the problem with little extra cognitive load.I do not have anywhere near the same flexibility and low cognitive load with C++. The better performance isnicebut for almost everything I do day to day completely unnecessary and not worth the effort. My case isn't all cases, C++ (or whatever compiled language you pick) will be a win for some people but not for me.
And how much code is generally written that actually is compute heavy? All the code I've ever written in my job is putting and retrieving data in databases and doing some basic calculations or decisions based on it.
Rule of thumb:Code is "compute heavy" (could equally be memory heavy or IOPs heavy) if it's deployed into many servers or "the cloud" and many instances of it are running serving a lot of requests to a lot of users.Then the finance people start to notice how much you are paying for those servers and suddenly serving the same number of users with less hardware becomes very significant for the company's bottom line.The other big one is reducing notable latency for users of your software.
That is absolutely true.But sometimes, you do end up writing that compute heavy piece of code. At that stage, you have to learn how to write your own native library :)Speaking of which, I've written some Python modules in Rust using PyO3, its' a very agreeable experience.
Damn! Is the rule of thumb really a 10x performance hit between Python/C++? I don’t doubt you’re correct, I’m just thinking of all the unnecessary cycles I put my poor CPU through.
Outside cases where Python is used as a thin wrapper around some C library (simple networking code, numpy, etc) 10x is frankly quite conservative. Depending on the problem space and how aggressively you optimize, it's easily multiple orders of magnitude.
Those cases are about 95% of scientific programming.This is the first line in most scientific code:import numpy
FFI into lean C isn't some perf panacea either, beyond the overhead you're also depriving yourself of interprocedural optimization and other Good Things from the native space.
Of course it depends on what you are doing, but 10x is a pretty good case.  I recently re-wrote a C++ tool in python and even though all the data parsing and computing was done by python libraries that wrap high performance C libraries, the program was still 6 or 7 times slower than C++.  Had I written the python version in pure python (no numpy, no third party C libraries) it would no doubt have been 1000x slower.
It depends on what you're doing. If you load some data, process it with some Numpy routines (where speed-critical parts are implemented in C) and save a result, you can probably be almost as fast as C++... however if you write your algorithm fully in Python, you might have much worse results than being 10x slower. See for example:https://shvbsle.in/computers-are-fast-but-you-dont-know-it-p...(here they have ~4x speedup from good Python to unoptimized C++, and ~1000x from heavy Python to optimized one...)
It can be anywhere from 2-3x for IO-heavy code to 2000x for tight vectorizable loops.  But 20x-80x is pretty typical.
Last time I checked (which was a few years ago), the performance gain of porting a non-trivial calculation-heavy piece of code from Python to OCaml was actually 25x.  I believe that performance of Python has improved quite a lot since then (as has OCaml's), but I doubt it's sufficient to erase this difference.And OCaml (which offers a productivity comparable to Python) is sensibly slower than Rust or C++.
It really depends on what you're doing, but I don't think it is generally accurate.What slows Python down is generally the "everything is an object" attitude of the interpreter. I.e. you call a function, the interpreter has to first create an object of the thing you're calling.In C++, due to zero-cost abstractions, this usually just boils down to a CALL instruction preceded by a bunch of PUSH instructions in assembly, based on the number of parameters (and call convention). This is of course a lot faster than running through the abstractions of creating some Python object.
> What slows Python down is generally the "everything is an object" attitude of the interpreterNah, it’s the interpreter itself. Due to it not having JIT compilation there is a very high ceiling it can not even in theory surpass (as opposed to things like pypy, or graal python).
Which can be inlined/speculated away easily. It won’t be as fast as well-optimized C++ (mostly due to memory layout), but there is no reason why it couldn’t get arbitrarily close to that.
> Which can be inlined/speculated away easily.How so? Python is dynamically typed after all and even type annotations are merely bolted on – they don't tell you anything about the "actual" type of an object, they merely restrict your view on that object (i.e. what operations you can do on the variable without causing a type error). For instance, if you add additional properties to an object of type A via monkey-patching, you can still pass it around as object of type A.
A function/part of code is performed say a thousand times, the runtime collects statistics that object ‘a’ was always an integer, so it might be worthwhile to compile this code block to native code with a guard on whether ‘a’ really is an integer (that’s very cheap). The speedup comes from not doing interpretation, but taking the common case and making it natively fast and in the slow branch the complex case of “+ operator has been redefined” for example can be handled simply by the interpreter. Python is not more dynamic than Javascript (hell, python is strongly typed even), which hovers around the impressive 2x native performance mark.Also, if you are interested, “shapes” are the primitives of both Javascript and python jit compilers instead of regular types.
Well at least 10x, sometimes more. Not really surprising when you think about that it's a VM reading and parsing your code as a string at runtime.
> it's a VM reading and parsing your code as a string at runtime.Commonly it creates the .pyc files, so it doesn't really re-parse your code as a string every time. But it does check the file's dates to make sure that the .pyc file is up to date.On debian (and I guess most distributions) the .pyc files get created when you install the package, because generally they go in /usr and that's only writeable by root.It does include the full parser in the runtime, but I'd expect most code to not be re-parsed entirely at every start.The import thing is really slow anyway. People writing command lines have to defer imports to avoid huge startup times to load libraries that are perhaps needed just by some functions that might not even be used in that particular run.
> re-parse your code as a string every timeThat doesn’t really take any significant time though on modern processors.
Aren't those pyc files still technically just string bytecode, but encoded as hex?
Well bytecode isn't the same as the actual code you write in your editor.
As a long-time Python lover, yes that's a decent rule of thumb.
It is anywhere from 1x to 100x+.
If the 1 second is spent waiting for IO, it will take 1 second in whatever language.But yes python is slow.However I've seen good python code be faster than bad C code.
Well, to be fair the "good python code" is probably just executing something written in c lol. But lots of python is backed up by stuff written in c.
Not necessarily. Just using a better optimized sort or hash algorithm can make a big difference.I was talking specifically of pure python code (except the python's standard library itself, where it really is unavoidable).
Of course algorithmic complexity will trump anything else at big enough n values.
Not for everything. There are plenty of Python operations that are not 10x slower than c.
That is true, but there are relatively few real world applications that consist of only those operations.  In the example I mentioned below, there where actually some parts of my python rewrite that ended up faster than the original C++ code, but once everything was strung together into a complete application those parts where swamped by the slow parts.
Most of the time these are arithmetic tight loops that require optimisations, and it's easy to extract those into separate compiled cython modules without losing overal cohesion within the same Python ecosystem.
If Python was merely twice as slow then I could agree with you.
Not all code needs to process terabytes of data.I have code running that reads ~20 bytes, checks the internal status on an hashmap and flips a bit.Would it be faster in C? Of course.Would it have taken me much longer to write to achieve absolutely no benefit? Yes.
Speeding up the time critical parts with Cython or Numba or ... is rather easy.
There are also programmers who are tired of chasing pointers and simply want to get stuff done.E.g. people who once wrote "robust" code in Rust but were "outcompeted" left and right by coworkers who churn out shiny new things at 10x the speed.
At some point, every engineer has heard this same argument but in favor of all kinds of dubious things such as emailing zip files of source code, not having tests, not having a build system, not doing IaC, not using the type system, etc.I'm sure Rust was the wrong tool for the job in your case but I find this type of get shit done argument unpersuasive in general. It overestimates the value of short-term delivery and underestimates how quickly an investment in doing things "the right way" pays off.
Totally depends on the business you're in.If you're dealing in areas with short time limits then Python is great,
because you can't sell a ticket for a ship that has sailed.And I've seen "the right way" which, again, depending on the business may
result in a well designed product that is not what's actually needed (because
people are really bad at defining what they want)What's brilliant with Python compared to other hacky solutions that it
does support test, type hints, version control and other things. It just
doesn't force you to work that way. But if you want to write stable, maintainable
code, you can do it.That means you can write your code without types and add them later. 
Or add tests later once your prototype was been accepted. Or whenever something
goes wrong in production, fix it and then write a test against that.Oh and I totally agree you should certainly try to "do things the right way", 
if the business allows it.
It is hard to believe that Python is objectively that much more productive than other languages. I know Python moderately well (with much more real world experience in C#). I like Python very much but I don't think it is significantly more productive than C#.
Python is out of this world more productive in the Science space and Data space.The only thing that can compete with it for productivity in the science space is R.
This. C#, Java or even newcomers such as Kotlin/Go are even in the same ballpark due to the REPL/Jupyter alone. Let alone when you consider the ecosystem
If you are in a lab (natural science lab) or anywhere close to data, I bet you it is much more productive, even more so when you have to factor in that the code might be exposed to non-technical individuals.
Using Python vs Rust is in no way in the same league as not having tests.
Totally agree. That's why I clarified:> I'm sure Rust was the wrong tool for the job in your case but I find this type of get shit done argument unpersuasive in general.Unless you're working on a fire-and-forget project with a tiny time horizon get shit done arguments are blatantly short-termist.
The thing is that the short term is much easier to predict what you're going to need and where the value is, and in the long term you might not even work on this codebase anymore. Lot of incentives to get things done in the short term.
The business owner (whoever writes the checks) prefers get shit done over "the right way". Time to completion is a key factor of the payoff function of the devs work.
The entire point of doing things the right way is that you end up delivering more value in the long term, and "long term" can be as soon as weeks or even days in some cases.Business owners definitely prefer less bugs, less customer complaints, less support burden, less outages, less headaches. Corner cutting doesn't make economic sense for most businesses and good engineering leadership doesn't have much trouble communicating this up the chain. The only environment where I've seen corner cutting make business sense is turd polishing agencies whose business model involves dumping their mistakes on their clients and running away so the next guy can take the blame.
Try the travel/event booking business (where I'm in) - and no, people don't dump their mistakes on the next guy here - to the contrary, the "hacky" Python solutions are supported for years and teams stay for decades (allthough a decade ago we had not discovered how great Python was)What business owners actually don't like at all is how long is takes traditional software development to actually solve problems - which then don't really fit the business after wasting a few years of ressources... and the dumping and running away is worse in Java and other compiled software. With Python you can at least read the source in production if the team ran away...
> the dumping and running away is worse in Java and other compiled software. With Python you can at least read the source in production if the team ran away...Java (and dotnet, the two big "VM" languages) is somewhat of a strange example for that; JVM bytecode is surprisingly stable and reverse engineering is reasonably easy unless the code was purposely obfuscated - a bad sign on any language anyways.
> It overestimates the value of short-term deliveryFor an early stage start up this is almost the only relevant factor for success.
From the other half of that sentence:> underestimates how quickly an investment in doing things "the right way" pays off.What time horizon should a startup optimize delivery for? Minutes, hours, days, weeks? Say you're a startup dev in a maximalist "get shit done now" mindset so you're skipping types, tests, any forethought or planning so you can get the feature of the week done as fast as possible. This makes you faster for one week but slower the week after, and the week after, and the week after that.Say a seed stage startup aims for 12 months runway to achieve some key outcomes. That's still a marathon. It still doesn't make sense to sprint the first 200 meters.
> coworkers who churn out shiny new things at 10x the speedSounds like a classic web-dev perspective, my customers hate when we ship broken tools because it ruins their work, new feature velocity be dammned. We love our borrow checker because initially you run at 0.5x velocity but post-25kSLOC you get to run at 2x velocity, which continues to mystify managers worldwide.
This is not just a web-dev perspective.People use Python in financial applications, Data Engineering and AI/ML pipelines, infrastructure software etc and the 10x speed can be real.
Feature factories give web dev such a bad rep, it doesn't have to be this way..
I use mostly Python, and a bit of Rust.With Python, testing, good hygiene and a bit of luck you can write core that is maybe 99% reliable. It is very, very hard to get to (100-eps)% for eps < 0.1% or so. Rust seems better suited to that.Anything else, especially if there isn't a huge premium on speed, meh - Python is almost always sufficient, and not in the way.
I use the same combo: lots of Python to analyse problems, test algos, process data, etc. Then, once I settle on a solution but still need more performance (outside GPU's), I go to rust.
Genuinely curious, why do you need Rust?
I'm simulating an audio speaker in real time. So I do the data crunching, model fitting, etc. in python and this gives me a godd theoretical model of the speaker. But to be able to make a simulation in realtime, I need lots of speed so rust makes sense there (moreover, the code I have to plug that in is rust too, so one more reason :-)). (now tbh, my realtime needs are not super hard, so I can avoid a DSP and a real time OS :-) )I don't need rust specifically. It's just that its memory and thread management really help me to continue what I do in python: focusing on my core business instead of technical stuff.The less I code the better I feel :-)
My most successful career epiphany was realizing that everyone -- my customers, my boss, etc -- was happier if I shipped code when I thought it was 80% ready.  That long tail from 80-100% generates a lot of frustration.
Can you clarify this comment?
You mean the bit about frustration?It's just an application of the Pareto principle.  That last 20% of work to make perfect software costs alotof time.  Customers (and by extension, management) do not care how pretty your code is, how perfect your test coverage is (unless your manager is a former developer, then they might have more of an opinion), they care most that youship it.  Bugs are a minor irritation compared to sitting around waiting for functionality they need, as long as you're responsive in fixing the bugs that do come up.
Thanks. I thought that is what you meant but another possible take was that the last 20% is actually important. Getting something 80% finished is fast and then the long tail to get it to 100% is frustrating for everyone because the work, in theory is finished. I think that can happen as well.Of course there are at least three dimensions to discuss here: internal quality, external quality and product/feature fit. Lower quality internal code eventually leads to slower future development and higher turnover as no one wants to work with the crappy code base. Lower external quality (i.e. bugs) can lead to customers not liking your product. Interestingly the relationship between internal and external quality is not as direct as one might think. Getting features out the door more quickly (at the expense of other things) can help with product fit. Essentially, like most things, this is an ongoing optimization problem and different approaches are appropriate for different problem domains.
That is interesting. I went in the other direction :)I am tired of having to refactor shiny new things churned out at 10x the speed and that keep breaking in production. These days, if given a choice, I prefer writing them in Rust code, spending more time writing and less time refactoring everything as soon as it breaks or needs to scale.
When the pointer chasing (sometimes) comes in handy, is once you have a successful business with a lot of data and/or users, and suddenly the cost of all those EC2 instances comes to the attention of the CFO.That's when rewriting the hot path in Go or Rust or Java or C or C++, can pay off and make those skills very valuable to the company.  Making contributions to databases, operating systems, queueing systems, interpreters, Kubernetes etc. also fall into that category.But yeah if you are churning out a MVP for a new business, yeah starting with Python or Ruby or Javascript is a better bet.(Erlang/Elixir is also an interesting point in the design space, as it's very high level and concise, but also scales better than anything else, although not especially efficient for code executing serially.  And Julia offers the concision of Python with much higher performance for numerical computing.)
Or there are programmers who write both. Something that I want to write once, have run on several different platforms, handle multi-threading nicely, and never have to think about again? Rust. Writing something to read in some data to unblock an ML engineer or make plots for management? Definitely not Rust, probably python. Then you can also churn out things at 10x the speed, but by writing the tricky parts in something other than python, you don't get dragged back down by old projects rearing their ugly heads, so you outpace the python-only colleagues in the long-term.
Programming is secondary to my primary duties and only a means for me to get other things done. I'm in constant tension between using Python and Rust.With Python I can get things up and going very quickly with little boilerplate, but I find that I'm often stumbling on edge cases that I have to debug after the fact and that these instances necessarily happen exactly when I'm focused on another task. I also find that packaging for other users is a major headache.With Rust, the development time is much higher for me, but I appreciate being able to use the type-system to enforce business logic and therefore find that I rarely have to return to debug some issue once I have it going.It's a tough trade-off for me, because I appreciate the velocity of Python, but Rust likely saves me more time overall.
If you're 'tired of chasing pointers', Rust's a lot closer to (and I'd argue better than) Python than say Go - it'll tell you where the issue is and usually how to fix it; Go will just blow up at run time. (Python (where applicable) will do something unexpected and wrong but potentially not error (..great!))(Fwiw I use all three, Python professionally.)
I completely agree - but you say that like it's a bad thing. I work as a developer alongside data scientists, who might have strong knowledge of statistics or machine learning frameworks rather than traditional programming chops.For the most part they don't need to know about concurrency, memory efficiency etc, because they're using a library where those issues have been abstracted away.I think that's what makes python ideal - it's interoperability with other languages and library ecosystem means less technical people can produce good, efficient work without having to take on a whole bunch of the footguns that would come from working directly in a language like c++ or Rust.
But this is a false dichotomy. The space of options isn't C++/Rust or Python. There are languages which attempt to give the best of both worlds, e.g. Julia.> they're using a library where those issues have been abstracted away.I work in Python, and while libraries like numpy have certainly abstracted away some of those issues, there's still so much performance left of the table because Python is still Python.
I'd say if you do data-intenstive computation with Numpy you are not leaving much on the table due to Python.
Have gone through the exercise, I know this is false.Not everything can be pushed into numpy, and you can still be left with lots of loops in python.
That's what numba [0] is for (can also help with the NumPy stuff in certain cases.)[0]https://numba.pydata.org/
Oh, I'm familiar with numba and while it certainly helps, it has plenty of it's own issues. You don't always get a performance gain and you only find this out at the end of a refactoring. Your code can get less readable if you need to transport data in and out of formats that it's compatible with (looking at you List()).To say nothing of adding yet another long dependancy chain to the language (python 3.11 is still not supported even though work started in Aug of last year).I do wonder if the effort put into making this slow language fast could have been put to better use, such as improving a language with python's ease of use but which was build from the beginning with performance in mind.
I've rewritten real world performance critical numpy code in C and easily gotten 2-5x speedup on several occasions, without having to do anything overly clever on the C side (ie no SIMD or multiprocessing C code for example).
Did you rewrite the whole thing or just drop into C for the relevant module(s)? Because the ability to chuck some C into the performance critical sections of your code is another big plus for Python.
But... pretty much any language can interoperate with C, it's calling conventions have become the universal standard. I mean, I still remember at $previousJob when I was deprecating a C library and carefully searched for any mention of the include file... only to discover that a whole lot of Fortran code depended on the thing I was changing, and I had just broken all of it (since Fortran doesn't use include files the same way, my search for "#include <my_library" didn't return any hits, but the function calls were there none-the-less).Julia, to use the great-great-grand-op's example, seems to also have a reasonably easy C interop (I've never written any Julia, so I'm basing this off skimming the docs, dunno, it might actually be much more of a pain than it looks like here).
Calling C from Julia is pretty straightforwardhttps://docs.julialang.org/en/v1/manual/calling-c-and-fortra...
Even if you do this, you're still paying a penalty whenever you move data Python->C and C->Python.Plus that you now need to write performant (and safe) C code, which (to me) defeats part of the reason to use Python in the first place.
I’ve done the same but moved from vanilla numpy to numba. The code mostly stayed the same and it took a couple hours vs however long a port to C or Rust would have taken.
For a package whose pitch is "Just apply one of the Numba decorators to your Python function, and Numba does the rest." a few hours of work is a long time.
2-5x speedup is not a lot, I would say it is not worth it to rewrite from py to C if you don't have an order of magnitude improvement.Because if you compare the benefit to the cost of rewrite from py to C and cost of maintaining/updating C code and possible C footguns like manual memory safety, etc - then there is no benefit left
2-5x IS a lot. It's the speed difference between the current iPhone 14 and an iPhone XS-iPhone 6. That's 4-8yearsof hardware improvements.And the parent was talking about numpy code which is better than stock python, who knows how far back normal python would send you.
I'm in the camp that 2-5x performance improvement is not really worth re-writing Python code in C for.
Guess that'll depend on how much you need the performance and how much code it is.They're comparing numpy (SIMD plus parallelism) with straightforward C code and getting a 2-5x improvement.
I highly doubt that numpy can ever be a bottleneck. In typical python app - there are other things like I/O that consume resources and become bottleneck, before you run into numpy limits and justify rewrite in C.
I haven't personally run into IO bottlenecks so I have no idea how you would speed those up in Python.But there's two schools of thoughts I've heard from people regarding how to think about these bottlenecks:1. IO/network is such a bottleneck so it doesn't matter if the rest is not as fast as possible.2. IO/network is a bottleneck so you have to work extra hard on everything else to make up for it as much as possible.I tend to fall in the second camp. If you can't work on the data as it's being loaded and have to wait till it's fully loaded, then you need to make sure you process it as quickly as possibly to make up for the time you spend waiting.
In my typical python apps, it's 0.1-20 seconds of IO and pre-processing, followed by 30 seconds to 10 hours of number crunching, followed by 0.1-20 seconds of post processing and IO.
It can be worth it. What matters is how much time it saves your users over the course of using the app vs the time it took to develop it. So, if:#-of-users * total-time-saved-per-user > time-spent-optimizingThen it's worth it. You can even multiply by cost of user per time unit and cost of developer per time unit, to see how much money was saved.Even in cases where its the same person on both sides, it can still work out. There's an xkcd comic about it, even.
2-5x speedup barely seems worth re-writing something for, unless we're talking calculations that take literally days to complete, or you're working on the kernel of some system that is used by millions of people.
Most programmers don't actually need to know about that stuff, either. And most programmers who do need to know about that stuff, don't know about it.
Solving race conditions is QA's problem right? ;)
You're so silly. QA? What's QA? Solving race conditions is the customer's problem :-p
>For the most part they don't need to know about concurrency [...]In my opinion, this is the part that Go gotmostlyright. Concurrency is handled by the runtime, and held behind a very thin veil. As a programmer you don't really need to know about it, but it's there when you need to poke at it directly. Exposing channels as a uniform communication mechanism has still enough footguns to be unpleasant, though.In an ideal world, I should be able to decorate a [python] variable and behind the scenes the runtime would automatically shovel all writes to it through an implicitly created channel. Instead of me as a coder having to think about it. Reads could still go through directly because they are safe.If I could have Python syntax and stdlib, with Go's net/http and crypto libraries included, and have concurrency handled transparently in Go-style without having to think about it, that would be pretty close to an all-wishes-come-true systems language. Oh, and "go fmt", "go perf" and "go fuzz" as first-class citizens too.Someone else in this thread brought up the idea of immutable data structures as a default. I wouldn't mind that. Python used to have frozenset (technically it still does but I haven't seen a performance difference for a while), so extending the idea of freeze()/unfreeze() to all data types certainly has appeal.
In fact, the development of the world is based on constant levels of abstraction, just think of assembly language and computer punch tape programming, those days are not long past.
> maybe software developers shouldn't be so hard to use?This whole take assumes bad intention on both sides. Nobody's job is easy in this situation. Leadership's job is to set everyone up for success. If things go off the rails and end up with months of back and forth leading to nobody being happy despite good intentions and honest effort, then the problem lies with leadership.
> a whole bunch of the footgunsCould you expand on this in the context of Rust?
Sure thing! Footguns might be the wrong word, and I know as a low level language Rust is insanely safe, but for a high level developer it's type system is gonna mean spendinga lotof time in the compiler figuring out type errors, at least initially. That might not be a traditional footgun, but if you're just trying to, I dunno, build a crud api or something, its gonna nuke your development time.Please don't read this as "rust is difficult and bad", I definitely don't think it is! But its a low level language, and working with it means dealing with complexity that for some tasks just might not be relevant.
I find figuring out type errors is usually less work than figuring out the runtime bugs they prevented.
I agree, but for something like the CRUD app example I made bringing in pydantic or something would solve that. Rust's type system is a lot stricter because it's solving problems in a space that doesn't touch a lot of Python developers.
In all fairness Rust was never meant for writing database interfaces, more like storage engines.
>and they don’t care - or know about - concurrency, memory efficiency, L2 cache misses due to pointer chasing.Also if I (a programmer) want to write really really fast code I'm probably reaching for tools like tensorflow, numpy, or jax. So there's not much incentive for me to switch to a more efficient language when as near as I can tell the best tooling for dealing with SIMD or weird gpu bullshit seems to be being created for python developers. If you want to write fast code do it in c/rust/whatever, if you want to write really fast code do it in python with <some-ML-library>.For a very specific definition of the word "fast" at least.
> Also if I (a programmer) want to write really really fast code I'm probably reaching for tools like tensorflow, numpy, or jax. So there's not much incentive for me to switch to a more efficient language when as near as I can tell the best tooling for dealing with SIMD or weird gpu bullshit seems to be being created for python developers. If you want to write fast code do it in c/rust/whatever, if you want to write really fast code do it in python with <some-ML-library>.Rather unfortunately, my current bugbear is that Pytorch is... slow. On the CPU. One of the most common suggestions for people who want stable diffusion to be faster is, wait for it, "Try getting a recent Intel CPU, you'll see a real uplift in performance".This despite the system only keeping a single CPU core busy. Of course, that's all youcando in Python most of the time.(You can also use larger batch sizes. But that only partially papers over the issue, and also it uses more GPU memory.)
>"Also if I (a programmer) want to write really really fast code I'm probably reaching for tools like tensorflow, numpy, or jax."Very limited view which ignores way too many areas.
Your OS, the linear algebra libraries themselves, much of the user-facing software that you use (latency sensitive rather than throughput sensitive), image/video encoding/decoding, most of the language runtimes that you use, high volume webservers, high volume data processing (where your data is not already some nice flat list of numbers you're operating on with tensor operations), for some examples.Really, for almost any X, somebody somewhere has to do X with strict performance requirements (or at very large scale, so better perf == savings)Most of these python libraries are only fast for relatively large and relatively standard operations in the first place. If you have a lot of small/weird computations, they come with a ton of overhead. I've personally had to write my own fast linear algebra libraries since our hot loop was a sort of modified tropical algebra once.
How is it in disagreement with parent?
They asked for examples of non-numpy/tf/had use cases and I gave some including my own experience? No disagreement, HPC Python in practice is heavily biased towards numpy and friends
They're not, those are useful examples.
Your comment is super interesting because it suggests Python has evolved in a direction opposite to the Python Paradox -http://www.paulgraham.com/pypar.htmlWhereas before you could get smarter programmers using Python, now because of the exponential growth of Python, the median Python programmer is likely someone with little or no software engineering or computer architecture background who is basically just gluing together a lot of libraries.
Neat observation. I wasn't doing much programming in 2004, but,  I'm guessing 2004 Python would be like today's Rust. People learn it because they love it.
I think more so Rust than even Python on 2004 since Rust has a pretty steep learning curve and does require a non-trivial amount of dedication to learning it.
Perhaps today its not smart programmers per se, but smart people who are interested in learning to program.The libraries are the killer feature for me.
>  It’s frequently the second best language but it’s the second best language for anything.This myth wasn't even true many years ago, it certainly isn't true today. You can build a mobile app, game, distributed systems, OS, GUI, Web frontend, "realtime" systems, etc in Python, but it is a weak choice for most of those things (and many others) let alone the second best option.
The saying does not mean that in a rigorous evaluation Python would be second best out of all programming ecosystems for all problems.The saying means that for any given problem, there is a better choice, but second best is the language you know which has all of the tools to get the job done, so the answer is probably just a bunch of pip installs, imports, and glue code.It’s kind of like “the best camera is the one you have with you” — it’s a play on the differing definitions of “best” to highlight the value of feasibility over technical perfection.
When I switched from PHP to Python years ago I had the same feeling as the OP, then it became the third best, then the fourth, then situational when object-orientation makes sense, then for just scripting, and now... unsure beyond a personal developer comfort/productivity preference. TUIs and GUIs built on Python on my machine seem to be the first things to have issues during system upgrades because of the package management situation.
> it’s the second best language for anythingAnything that doesn't require high performance that is. Is there any 3D game engine for python yet? I guess Godot has gdscript which is 90% python by syntax, but that doesn't quite count I think.
You won't get high performance out of Python directly, but there are a lot of Python libraries that use C or a powerful low level language underneath.  The heavy lifting in so much of machine learning is CUDA, but most people involved in ML are writing Python.
Sure, but what's not really python per se. One could also call C++ libraries from java via JNI and pretend java is super fast.If people write program logic in python it will run at python speeds. Otherwise you're not really writing python, like nobody says some linux native program is bash because it happens to be launched from a bash script.
> Sure, but what's not really python per se. One could also call C++ libraries from java via JNI and pretend java is super fast.But that's howeveryscripting language obtains good-not-just-decent performance. A strong culture of dropping down to C for any halfway-important library is why PHP's so hard to beat in real-world use, speed-wise (whatever its other shortcomings).
> Sure, but what's not really python per se.But that's exactly the strength of Python: it's an interface language. It's meant to make pretty sophisticated things like CUDA easy for everyone.
Java is super fast though, it almost never uses JNI as it doesn’t need it as opposed to Python. It uses JNI for integrating with the C world (e.g. opengl bindings).
Python isn't a joke either. I'm a full-on programmer who started with C and branched out to several other languages, and I'd still pick Python for a lot of new tasks, even things that aren't little scripts. Or NodeJS, which has similar properties but has particular advantages for web backends.
I’ve been a Python developer for 15 years, and Python might have been the second best language for anything when I started my career, but there are so many better options for just about any domainexcept maybe data science. Basically for any domain that involves running code in a production environment (as opposed to iterating in a Jupiter notebook) in which you care about reliability or performance or developer velocity, Python is going to be a pretty big liability (maybeit will be manageable if you’re just building a CRUD app atop a database). Common pain points include performance (no you can’t just multiprocess or numpy your way out of performance problems), packaging/deployment, and even setting up development environments that are reasonably representative of a production environment (this depends a lot on how you deploy to production—I’m sure lots of people have solved this fortheirproduction environment).
Yeah, big corp big data web scale systems use python too.
I'm a bit surprised to see this article on GitHub blog, it feels more like something from dev.to - looking at the surface, with little actual insights.Most of the provided reasons behind Python's popularity are true also for other languages - portable, open source, productive, big community. This can be also said about PHP, Ruby, or Perl back in 2000s. Why isn't Perl as popular as Python?I don't think it's all about readability or productivity, but about tools that were built over the last 30 years that have been used in academia and now with the boom in ML/AI/Data Science, they made Python an obvious choice to use for the new generation of tools and applications.Imagine that the boom in ML/AI didn't happen - would Python be #1 language right now?
> Why isn't Perl as popular as Python?I don't think there is a single reason, but it sure didn't help that the community self-destructed by trying to make an entirely new language after version 5 and still call it Perl.  It took a lot of years to resolve that nonsense, and in the meantime many people moved on.It also does not help that Perl is a creative language, useful but very much open to many different interpretations.  Hiring a perl guy and expecting them to read someone else's code is a crapshoot.  The upside to Python's strong cultural opinions on coding style makes it easier for one developer to pick up someone else's code.> Imagine that the boom in ML/AI didn't happen - would Python be #1 language right now?Probably not.  But it wouldn't be perl, either.  Javascript most likely.  But the core usage of python for scripting was never predicated on ML popularity, so it would still be a pretty commonly used language.  and javascript has many annoying warts too, so I think plenty of people would still choose to write django apps instead of node, whether ML existed or not.
The line noise complaint isn't without merit either.One of the few programming language jokes I've liked enough to repeat is "Python in Perl for people who can't bring themselves to write Perl code"
As commented somewhere else in this thread, Python was clearly more ergonomic than Python, hand had a lot of mindshare exactly for this reason. I remember when Python was new and the not that professional choice, Perl was at that time for that niche. Now still I don't see a contender for a language where speed doesn't matter. Ruby has some Perlisms that really make it weird, PHP is tight to the web, and equally weird, these $s and @s are really bad for normal people. Python wins clearly when teaching somebody programming.
I’d say that Ruby and even Perl are a lot nicer for scripting than Python (due to the extremely low-effort unix interop). Python can do it but it’s a while lot more verbose and difficult for a beginner to learn than “anything inside a pair of backticks is run as a system command and you can interpolate variables”.Pythonwasfriendlier for beginners than Ruby the first time I took a real stab at learning to code during a CNY holiday in 2008, but it wasn’t about the language itself. Ruby was harder then because many of the popular libraries and many of the tutorials were written by people who considered Windows support as an afterthought. It’s hard to express how frustrating it was to have my vacation days ticking down, hitting issues in one tutorial after another and having people suggest I install linux on a VM (a process where I hit still more snags).People learning Python and PHP didn’t hit that hurdle. I ended up learning Flash on my Asus laptop a couple of years later and getting my start that way and not coming back to Ruby until six years later when I was a much more experienced dev.
> Why isn't Perl as popular as Python?Perl was significantly more popular at one point, but it slowly lost traction while Python gradually gained traction over the years.Better ecosystem for numeric computing is definitely a big reason for the success of Python, by the question is why Python gained a foothold in that niche in the first place. It think it is because Python is just a lot more accessible to people with different backgrounds. Perl really grew out of shell scripting as a supercharged alternative to Bash and Awk, but retaining many of the quirks for familiarity. Python on the other hand grew out of research in teaching programming to beginners.
This was already posted athttps://news.ycombinator.com/item?id=35000415, I don't know why it didn't detect the duplicate. I'll repost my comment from there:This is a strange article. It's got the talking point about Python that we were hearing about 10 years ago - "tired of those pesky curly brackets in Java, try this new language you might not have heard of: Python!". Who reading the GitHub blog has not heard of Python?Also, that snippet used in the "What is Python commonly used for" section is strange:import antigravity
  
  def main():
      antigravity.fly()

  if __name__ == '__main__':
      main()It's overly verbosely written (especially given the example just above about how you don't need main function in Python) and refers just to an insider joke/Easter egg. I can't see that it's going to convince anyone to try Python, only make them feel that they're on the outside of a joke.It then ends with what seems like it might have been the point of the article, an advert for Copilot. It seems the way to get started writing Python is to write a short comment and then spam <TAB> and let the AI auto-complete your project.(Also, and perhaps less importantly, looking at the author's GitHub profile I can't see a single instance of Python there. Though I'm not doing a deep-dive as that feel overly picky and there's plenty of private contributions that could well be Python.)
I read the article and had the same feeling that it's a fluff piece without substance. If you've to compare anything, compare it with the vibrant JVM ecosystem. Using the same tired argument of `System.but.Println()` shows the author has no original idea. Python is great but JVM is no lackey, it is a marvelous piece of battle tested engineering.In the end it is just an ad for Github products and not worthy of being on HN frontpage.
Agree, I thought it was a pretty low-effort article until I got to the end and realized it was just an ad for CodeSpaces and CoPilot.
I find CoPilot to be super useful, but I would not use CodeSpaces due to safety concerns and limitations in team management.
>It's got the talking point about Python that we were hearing about 10 years ago - "tired of those pesky curly brackets in Java, try this new language you might not have heard of: Python!"That was a talking point closer to 20 years ago, at this point.
Pretty sure I tried both Java and Python at the end of the 90s. So more 25 years ago.
You're right, I think I was caught out by the unending march of time :)
There's a joke I saw that goes like:1980-2000 = "30 years ago"
   2000-2010 = "10 years ago"
   2010-2023 = "Recently
> Who reading the GitHub blog has not heard of Python?The GitHub blog became a strange place recently(-ish). It went from a factual blog describing fancy new GitHub features and interesting technical stuff (as it was a decade ago) to mostly a place full of incoherent marketing fluff like this post (with some real technical content interspersed).
It's doubly weird, since the antigravity module doesn't have a fly attribute, and it "does its thing" on import.https://github.com/python/cpython/blob/main/Lib/antigravity....
Very suspect
Curly brackets or brackets at all aren't mentioned by name in the article - is that your interpretation of the first code example?IMO, that example is there to show that there's less required boilerplate required in python compared to java when doing the same thing. And, in particular, none of that boilerplate really matters to what you want to do - print hello world - emphasizing the point of python being simple.
The section that explains why python is good for AI talks about pybrain, a library that seems to date from 10 years ago. I’m pretty well versed in most ml frameworks and never heard of it. Last update to the website looks to be 2010. Weird to feature that and PyTorch as examples of ML libraries. No mention of sklearn which is vastly more popular
But I didn't typeimport antigravityI typedpydoc3 antigravity(Cue clip of industrial disaster in background.)
The antigravity part is probably a reference tohttps://xkcd.com/353/
> Hello world is just `print "Hello, world!"`SyntaxError: Missing parentheses in call to 'print'. Did you mean print("Hello, world!")?
That's because that issue of the webcomic is like 15 years old. It was true of the version of Python which was current at the time:https://stackoverflow.com/questions/6182964/why-is-parenthes...
Yes, I know. But some people still have the reflex from Python 2 and feel bitter when the error message says "I know what you want, and I'm not giving it to you."
It _is_ a reference tohttps://xkcd.com/353/, quite literally, as importing the module opens that link.
Eh, they're just a lot of ways to say "path dependence". Scripting languages are basically the same exact technology with respect to each other. In the alternate universe where numpy and scipy are, let's say, numruby and sciruby, wouldn't we be here asking why Ruby keeps growing?That's not a sales pitch for python, it's a sales pitch for the concept of a scripting language; it's like saying "you should really buy a Ford, it comes with four wheels".
I admit I have a blind spot for Python, because I use PHP in my day job, so when I need to do some scripting, I mostly use PHP. But admittedly Python is a lot friendlier than some alternatives (Perl, Shell scripts etc.), and more universal than others (PHP being mostly used for web dev), so that's why people choosing a scripting language for their tool/library tend to choose Python.
I use Python all the time both for my personal stuff and for some side-projects at work, so this isn't a dunk on Python, but honestly it feels like a circular thing: it's popular because it's popular.I wouldn't say it's friendlier than the alternatives, Perl and Shell scripts sure, but not when compared to Javascript, Ruby or Lua.Now, if you're talking about libraries, support, etc. then sure, Python wins hands down, but that doesn't make it a better language in itself. I'd say Ruby and Lua are a little bit betteras languages.But then again, I don't care much for the language in itself, so Python is enough for most of my use cases.
I read "it's popular because it's friendlier". PHP, Javascript or R are popular, but are not friendlier. I find their error messages way worse for the beginner, when you need it more. Third party code is too "clever" for the beginner to read and learn, because it seems to be two languages: the one you are learning in the tutorials, and the other idiom that is used in the serious libraries. As a beginner you are hit with this feeling that you are far, far away from writting an useful thing.In my job I've seen some beginners starting with R, and quickly hating it because they don't feel they can do much on their own, but copy-pasting and then modifying from the examples and the tutorials. And it the changes go too far, everything collapses with cryptic errors. When you show them Python as an alternative, pointing that they shouldn't use it over R for statistics and graphics, they like that they can build ideas from the scratch. That beginner is hooked for life.
I think Lua was always seen as a bit obscure, and not enough people invested in the language to write useful utilities. It has a solid C foreign function interface, and the compiler is quite fast, which leaves me puzzled about why it never gained traction. I think it's an embedded scripting language in the majority of use cases (e.g. NeoVim, LuaLaTeX, scripting in some game engines).The story of Ruby is altogether different: they made the fatal mistake of not defining a C foreign function interface in the standard, otherwise I imagine we'd be seeing numerical computation and ML libraries with a Ruby interface today. Still, Ruby lives on in Metasploit, and in Sorbet and Crystal.
> I think Lua was always seen as a bit obscure, and not enough people invested in the language to write useful utilities. It has a solid C foreign function interface, and the compiler is quite fast, which leaves me puzzled about why it never gained traction. I think it's an embedded scripting language in the majority of use cases (e.g. NeoVim, LuaLaTeX, scripting in some game engines).- Lua's standard library is so weak that it makes most other batteries-not-included languages look like they have large, robust, and helpful standard libraries.- It's got a bit of the quirkiness and gotcha-ability of JavaScript but without its being a language that's impossible to avoid due to capture of a mega-popular platform, which is what propelled JavaScript to ubiquity despite its being kinda shit and unpleasant to work with.- Tooling's not as good as many other languages.(FWIW sometimes I write Lua regardless, because it's the right tool for the job)
> The story of Ruby is altogether different: they made the fatal mistake of not defining a C foreign function interface in the standard, otherwise I imagine we'd be seeing numerical computation and ML libraries with a Ruby interface today.This to me is extremely plausible, and sad.
Luck of libraries and initial userbase are certainly involved in success, but not all scripting languages are equal. I mean we could add bash to that list then.In fact I'd argue that python enjoying the success it has, despite probably the worst handling of a version bump in any language (2->3), is a testament to its popularity.
The worst version bump ever seen was Perl 6 which literally became another language (Raku).
Why did Rails get outcompeted by newer (and also some older) alternatives in the long run, when numpy and scipy did not?Ruby would have a much bigger market share these days if library path dependence was that powerful.
> Why did Rails get outcompeted by newer (and also some older) alternatives in the long run, when numpy and scipy did not?Chiefly, because big money corp invested massively elsewhere.Also by now it’s easier to find developers who are cheaper and already (only can) use javascript/python?I think that actual technical merits are dwarfed compared to other forces at stake here.
I think that experiment is taking shape with Elixir:https://github.com/elixir-nx/nxI don't see how it could ever overtake Python, but it could establish itself as a viable niche alternative.
I think one reason for Python growing popularity is because it's become the default tool in some domains whether it is the best tool or not.This week our Director ordered a total rewrite of two years of work in Python. His rationale: it's what everyone else uses in this space. No reason specific to our use case, just simply to follow the herd. I realise that a large community translates into easy hiring and rich ecosystems, but I despise the mentality as it promotes a monoculture.
... and Python _became_ the default tool because the de facto developer consensus (after years of competing languages) is that an interpreted language should= be usable, and 

    = provide a set of data structures that an educated programmer *expects to find when scripting*.Python literallysucked lessthan the alternatives.
Python gets introduced to students, so for many people it's the first language they learn. Half the programming community have less than 5 years of experience. I question their ability to evaluate suckage, lol.
That's a terrible idea for so many reasons
What are you rewriting from? At director level focus is usually more on things like how easy is it to staff / get support for something. Python is strong here - you can find programmers globally who can do pretty well with it.Can you say the same about your solution?
If Python was a market, this would clearly be the top.There was a time when all you had to learn was Java or C++ or (language or tool here). Somehow, this time when we standardize, it will be different.
It's really funny that one of the subheadings under "Why is Python so popular?" is "It has high corporate demand."
That's a perfectly relevant thing, no?
Yes. The entire reason I like using Java at my day job is that the rest of the company uses it the most and supports it well. I would never use Java on my own, but that's a different situation.
It reads as a little bit of a tautology. "People are using it because people use it". I get that from a hireability standpoint it's a real thing to consider, but the statement doesn't say anything about whether or not Python is actually a good language touse
Another counterpoint to this. Rust is a popular language (debatable claim, of course) but it's not high in corporate demand.
Agreed. Coincidentally, I resigned the day before this was announced.
Sorry if it sounds too cynical, but that's probably the intended effect of a rewrite from what the team knows into Python: staffing changes. A bunch of the (expensive) old guard will leave and they can be replaced with cheap grads, who all know Python.Better luck with the next one!
I have been a heavy Python user now about 15 years, but for me now I'm increasingly reaching for modern JavaScript and particularly TypeScript to do the things I would have traditionally done with Python.ES modules, fat arrow expressions, and all the other nice new syntax and library features have made the language so more pleasant to use. In many ways the ergonomics of TypeScript in particular are far superior to Python now, and I find that really surprising.I haven't yet found a replacement for Django (particularly the ORM/Admin/Forms combination) it is just so incredibly productive to use. So, I don't think I will be moving off it, but it's certainly not the growth language for me anymore.
I am going this way too. I recently tried to onboard a few contractors with limited python experience. It took several deep sessions to work out why they couldn't get an environment set up. After 10+ years I've never come across the install certificates command. There's still no way to get a dev environment with a specific version of Python working with one command that works reliably everywhere. pyenv isn't even packaged for Linux, you have to install from source.This, plus Typescript's superior type system makes it very tempting for application development.However I'll probably wait until there's a really good Jupyter Notebook equivalent...
No need to wait, there is a Javascript kernel for Jupyter Notebook:https://github.com/n-riesco/ijavascriptI used this for interactive debugging AWS API calls using the AWS Javascript SDK. It worked great!
> There's still no way to get a dev environment with a specific version of Python working with one command that works reliably everywhere.Closest thing to this is Docker nowadays. It's so annoying. npm just works.
> However I'll probably wait until there's a really good Jupyter Notebook equivalent... 
Ha, take that Observable! >:)
I don't mean this to be insulting, but I find it really strange that you find TypeScript more pleasant to use than Python!
Oh, I wouldn't say TypeScript is more pleasant than Python, but it is more pleasant than old JavaScript. But I increasing precise the productivity I have with TypeScript and some of the ergonomics than Python.I still love Python. Just feel like I'm cheating on it with this new younger model...
> I haven't yet found a replacement for DjangoTake a look herehttps://adonisjs.com
Same. I analyzed a little why I find JS (I don't like TS) easier to deal with for some tasks:- Particular support for web frontends or backends, both very broad categories.- JS concurrency is easier to deal with. Focused entirely on promises with the nice async/await syntax on top, unlike Python which slapped on too many different ways to do this.- By far easier package management and imports. Python's is so annoying that any project you download is gonna have you spin up a Docker container for it.- ES6 added a lot of array/etc managing that JS was lacking before.- Freeform objects with {key: value} syntax are convenient, despite maybe seeming weird at first. Python OOP somehow got really complicated over the years.- Inline functions (I use fat-arrow but regular way is also fine). I never got why Python, despite being common in function-oriented programming, didn't let you do an inline def.- Curly braces. Indentation shouldn't affect logic flow.- No Python3 vs 2 drama.Specific use cases have been Express backends with node-postgres and lots of SQL, and React (or RN) frontends.
Python 3 vs 2 drama is from 5 years ago.  It's just python 3 now.
"Python 2 is unsupported by the Python Foundation since 2020-01-01" according to Debian docs. Ubuntu defaulted to Py2 until around then. So I'd say that's when the drama ended, then again it's probably not the last I've seen of Py2.
If you're looking for a Django replacement, check out Adonis. Laravel in PHP was heavily inspired by Django but is much better and Adonis is an exact clone of Laravel. I think you'd like it.
The article assigns significance to the language when the real work is done by the libraries. And many good libraries inspire even more good libraries. At that moment the language no longer matters. But it matters in the beginning when people have to create the initial environment and this is what should've been underscored. Python lets you do so many things in so many ways that minor mistakes do not matter and everyone has the freedom to experiment, achieve results, discover that they've done something stupid, but at that moment you already feel confident to do it again, but better.
5his is right in the spirit of: The Python community is a bunch of people learning programming together.Someone else made this remark once, when the indroduction of type annotations was discussed as the python community discovering the benefits of static typing.
I'd been in the Python community for around 10 years, spoke at several conferences, wrote libraries; contributed to CPython, Openstack, and others. I've been a technical reviewer for a book on distributed computing in Python. A big part of my career was built on this language, its community, and ecosystem. I'd say a big part of Python's slow-and-steady success is its community. Going to Pycon US, Pycon CA, and Pycon's around the world -- the user groups that the foundation funds with Pizza money and mentorship programs: it's a fairly unique experience.Another major factor is how it serves as a glue language in the scientific community. Python provides a relatively simple programming language that powers complex, powerful libraries like NumPy, SciPy, PyTorch, SymPy, etc. It's like a scripting language for engineering and scientific computing tools, sort of like what Javascript does for browsers, Node, and Deno, etc.I don't do much Python programming these days but I owe it a huge debt! May it continue to flourish and grow.
The syntax, I think, is also the least likely to scare off newbie programmers.  Personally, I came to really dislike the Python syntax, but it reads rather well, is very unintimidating, and easily supports the kinds of things that newbies will be doing.Not to rag on Python, but I found the indent-sensitivity of Python can make it challenging to do the sort of basic things that C-family languages make fairly simple.  Lambdas in Python suck in contrast to how lambdas and anonymous functions work in other languages.But yeah, Python has proven itself to be a great language for a wide variety of applications.  It makes a lot of sense for the scientific community probably because things like heavy object orientation matter a lot less in those cases.  The community doesn't discourage people from just writing functions, unlike other communities that are hellbent in making everything a method of some class structure and being explicit about that.
Comparing Python to Java 8 and saying it’s more readable isn’t showing much.And it’s not very portable the second dependencies with native code (which is common since pure Python is too inefficient for many tasks) are used.I think Python is popular for two reasons:- it’s believed to be beginner friendly compared to other languages. I’m not really sure why - maybe the whitespace?- it has an enormous set of libraries available to useIn other words, Python has momentum. The language itself isn’t great, but that is a secondary concern to most, if they are even aware of this at all!
I started in Python, as a Biologist (hooray for Jupyter-lab, coding so visually, in small steps, with output just there is so great when starting to learn Python). I ventured into other languages every now and then. For example I tried to make an Android app in Kotlin that gets info from some API. I expect something like this but with more brackets everywhere:import request
   
    data = request.get(https://some.api/get_some_json)
    some_value_I_want = data['dig']['into']['nested_structure']I didn't get it to work at all, I was lines and lines of code into the program when I didn't even get to see any returned values.Also, say I want to make a nice plot of some tabular data (.tsv), I do:import pandas as pd
    import seaborn as sns
     
    data = pd.read_csv('some_file.tsv', sep='\t')
    pd.melt(data, value_vars=['s', 'max_vms'], id_vars=['sample', 'process', 'N'])
    g = sns.FacetGrid(data=data, col='process', row='variable', hue='sample', sharey=False, margin_titles=True)
    g.map(sns.barplot, 'sample', 'value', order=data['sample'].unique())Boom, what a plot (or large grid of plots actually), so much information. Can anyone show me how to do this in some other language (but R)? Idk, maybe I'm just not so smart, I just learned to program at 35 after always being a biologist, but any venture into any language has me thinking: Why does this have to be so complicated?(Btw, I'm putting 4 spaces in front of the code, why is it not rendered as code?)When I just started I used Python to read, sort and transform images and output them to a PowerPoint file. One can use CSS like synthax to format the slides. Boom PPT with 120 slides with images and data from some Excel file that convinced a lot of people with a lot of data that fluorescent images next to H&E stains + metadata can be nice. Is it the best way to present such data? Meh. But man was it cool and easy and time saving.
This is just a property of having libraries. If you've got the same libraries in Java then the code looks identical except that you stick to word "var" in front of lines 4 and 6 and you don't have named arguments.Pythondoeshave a great data processing ecosystem. But that isn't really a property of the language.
Creating a new venv, installing a few needed libraries that you know the names of with a simple command and writing a quick low-ceremony script that uses those libraries is frictionless in Python. Doing that repeatedly in nearly every other major language is not as easy.Some languages have a good integrated tool chain (Rust, Go) but are not as approachable and forgiving.Some are approachable but lack the friction-free story for locating and installing 3rd party dependencies.
The most similar language to Python is Ruby, not Rust or Go, and Ruby is better at the things you've listed. Which would bring us back to the previous point that it's not actually about ease of use.Someone else identified Ruby's fatal flaw as not having good C tooling, and I think that's probably accurate.
Ruby has odd, once unique syntax that looks strange to anyone raised on C-like syntax, including js and java.  Python is similar, simply removing redundant braces.  So no ruby was not better at things most folks care about, i.e. being easy to learn.
You seem to have confused personal familiarity with ease of learning.
Things that are familiar are easier to learn, it’s a fact.  As someone raised on math and English notation, then industry exposure.  Ruby being a odd duck did it no favors.Python definitely found footing based on its  pseudocode readability.  It’s  gotten a bit worse recently with too many colons and features but already made it.
Poetry is indeed very nice for that. Bit of a learning curve but then very easy to push packages to PyPI or internal things like Artifactory.
Your examples don't depend on the language but on the libraries. You can be as simple and concise in most languages, provided the libraries let you, instead of needing to add boiler plate.But what if your web request fails? Do you deal with it in time or use some_value_I_want which might contain junk?
I think you are confusing familiarity with ease of use.
Ok, then I'm not programming. Call it anything you want, I call it "Being productive." Or, "Saving on time spent clicking around in Excel." or "Automating the boring things." And I find it to be quite pleasant.Maybe it also doesn't help that out there, in the C++, Rust, Javascript, Go world I'm going to run into people with usernames like "ihatepython".
Don't feed the trolls! Case in point, this is a quote:quote_from_user_ihatepython == """
    ihatepython 1 day ago | parent | context | prev | next [–] | on: Moscow Metro  
    launches longest metro circle lineYou realize that the Nazis still exist and are Ukrainian, right?"""
Sometimes I wish for "block" function in HN for such trolls (I really hope it's no-life troll working for 5 rubles per comment and not a real person with genuine hateful opinions like that).
This isn't really programming though.It is however what a lot of people who 'program' at work do every day. Python actually lets working professionals solve real problems they actually have at work quicker and easier than any other programming language.
"That's not programming, that's just calling libc with an unpleasant interface"
Ironically, TFA claimed there are a bunch of people “not programming” in python getting real work done out there.But, with a user name like that, I know I’m just wasting my time responding to you.
> - it’s believed to be beginner friendly compared to other languages. I’m not really sure why - maybe the whitespace?I am leaning more towards it looking like pseudocode> - it has an enormous set of libraries available to useI believe that to be the actual reason. I've long held that python is a kinda bad language, but with FANTASTIC libraries
beginner programmers don't know pseudo code either though!the best teaching language (imo) is one with few features  or surprises. I think Scheme might come out top here.
I think Scheme might come out top here.Depends what you are trying to teach. If you're trying to teach computer science and programming fundamentals, then sure.  If you're trying to teach people how to get 'real work' done quickly and efficiently then Scheme will only get in the way and slow people down.For example when I've taught programming, one of the tasks I taught fairly beginner programmers was to grab some satellite images between certain dates, try to detect if there is a forest fire, measure the spread of the fire and plot the spread on a map.With python (and its excellent libraries) this is quite quick and easy, and most people are up and running and hacking around with their programs in pretty short order. They find it really cool and inspiring and makes them quickly realise that programming could be something useful in their day to day job. Trying to start with chapter 1 of SICP and Scheme and working up from there to solving the above problem would probably lead to most of these people giving up on programming very quickly. That being said the few people that made it all the way through that would no doubt be much much better programmers because of it.
And fantastic documentation!
This is an under-discussed point, at least from my biased opinion. It seems like the Python documentation ecosystem is the best, and has been building fantastic tooling for over 10 years now.
Eh, you massively overestimate the importance of performance.For the vast majority of use cases, performance just isn't a priority. Doubly so for Python, that shines for simple automation, command line applications, and perhaps some serveless computing.Being easy to write, having a good ecosystem of libraries, and being widely known is typically good enough. I wouldn't use Python to write a robust backend server side application, mostly because the language doesn't lend itself well for it.
Eh, you make incorrect assumptions about me. I'm stating a fact why Python is used - the data science ecosystem in Python thrives because of well-written libraries _written in C_ under the hood AND an easy-to-use language that writes like pseudocode.If it was too slow, we'd be doing all of this in Java, the C# or maybe doing it in C/Fortran. But because of some early design decisions (Guido being on the matrix-sig helped), the history behind Numeric/Numarray and finally NumPy and SciPy being based on those efforts allowed it to thrive.
>  it's the only way a tragically slow language like Python can keep up.Those were your words, not mine. I need not make any assumptions.I just replied listing use cases where Python shine due to its strengths, performance being mostly irrelevant. I didn't even mention data science.And although it's beyond the point, if I was to use Python, why should I care in which language a library was written? If the language allows libraries written in other languages, this is actually a nice feature.
> If the language allows libraries written in other languages, this is actually a nice feature.That’s actually my primary use case for python, playing with  C/C++ libraries in a repl because they don’t natively have one.Sure, it takes work to wrap a library but that’s something I enjoy doing.
libraries written in CThat is simply not true. Even libraries like numpy, scipy and scikit-learn are majority python code.
Majority python code, being ~60% is mostly wrapper code, with the slowest parts (the parts that matter) written in C.https://stackoverflow.com/questions/1825857/how-much-of-nump...
Don't forget about FORTRAN
Does it matter?
>- it’s believed to be beginner friendly compared to other languages. I’m not really sure why - maybe the whitespace?Good bait. I'll take it.- dynamic, weak (really "duck") typing, meaning users don't have to worry about conversion between things. Want to print() a dictionary of whatever? Sure!- no semicolons to terminate a statement. End of line, that's it- rich standard library, so you can actually get going on things without having to go on a quest to find the right library for your thing. JSON? It's right there. argument parsing? argparse. Http? http.client works...- also yeah the "pseudocode" thing. Python is light on extraneous syntax.Now eliti^H^H^H advanced programmers will frown on many of these same things that make it beginner-friendly...Dynamic typing means that complex designs have to be careful with their APIs, lest you can get tangled up in deep type errors if you're not careful (I particularly hate the "mix-in" pattern). No semicolons mean, uh, long statements need to escaped? The standard library is "where lib go to die" because they can't evolve as much. "Significant whitespace!? What is this, COBOL!?!11"
Static typing had a tighter feedback loop - you don't even need to run the code to see you made a (type) error.Ability to do structural printing of arbitrary structures is not restricted to dynamically typed languages.However, I actually think a good beginner language could be dynamic or static.
> it’s believed to be beginner friendly compared to other languages. I’m not really sure why - maybe the whitespace?Experienced programmers tend to forget how the experience was as a beginner programmer. But Python grew out of actual usability research into teaching programming to beginners. Logo is another language with the same background, but it never escaped that niche. The success of Python is because it attractive to beginners but remains a powerful tool as the programmer becomes more experienced.Whitespace is definitely a factor - or rather the lack of redundant braces. Beginner programmer seem to really struggle with the lack of correspondence between the visual structure and the logical structure in most languages. Even experienced programmers get tripped up by erroneous indents. Python just solves this once and for all.The lack of type annotations is also a factor. For beginners this is just an additional layer of complexity.Scheme is great for teaching computer science students, but if you are just a regular Joe researcher wanting to get the job done, you want to write "2 + 2" like everybody else in the world, not "(+ 2 2)"Most languages are designed to attract experienced programmers, e.g. by having C-like syntax which they may already be familiar with. But it has a cost for beginners.
The classic"public static void main"example is also getting old. It's been so long since I last wrote it, that I actually had to copy/paste it from the article. I just generate a new project from the "Spring initializer" plugin and jump straight into the real work.If we want to measure developer productivity we should try to compare actual real world usage that goes beyond "hello world" using Notepad. The author did provide more examples in the article, but I think we should just retire the basic minimal hello world example for these types of discussions.If their argument is that Python is simpler for quick scripts and programs, I agree. The same applies to ML / AI where Python has lots of great tools. Once you start looking at other areas (Django and FastAPI), there are many alternatives based on other languages where you can be just as productive.Most of the time consuming work is spent doing business logic where the differences between languages doesn't matter as much. They all have advantages and disadvantages. Personally I prefer static typing for larger projects and teams.If their argument is that Python is better in general, they need to provide better arguments.
A third point is that python is the default scripting and plugin language in a lot of popular commercial and professional applications. A lot of people I know who learned python did so to automate or extend applications they used for their 'real' work, like ArcGIS, FME, Rhino/Grasshopper, Revit/Dynamo etc.
Indeed. I wish Microsoft would push F# as the default macro language for Excel.
Python's biggest advantages are in my experience:1. Near zero boilerplate. Python's boilerplate is usually no more than setting up a class and then calling a method. Often you can skip the class and just call it directly. This is probably the biggest strength; to give you an example, my standard test for a languages approachability is "how much work do I need to put in to get a very simple JSON file from a web URL" (nothing fancy like POST, just an HTTP GET). With python, a call to urllib.request.urlretrieve and then a call json.loads are all you need. In Java, you need to manually implement a bunch of boilerplate code that looks horrible, need to think about the size of your response in memory and often need to pass in configuration options thatshouldbe a case of "works by default" but aren't because the standard is ages old so it needs to be manually toggled on. Part of that is that the Java stdlib consists largely of reference implementations rather than actual implementations, which means that anyone who wants to implement something in Java will usually end up falling back to the stdlib interfaces, which in turn suffer from being stdlib interfaces, so a lot of "should really be on by default" expectations aren't on by default since the stdlib is where code goes to die, so you instead start piling on features.2. Interop with C. I hold the opinion that C is a great language that doesn't work very well once you get to any form of scaling. Python allowing developers to take the slowest parts of their code and writing it in C to speed it up is one of the easiest speed gains to make and it avoids the biggest bumps that come with using C as your primary language in terms of project structuring.3. Library support is as you say, good. If you need it, there's probably a package for it. Pypi is dependency-wise kind of a disaster but if you know how to set up requirements.txt, it works really well. Most libraries ship with "sane" defaults too.All of these combine to a language that's easy to prototype, easy to expandIt's important to keep in mind that pythons biggest successes aren't in the speed-focused, low-memory environments where every speedgain is necessary. Its success lies in conventional desktops and servers, which have much more processing power and often have more leniency in being a bit slower.With python you can write something in 3 hours what would take a day in another language, at the cost that instead of being lightning fast and done in 10 seconds, you need to wait 30 seconds. That's an issue forsomeenvironments but in 99% of the cases that's not a problem.That isn't to say the language is perfect (no language is), but speed of development at the cost of slightly slower execution time is the main reason why python got popular.
>"how much work do I need to put in to get a very simple JSON file from a web URL" (nothing fancy like POST, just an HTTP GET). With python, a call to urllib.request.urlretrieve and then a call json.loads are all you need.In C# you just have to do this:
var things = await httpClient.GetFromJsonAsync<List<Thing>>("url");
why would an http client know anything about json?  that's a bad code smell.
It doesn't.  It's a standalone (static) helper method that uses HttpClient to perform the request and feeds the response body into a json parser.  It's an extension method [0] which means that there's syntactic sugar so that you can write client.GetFromJsonAsync() and the compiler transforms it into the actual static method call, HttpClientJsonExtensions.GetFromJsonAsync(client).0:https://learn.microsoft.com/en-us/dotnet/csharp/programming-...
Mostly because JSON is one of the most common formats used when sending over data. I think this practice started with pythons requests (which is my real answer as to what you should use in python but I wanted to focus on the stdlib), which has a json function on the Response object for convenience.Most languages nowadays tend to implement some variation of this specific convenience because it's just one of the most frequently needed things; setting up a separate parser and then calling it might be the "cleaner" option, but it's also more boilerplate and the industry has largely moved to try and avoid that.
Java programmer, recently switched to using Python in the job - This exactly is it. Sane defaults is the killer feature of Python.
I agree comparing hello world code in Python and Java is a bit pointless. Hello worlds might be much shorter, but at scale, this becomes less relevant. Also, comparing to a language that hates change is unfair, if you compare it to C#, which is improving over time, you'll see the hello world also takes one line (but is 13 characters longer, so Python still wins!)
> if you compare it to C#, which is improving over time, you'll see the hello world also takes one lineWell yes it it doesnow, since C# 10 or, but in Python is have been a one liner since the beginning 30 years ago, and over the decades it has build a following. And even with recent efforts to cut down on boilerplate, C# still has more cryptic syntax than Python.I'd argue C# is more maintainable in the long run due to the static typing, but there is no way it is as accessible to beginners.
> Comparing Python to Java 8 and saying it’s more readable isn’t showing much.It shows an obvious reason why a lot of beginners choose python, even when learn Java basics in university first.
I remember the evolution of Python. When I started with my brand new Ubuntu installation when Ubuntu was also very new, there were two languages, Perl and Python. Because Perl was more popular at the time I check some books in the library, and wrote some scripts. But already then the consensus was, that even though libraries are lacking (!), it is the better, cleaner language. Another big push was the bad enterprise guys, that like static typing, so C, C++, Java, vs. the hipster dynamic language guys. Some tenets were broken, speed is not as important as language concepts, that enabled fast iteration. Agile was new, and Python was very agile. There was no real alternative to Python at that time, that was as sane, and beautiful. That's the reason why we have now such a nice variety of libraries, because it is just a sane language to build on, if speed is not your business. Ruby was a contender, but not that much better in the end. Now Javascript kind of took the edge away from Python, even it wasn't for the browser and the web, Python would dominate much more. Javascript as a language is worse than Python because of its cruft, so I don't see a big rewrite of ML tooling into Javascript. Maybe Typescript.
Perl was very popular and I think Python got its boost from being seen as the more sane replacement to it.  At that time nothing else really offered to solve the pain of Perl in the same way except Ruby and Ruby was even slower
I learned Perl first and found it incredibly useful just because of regexps but Perl programs got messy as they got larger. Python regexps are just that bit less convenient and that trivial amount matters but in python I feel that once you get to writing functions and perhaps even classes it accelerates far ahead of Perl and you can write understandable, maintainable large programs in Python.You're not forced to dip into the OO side of things though and I've heard people suggest to me that Python is a language where no rules apply and no structure exists.  They feel that they can dive in without the care they would have to take in Java or C++.  I think they are very wrong but you can certainly write terrible code if you want and perhaps this "all-things-to-all-people" aspect of it is part of the success.
Well said.  The core to Python’s success, for me, has always been its system for containing code inside modules and for importing and exporting symbols between those modules.Understandable code is maintainable code.  Abstraction makes comprehension possible — imagine if every call toprintwere an inline block of assembly instead! — and Python’s modules provide a very quick and easy way to break up large code into small modules.
It's interesting that people keep claiming that indentation-based blocks makes Python easier to learn and read. I've been teaching programming to students in banking, finance and insurance for a few years, using Python, and my experience with them is the opposite. They have been struggling with that a lot. They didn't pay too much attention to white spaces and tabs, probably because they are "invisible", and couldn't see why a statement was not executed at the end of the block, because it was not indented correctly. For me, it was obvious, because as a professional programmer, I've been trained to pay attention to details. But for most of them, it made no sense. Explicit block markers are much easier to teach.
On the other hand, back in college I was a TA for an intro to programming course that used Java.  This:> They didn't pay too much attention to white spaces and tabs, probably because they are "invisible"can get so much worse than people imagine, when the language doesn't enforce it.  It was that experience that made me lean towards python being a good introductory language, to help people get used to correctly indenting code in general.
Agreed. Zig for example is considering triggering an error for incorrectly indented code/misleading indentation:https://github.com/ziglang/zig/issues/35
> Explicit block markers are much easier to teach.The point of communication is to express something in a way that the listener understands it. Simply expressing something that is comfortable or normal to the speaker is simply not useful for either party of the goal is communication.
You're right. What matters is that explicit block markers are easier tolearn(from the student's perspective). Being easier toteach(from the teacher's perspective) doesn't matter as much.
Sure, but without the white space defined blocks it is entirely onyouto teach them about the importance of formatting their code to ensure readability.
That's right. That's the other side coin. But I'm not convinced it matters that much nowadays when most languages provide code formatters.
My point was to express that your students need to learn to communicate with the programming language in a way that the language understands, not in a way that is comfortable for them as the “speaker”. You as the teacher should be setting that expectation.
Code is still completely unreadable with explicit block markers, if it is without appropriate indentation and newlines.  That's like trying to read minified javascript. And python forces you to have these, to some extent.
I used to think the same, but go fmt totally changed my mind on this. Most languages now have a code formatted that is integrated in all popular text editors and IDEs.
I agree. Beyond go fmt, I'm a huge fan of terraform fmt (for terraform) and `black` for python.
IMO, the thing about beginners and relevant white space is that it forces them to learn how to indent their code, not that it makes it any easier to learn the language.
My go-to language is C++, although I know and have admired Python for a long time.I had a BMP file which I wanted to transpose and turn into raw RGB 5-8-5 values.  Using the Python Image Library made things absurdly easy.That's Python's advantage in a nutshell. Things are just so absurdly easy.
Python is the ideal glue layer for low-level languages, now mostly Fortran/C/C++ but there are already many projects exposing Rust libraries through Python, which for me is a great combo of performance and usability.
Sure, but that's because there was a good library available, little to do with Python vs C++.If there was an equally good C++ image library available then it would have been equally simple in C++.Of course the thing is that, in general, there may well NOT have been such a C++ library, and this is what makes languages such as Java and Python popular - because of the breadth of libraries available.For C++ image manipulation I've found libvips to be decent, but the point still stands that for a given problem there may not be decent libraries available.
And yet, GitHub seems to be in no rush to support Python in GitHub Packageshttps://github.com/orgs/github/projects/4247/views/1?filterQ.... This has been TBD status for years. Frustrating for anyone needing to manage private libraries and tools. And baffling, since Python is now the most popular language on their platform by most metricshttps://madnight.github.io/githut
Tangent: Something interesting (and frustrating) ... I went to the LinkedIn assessments to take the Python assessment and over half the questions were specifically about Numpy, it's API and matrix math. Which for me and what I generally do has nothing to do with "Python" and I was quite surprised to find that in the questions.
In my search for a senior Python developer I have encountered dozens and dozens of resumes whose Python experience consists almost exclusively of Numpy and data entry. Not at all the skill set I’m looking for.
As a pretty experienced python dev who has never worked professionally with Django / Flask or Numpy, I have a hard time finding job postings without those seemingly hard requirements.
I'm curious as to what you've worked on in your career? I mainly ask because we are 100% Django/Flask. :)
It's been split between three areas - writing mathematical code that wouldn't really benefit from numpy, at least not at first (think engineering design codes - step-by-step calculations where the output has to be verifiable by a human; charts and graphs aren't the focus (I'm not at this company anymore)), writing testing infrastructure for a legacy client/server application that was designed around the time Ethernet was invented (well before I was born), and writing library code for my QA team to write tests for said application.Most of these domains are sort of document-oriented - for the math stuff, the hard part is just defining the model, and there is only one "thing" to operate on. For testing, the units of work are test cases and steps, which _could_ be database entries, but work better in practice as a document that a non-technical QA team member could edit by hand. Results are fed to a SaaS that keeps all the historical test result data.Not that I couldn't pick up either one of these tools and use them (I'm a mechanical engineer by training and got into Python because I didn't like using Matlab/Octave), I've just never needed them professionally. But that doesn't get me past the resume filters :(
Appreciate the response. Thanks!
Are you calling the job 'senior python developer'? I haven't used any other language (as the primary one anyway) professionally (and I'm open to that remaining the case) but I probably wouldn't even open such a job description.
It's a fine article and makes many of the standard points. But I would expect a slightly more data driven analysis from GitHub given the large amount of data available to them. For example, what percentage of first repositories (new GitHub users) are in Python? What percentage of GitHub Python repositories use a data science library? Etc.
They don't mention that Python makes it really easy to interoperate with other languages via the subprocess module.  So you can run Javascript web code via node, wait for it to finish, then move on to something else. Or you can launch a C++ process that's can do real parallelism and wait for the results, avoiding many issues with the Python GIL.Also, Python makes it easy to work in different programming paradigms, it's as easy to write functional-type code as it is to write object-oriented code, both approaches are supported.  This makes it a great prototyping system if you want to rewrite the code later in some other language like C++ to get some performance improvements.
> Python makes it really easy to interoperate with other languages via the subprocess moduleLaunching processes and interacting with them through stdin and stdout is a bare minimum, and really a flag against the few languages that make it hard, instead of a relevant feature.> Python makes it easy to work in different programming paradigmsAs long as you stay in imperative, non-pure, structured with optional OOP and first classes functions. Again, that's not much in multi-paradigm. This is the set of things that work well with the imperative model.
What languages make it difficult to spawn other processes?
I just wish that I enjoyed using it. I've been doing a fair amount of Python work over the years because it's been required by my employers, but to be honest, I kind of hate it.I think the thing I hate the most about it is that white space is significant. It's like we travelled back in time to the early days, and picked up one the bad things about them and brought it back. I find that makes it more difficult for me to read, and more difficult for me to write (from a mechanical type-in-the-code point of view).I have other niggling issues with it, but if the white space thing weren't an issue, I doubt the other issues would bother me enough to complain about them.
Slashdot called and want their comment back, haha!  Whitespace blocks significantly reduce redundancy and are quite elegant imnsho.If you’re having trouble with them, use a programmer's editor  with indentation guides like notepad++ or geany.  These are considered basic features these days.Other simple things which reduce Python annoyances are tools like pyflakes and the blue formatter.
We disagree about whitespace blocks. That's fair.> If you’re having trouble with them, use a programmers editor with indentation guides like notepad++ or geany.Yes, of course. Python makes that pretty much essential, which is one of my complaints about Python. A language that requires a special editor is a language that is deficient, IMO.There are a ton of other, more minor, aspects of Python that makes it unpleasant for me. It's not just the whitespace thing. That's just the one that grinds my gears the most, because it's the one that slows me down the most.But note what I haven't said here -- I haven't said that Python sucks. I only said that I hate using it, despite being pretty fluent in it and having used it for years.
It’s not required to use a basic editor from the early 90s, no… but it can help on a big codebase.  Why handicap yourself?  I make patches once in a while with nano/micro without issue.  Maybe your functions are just too long, dunno.A lot of folks can’t survive today without a giant ide awhile you advocate not to use something downright tiny in comparison.  Do you hate working with jpeg or blender files because they require software?  Rather move bits with a magnetic needle and steady hand?Admit I was put off by it for an hour or so as well.  One spring day in 2001?  That afternoon I realized it as a masterstroke and didn’t write another line of c, perl, or java by choice for almost two decades.Two ways to delimit blocks is redundant.  Either one indents already or the project is a disaster.
Again, just to make sure I'm being very clear, note what I said in my original comment. I wish that I enjoyed Python. I did not say, and don't assert, that Python is bad or that nobody else should enjoy it.I just wish that I did.> A lot of folks can’t survive today without a giant ide while you advocate not to use something tiny in comparisonI'm not advocating anything. I'm stating my personal preferences. But I also make sure that I don't rely on a giant IDE for any language. I use a couple of different ones at work, but I don't use one at home (even though my hobby projects are no less complex), because I've found that using IDEs encourages me to engage in poor programming practices. I amnotsaying that nobody should use IDEs or that they make people worse programmers. I'm speaking for myself. I want to deeply understand the languages I use.> Do you hate working with jpeg or blender files because they require software? Rather move bits with a magnetic needle and steady hand?Of course not. Those are not human-readable data collections are need a tool to make them understandable by a human. A programming language is supposed to be directly understandable by a human, though, and if you need a tool to make it so, that strikes me as a failure of the design of the language.> Two ways to delimit blocks is redundant. Either one indents already or the project is a disaster.Eh, each to his own. Yes, there is a redundancy there, but I think it's a redundancy that brings value and reduces error.
Belt and suspenders, eh?Not sure how well-known but many 3D scene formats are text, especially early ones.  Similar to svg conceptually, which many are familiar with.  At a certain complexity, writing it by hand is no longer practical and software support approaches  necessity.
This is very true. I do 3D printing, and am also very familiar with the fact that STL files are text files. I even edit them by hand from time to time -- but I still use software to manipulate them, for obvious reasons.It boils down to "the right tool for the job", of course, and like every developer, I choose my tools with an eye toward the goals I want to accomplish. That my goals and yours aren't 100% aligned is to be expected. We're different people. And that also means that at times, a tool that is appropriate for your use case may not be appropriate for mine. And vice versa.
>Two ways to delimit blocks is redundant.It isn't redundant though because without delimiting symbols for a code block you lose the ability to have your code autoformatted in certain situations. Here's a trivial example to illustrate the point:def example():
        x = 5
    print("Hello world")What's the mistake here? Depending on whether the print is part of the function, it should either be indented or have a newline before it. The point is you (and any formatting tool) can't know what the horizontal alignment of this code should be just by examining the vertical line order. You can only determine this by knowing (or reanalyzing) the semantics of the code. During a refactor where you're moving around lots of code, this can be a significant PITA. However, in the JS example,function example() {
        let x = 5
    console.log("Hello world")
    }it's unambiguous what the mistake is because you can determine the correct formatting entirely from the line order, without having to know anything about the code's semantics.
The first example is a syntax error, which must be fixed, and takes a second.  Not a PITA, just a part of normal day to day refactoring.I see how a formatter could help you out in this specific situation.  However you are trading typing of redundant characters every few seconds and readability per minute, to avoid an issue that happens once or twice a day, per week on a mature project.In other words we generally don’tsignificantlyreorganize code nearly as much as reading, tweaking, adding features etc.Readability is definitely a strength of Python, not a weakness.  A lot of this is because of reduction of required notation.
>first example is a syntax errorThe code runs so it's most definitely not a syntax error. May be against PEP styling rules, but it is valid Python code.>which must be fixed, and takes a second.And that was my earlier point. The responsibility to get the code in a state where it is formatted AND runnable falls entirely on you, as this work cannot be entirely delegated to software when the syntax uses significant indentation. And the fixing of the code would require you to reanalyze the code's semantics before you would even know what the appropriate fix is. Of course it would only take a second for a trivial example like the one I used, but real Python codebases aren't going to be trivial.>typing of redundant charactersIt actually doesn't require any additional typing as compared to Python. In modern editors the closing brace is automatically added when you type the opening brace. So you simply type the opening brace and hit enter, just as you would type the colon and hit enter in Python. Even the space between the closing parenthesis and opening brace in the function header is added automatically by formatters.>readability per minuteSeems pretty subjective but I don't think there's a significant difference in readability between Python and braced languages, or even between Python and languages that use block delimiters other than braces, like Ruby. A lot of readability comes down to personal familiarity with a language.>we generally don’t significantly reorganize code nearly as much as reading, tweaking, adding features etc.Totally agree, and I think this is one of the big problems of software development. People generally don't want to make big reorganizational changes to code and instead prefer to change the code only through additions. As a result, legacy projects tend to accrete layers of cruft over time whether it is necessary or not. I'm not a Jonathan Blow fanboy by any means, but I recently saw this clip which I think makes a good point.https://www.youtube.com/watch?v=ubWB_ResHwM
$ python3
    Python 3.10.6 (...snip...)

    >>> def example():
    ...         x = 5
    ...     print("Hello world")
      File "<stdin>", line 3
        print("Hello world")
                            ^
    IndentationError: unindent does not match any outer indentation levelSort of an odd video, haha.  But I liked the guy... think we could be friends.  ;-)It's idea is sort of neither here nor there however, regarding whitespace blocks.  That we "rent" more often than own is just a reality of the system we find ourselves in.  (For example cheap products sell more than expensive ones and that is expected and ok.)I don't want to optimize my projects around large refactors since I only do it a few times per project, but will read it often.
That's because the REPL has the additional restriction of requiring a definition (or any top level indented block) to end with an blank line. This restriction does not apply when running code from a file.
$ python3 foo.py
      File "~/Desktop/foo.py", line 4
        print("Hello world")
                            ^
    IndentationError: unindent does not match any outer indentation levelI didn't understand your statement exactly, but it doesn't seem to be true in any case.
The file:def foo():
     bar = 3
  print ('4')runs fine when called as a file but when pasted into Python's REPL results in an error:>>> def foo():
  ...    bar = 3
  ... print ('4')
    File "<stdin>", line 3
      print ('4')
          ^
  SyntaxError: invalid syntaxHowever with a blank line after the definitiondef foo():
     bar = 3

  print ('4')results in:>>> def foo():
  ...    bar = 3
  ... 
  >>> print ('4')
  4
I see now.  The issue was pasting the snippet into a terminal added an extra level of indentation from the post (pre must be indented).  This changed the result.
> Readability is definitely a strength of Python, not a weakness.I find Python to be on the lower end of average in terms of readability.
Because its easy.
Because it has an interpreter.
Because it has notebooks.
Because it has huge set of libraries & easy library import.
Because schools are teaching it.
Because a lot of cloud native tools support it / prefer it.
No, because academics or professors don't care about real software enginneering and best practices.
Well yes.
But if you pump out millions of graduates with almost exclusively python experience, guess what they write in production once they have jobs?
Try dealing with your corporate security team, who's detecting out of date Python versions.For the most part these update without much hassle, but now you've "broken"  your researcher's code. It takes them a while to fix this, and then the security guys find out that Python packages also need updated...
I used Python for the last 10 years or so for all sorts of cross-platform command line scripting stuff, but watching Python3's progress I have the impression that this simple use case is no longer their main focus (I sometimes wonder if there's any focus or vision at all tbh). After having tinkered with Deno for the last 2 weeks or so I must say that this is indeed the 'better Python' (for me at least, and not because of Typescript - the language is more or less just an implementation detail for writing command line utilities - but because of Deno's approach to package management).
Python has been my favorite for products and scripting. I've been advocating for Python's dominance when the world was after Java. But now I'm more inclined towards JavaScript. And agree with you Deno is taking the right approach (as opposed to nodejs).Having JavaScript in the front end and backed both can reduce resource requirements as well.
By resource requirements surely you don’t mean compute resources right?
They mean human developers.
Is the popularity due to Python itself, or due to the explosion in use of AI/ML that all but mandates use of Python ?It'd be interesting to see an attempt to assess the growth in use of Python outside of AI/ML.
I wish I could wave a magic wand and replace all the Python in the world with JavaScript.The languages are practically equal in terms of features. They're both typeless with layered-on crutches available to make the runaway dynamism less painful. They both have weird footguns and ugly syntax and annoying design flaws, but these are different for each. So if you're forced to use both languages, it's an endless pain in the ass to remember which stupid runtime error can happen in JS but not Python and vice versa.So JS can replace Python... But Python can't replace JS simply because it's unavoidable on the front-end. Since you must have JS code anyway, why use a language that's functionally very similar but different enough in syntax and API that you'll be writing bugs all the time? Just stick with JS and start drinking like me.
It's easy to avoid JS on the front-end : just wave your wand!
Since I have an all-powerful magic wand that rewrites history, I guess I could use it to make Python the default language in Netscape Navigator 2.0 and then everything written in JS since 1997 would be in Python instead...But I don't actually want to do that. The Python design philosophy isn't really compatible with loading embedded, sandboxed user programs over the network. A hypothetical Python-Netscape would have crashed and burned with security holes like ActiveX, IMHO.
Somewhat agree. In fact for a recent project I began writing in JS for this reason but quickly ran into opinions from team mates with no JS exposure asking "Why wouldn't you use Python?", so I did. But, I think JS as a Python replacement is problematic because:1. Some probably usable version of Python is already on your computer. Not true for JS.2. Forced use of async in JS library code, even though Node.js doesn't require it.
Here's how out-of-the-loop I am: I'd don't know the command line method for invoking the JS runtime on my computer! What it is? I regularly image my laptop, so I'd like to know what the system JS command line is. (I use Linux & macOS.)
The CLI runtime that 99% of people use is Node.js, available via the same package manager where you'd get Python 3.Its dependency management story is not great, but in general better than the horrible mess on the Python side.On macOS there's a system runtime called JavaScriptCore.framework. It's actually a very good and useful engine. If you're writing native code, you could link to that. But of course it doesn't provide any of the Node.js API, just the JS standard library which is tiny. So the most typical use case would be to embed a JS API into your application.
Not really safe to assume there's a decent one. Better to install directly fromhttps://nodejs.org/
Ah, but with Javascript you are forced to deal with approximately ten thousand libraries from which you must choose for a given task.  I hate that.
Garbages keep growing, too.It's really hard to trace a Python bug based on codebase, due to its stricly bugly indentation sensitive for space/tabs.I rather work on a JS codebase than a python codebase.But i consider Python coders genius, because they can go deep into rabbit hole really well.
> I rather work on a JS codebase than a python codebase.That may only prove that you are not proficient in either.
Github is primarily a website for developers, right? Who is the blog for?This article is garbage. It reads like SEO trash and I'm not sure why Github feels the need to publish it.
It's just a list of common Python talking points. Points that the author displays a poor understanding of.The article doesn't really attempt to explainwhy python keeps growingbut the facts listed vaguely suggest that it "keeps growing" (not sure when it was supposed to die) because it is Good and Popular. Which makes sense, I guess.If the title was '10 Cool Facts About Python (a Programming Language!)' I would probably find it a little bit funny.
Marketing to those who are new to coding. Seems like a good business decision on GitHub's part.
The comparison with Java is always a funny one.  Consider this:import sys

  def main(
    args: list[str],
  ) -> int:
    sys.stdout.write(“hi\n”)
    return 0

  sys.exit(main())Apart from the call towriteinstead ofprinteverything else there is a standard Python pattern for writing testable, type-safe arg-parsing code!It’s just that you don’thaveto write testable, type-safe code if you don’t want to.
A lot of Java's verbosity isn't so much from the language, but from when the code was written. It happened to come to popularity at a time when big over-engineered Gang of Four-style design washot. So you get a lot of code written in this over-engineered fashion where half the classes have names that end in DelegateFactoryFacadeMessengerImpl.Some of it is the language too, but modern Java can definitely be reasonably terse. Record classes has done a lot for the language, so has lambdas and streams.
Java is still good for several use cases, which were popular at the time, or let's say much more code was needed. Now in the Enterprise world you have much better no- or low-code tools. But in large teams all of these public/private/protected key words are quite nice. Totally unnecessary for a small codebase. But Java with its great runtime, verbose patterns is great for web server applications in large teams. I would still use it as the foundation for a tech company, but not for the Fortune500 company that needs some customization. Where is no alternative where you can find people, and has the stable properties. Maybe Rust if you have the clout as a company. Otherwise it's too expensive.
For its warts, Java was supported by a company with a lot of smart engineers who were working to provide a “batteries-included”, cross-platform language ecosystem and Sun was really invested in its success. I’d love to see some of these successor languages get the same kind of corporate sponsorship, but I don’t think it’s profitable.
Protected data was never as useful to me as package-only data.  The former is only relevant with inheritance hierarchies, whereas the latter is more open while also restricting access only to other classes in yourcom.example.concernpackage.  Extremely useful for keeping big teams on the right track.
Yeah I think the problem is better understood now than when Java was originally designed.Modules/Project Jigsaw is arguably an even better step in the right direction. It arguably allows a much saner granularity of visibility and access.
> Apart from the call to write instead of print everything else there is a standard Python pattern for writing testable, type-safe arg-parsing code!Its…not, actually. A more typical, and testable, example of python would be:import sys

  def main(args: list[str]) -> None:
    sys.stdout.write("hi\n")

  if __name__ == "__main__":
    main(sys.argv)Your version:* Isn’t testable because it runs the sys.exit() call unconditionally on import, so there is no way to import the module and call main() from test code.* Fails with an error, because main has a required argument that it isn’t supplied in the unconditional main() call inside the sys.exit() call.* Isn’t following a typical python idiom by returning a value from a function and have it be unconditionally 0; if the only options are a fixed return and a exception somewhere, the convention is to return None (which doesn’t require an explicit return.)* Since a normal exit is the default response of ending the main program, sys.exit() is unnecessary here; “Exit with 0 if main() returns successfully, and with an abnormal exit on exceptions in main” is achieved by just calling main() and having nothing after it in the main program.
The example they give later in the article is also pretty verbose and includes much more "magic" than JavaExample:import antigravity

  def main():
    antigravity.fly()

  if __name__ == '__main__':
    main()I would argue that there is nothing simple about the last if-statement and will probably be very confusing for new developers.
> I would argue that there is nothing simple about the last if-statement and will probably be very confusing for new developers.The only thing that isn’t perfectly straightforward is “what is __name__”, but once you know how __name__ is defined…OTOH, that example ismuchmore complicated than needed.
As a simple executable script, that would do the same thing if antigravity. Fly() actually did anything, all that is needed is:import antigravity

  antigravity.fly()The rest is unnecessary boilerplate to provide a module that can operate either as a library or a script, which is superfluous here. Moreover, since the actual functionality it is demonstrating is all in an import hook, all you actually need (the rest just produces an error message) is:import antigravity
Python is really nice.Easy to learn yet powerful.
Easy to read yet very concise.
Anytime you need something complicated, it's a pip and an import away.Couple of downsides though:
    - slow
    - does not handle multiprocessing nicely.If the python team ever manages to fixes these two (not easy or it would have happened a while ago) to bring it to - say - the level of Go, Python would be the absolute killer language.
Python has a dual benefit - it's "easier" to approach from the bottom of the skill level - ie easier for a new dev to pick up compared to what C++But even as someone who knows C++, most of the stuff I do doesn't require it - and python is often easier and terser to express the concepts.
I think people embrace Python because they think it's easy to learn and use. While that might be true, the real complexity lies not in learning and using a language (unless it's Rust) but in learning the libraries, frameworks, idioms, dos, don'ts, tooling.
How difficult it would be to transpile python program into a more performant language using a LLM ? This would solve so many issues. Write a code in python and convert it into C++/Rust/Assembly for performance.
> How difficult it would be to transpile python program into a more performant language using a LLM ?It'd be a lot easier (and more reliable) just to use a traditional compiler, rather than an LLM imitating a compiler.The problem is maintaining the full scope of Python semantics there is usually no advantage to this. Compiling parts of a python codebase, with restricted semantics, can give you significant gains in some use cases, and there are tools (in Python!) that do that already.
I think the idea is that a person can read a project in python and re-implement it more efficiently in C++. The LLM could do the same thing. However, I don't think LLMs are quite that powerful.
So impressive to see all trading solutions/bots made with Python! What do you think about Julia in this field: I see it as a viable alternative even if it lacks the huge amount of Python libraries?
Are people going optimistic about the efforts to make Python faster?
Optimistic that we'll see maybe a 2x performance over the next 5 years, yea.  Optimistic that python will catch up to any of the 'fast' scripting languages, no.
If by "optimistic" you mean "confident we'll get some free wins that are ultimately pretty small for normal apps" then yes :P
I switched to python last year because it has an excellent builtin library. No more having to download random crappy libraries that download even more crappy libraries.
did you switch from nodejs?
I remember when Twitter rewrote the code in Java because Ruby wasn't suited for the task. Probably this will happen to many large Python code bases in the future.
Every codebase will eventually be rewritten in Rust sometime before the heat death of the universe.
As a divine punishment?
Perhaps, but it seems the shelf-life of anything AI/ML related (huge part of Python usage) is so short that it'll become obsolete before it ever becomes worth rewriting.
Dare I say, the article is quite a shallow take... but maybe that's all there is - the apparent ease and the few industries that have been built on top of it?
I dig a bit but not found how the percentage is from. Is it F(#LoC, #download, #repo, #active-in-past-x-year) something? What's the calculation here?
It's definitely the best language for quick scripting and multi-os tools that requires some code organization, probably not for scaling stuff.
Why haven't Python replaced Make? Its cross-platform and can do pretty much any horrible monstrosities that people do in make and cmake.
Meson is a build system written in python:https://mesonbuild.com/index.htmlGetting python bootstrapped is less easy than getting make bootstrapped, plus python isn't a GNU tool so I don't see them adding a dependency on it to all their packages.GNU Make is really far more sophisticated than people give it credit for and it's not that easy to replace it.
I was thinking of using python as a script (duh).> GNU Make is really far more sophisticated than people give it credit for and it's not that easy to replace it.Since its turing complete, it should be able to do everything make can. For example, to compile a C project involves something like:1. grab all the C files inside `src/`.
2. join the filenames with whitespace delimiter
3. execute `gcc <join result>`It can also be used to figure out the OS, where to find dependencies and what order compilation should happen or whatever.But why doesn't this happen?
Well as I pointed out, it does happen e.g. in Meson.Make doesn't do any of the things you mention - it just works out what targets need to be rebuilt and the code to do it is in the rules that you have to write in a shell language like bash.I admit you can use builtin implicit rules for C and get away with that up to a point but only a fairly low point.python is far harder to use than bash when it comes to running processes and doing things with them and doing the file-system manipulation that is usually wanted when building.There are modules that make it easier but so far as I've seen it's a crap choice plus python takes a long time to start up so there is a cost to running a "clean" environment for every build step but OTOH if you use the same interpreter for the whole build you can introduce all sorts of ordering problems  when a build runs on a different machine and doesn't work because it's executing build tasks in a different order.If you really want to build by "writing a script" (groan - because that's the age old horrible solution) why bother with python?
>python is far harder to use than bash when it comes to running processes and doing things with them and doing the file-system manipulation that is usually wanted when building.Can easily be solved by having libraries that does. Which is far better solution that hacking/chaining 5 different obscure unix tools to do string manipulation.>you can introduce all sorts of ordering problems when a build runs on a different machine and doesn't work because it's executing build tasks in a different order.Surely it is better than make? Even if make is "better" because it "just works". This is basically Hyrum's Rule waiting to be unleashed.>If you really want to build by "writing a script" (groan - because that's the age old horrible solution) why bother with python?Because I personally cannot decipher make and I think this is the experience of many developers as well. And how many make derivations are there? Its basically an arcane spell that needs to be chanted with every project (configure -> make -> make install).
GNU make is the only variant that matters.It's not arcane - you just don't want to learn it.   You can write your own system and rediscover all the issues and resolve them if you like.If you started from understanding make, though, you could do a better job than it has done because you don't have to be compatible.
There is a typo on the Java Hello World example hehe
$5 says this post was generated by ChatGPT.
I’ve seen replace a lot of tasks that used to be done with Excel - non-programmers programming tool of choice.
If the author of this article reads this: you have an error in a heading:> Using Python for and artificial intelligenceforwhatand AI?
Based on the text that follows, I would guess that the missing term is "machine learning".
Funny enough this sort of sentence, i.e one with a missing word, is a very common ML training task for large language models like Gpt3: the models objective is to predict the correct word from a set of possible answers.
I would take Nim over Python. Better designed, much faster. As readable as Python.
I'm very interested in giving it a try once it has a tree-sitter grammar (already has a Jetbrains plugin and LSP, but I'm trying to be conservative).
it's strange to me, because JS has so many advantages over Python, only remaining thing could be converting more scientific libs like scikit in JS
Odd pitch from a company who use Ruby over Python.
people love python. i never learned it but i figured the python indenting instead of bracketing thing would have spread more by now
Python is the new BASIC.That pretty much says it all.
The growth is actually too fast. I was a python expert. Now it's not a big deal any more because the language is so easy. I've hit interviews where they DIDn't want me to use python because it's too easy.I branched out to C++ and other languages to stay above the curve. Python is becoming like english, required to know, and not really a deep skillset employers are looking for now.
I'm strictly a "scientific" programmer. I've used multiple languages in 40+ years, but only two lasted more than a decade: Turbo Pascal and Python. As Python has passed the decade mark for me, I sometimes wonder why I'm still using it and what would make me get sick of it.Some of my reasons for choosing Python in the first place have been mooted. Python is free, and multi-platform, but so is everything else nowadays. I think that battle is over.For my use, packaging has not been a big obstacle, maybe because I tend to use a relatively small handful of established packages. I don't remember needing a package that I couldn't install with pip.Easy to learn? Yes and no. I think a beginner can ease their way into Python and get productive, if they start with basic scripting and progressively adding a few language features. On the other hand, some features are simply over the heads of beginners, making the code found in packages practically unreadable. But I've never found any language to be better in this regard.Fast? Sure, with numpy in its domain of use. Or writing your own C libraries. However, I think a beginner using numpy will run into roadblocks that require help from an experienced programmer, who can visualize what the array operations are doing under the hood. So, writing fast code isn't easier to learn in Python than in any other language.The editor should have a final option, that turns your code brown if it's just so bad that nobody should ever have to read it, including yourself.
I now use python, but Python is not even half the language Mathematica is for scientific computing.If only Mathematica was free, I think it would become the defacto language for scientists.The most important feature of Mathematica is that it is functional and not object-oriented. Mathematics is functional, not object-oriented. So thinking in Mathematica is as easy as thinking in maths. Thinking in python is to force yourself to think in an unnatural way.
I think you're regarding Mathematica from a purely "theory/analytics" point of view, however I think you're missing the fact for a lot of scientific computing you want to interact with other things apart from numerics/analytics etc.. I believe that is really where Python shines and why it's also eating Matlab's lunch (more so than Mathematica's). It's incredibly easy to write a gui to interface with e.g. a scientific instrument do some reasonably fast analytics with numpy and possibly even produce publication ready plots. This is not really possible with Mathematica and while you can do this in Matlab, you need several toolboxes which are expensive, but more over are of extremely varying quality (let's not even talk about the horror of writing GUIs in Matlab).  With Python, you have all of that for free, with a single tool (remember most scientists don't want to learn lots of programming languages).
Octave/matlab is a little more enjoyable to use for matrix stuff in the REPL though. The game of “is this in Numpy or Scipy and why won’t it autocomplete” is kind of annoying, IMO.On the other hand, the non-mathematical functionality of Python of course is much better developed!
I like Mathematica a lot, but a couple of issues limit its usefulness for me. First, I'm an experimental scientist, so a lot of programming is in the lab, automating experiments, running tests, etc. Makers of specialized software tend to choose their battles in terms of the application of their product, justifiably, but this means no single app is general purpose enough to serve me in the office, lab, and at home.Second, unless an organization is enlightened enough to approve a site license, specialized software tends to create a "silo" of people who can use it, and forces it to be used in a centralized fashion. With Python, I can literally install my tools on every computer that I touch -- in the office, multiple labs, at home, etc. It makes it more likely that a tool will be woven into "how I think."I can also share things and/or encourage others to try them out with minimal friction. Almost as easy as sharing an Excel spreadsheet within an organization that has purchased a site license. Free means free site license.The friction of approving a license also discourages people from learning a tool by just giving it a try on some trivial project, or taking it home.
This is great commentary.
Mathematica (and matlab for that matter) is effectively free at most national labs, and it’s still a tiny market share. That’s because scientific computing is rarely just scientists, but often includes engineers, SWEs, system admins, theorists, grad students, and more, solving lots of problems. If you can’t get wide adoption at a national lab, where are you going to get it?Similar problem with Julia and Fortran even. They all have their niches and are great at certain problems, but Python (and C/C++) rule the overall landscape. in HEP, for example, it’s even the case that a full batteries-included C++ environment (ROOT) has slowly given way to python.
I was amused to notice that the Google trends map for Fortran was essentially a map of the US national labs.
> The most important feature of Mathematica is that it is functional and not object-oriented.Python has object-oriented features but there is nothing that requires you to use them; you certainly don't have to express every Python program in terms of classes and methods, the way you do in Java. Doing functional programming in Python is common. Is there a particular aspect of doing functional programming in Python that you find to be a roadblock?
It's more of the fact that all popular scientific libraries in python are written in an object-oriented way. That kind of forces you to write your own code in an OO way. I am guilty of this as I am writing a library myself. But users have to use, say numpy, along with my library. It would be suboptimal to force the user to constantly switch between functional and OO, so now my library is OO.On the other hand, all the code I wrote in Mathematica during my PhD was functional, because it is just easier to write functional in Mathematica.
> It's more of the fact that all popular scientific libraries in python are written in an object-oriented way. That kind of forces you to write your own code in an OO way.I'm not sure I see why. The object orientation in libraries like numpy or scipy is to provide the user with fast implementations of the kinds of mathematical objects they will need to do computations. But unless you are defining additional such objects in your own code, there's no reason why your own code needs to be object oriented. You can just write ordinary functional programs that use the mathematical objects the library provides.For example, say you are doing matrix computations. You are of course going to use the matrix objects provided by the library; but your own code shouldn't need to define any new matrix objects. Your own code can just be straightforward computations using the existing matrix objects in the library.
It doesn't matter how libraries are written, in py you can use in functional way. I don't get what do you mean by forcing you to code in OO? I Had used pandas, scikit-learn, numpy, pytorch in production and I had never wrote them in OO way. Are we from same universe?
> If only Mathematica was free, I think it would become the defacto language for scientists.Of course. It’s one of the few languages that I think are worth it.I’ve been waiting for Wolfram to open source it for 10 years as I can’t afford it, or really justify why my org should use it.
> I’ve been waiting for Wolfram to open source it for 10 years as I can’t afford it,Wolframscript is free (not guaranteed to stay that way, as it isn't Open Source, but free for now).It can AFAIK do pretty much all Mathematica can.Only part missing is the Mathematica IDE/GUI/Notebook which I personally dislike profoundly anyways.Best of all, since it's a batch tool, it can be integrated in a Makefile and/or data processing pipeline without that nasty GUI showing up at all.https://www.wolfram.com/wolframscript/
I believe this is only the language. Not the set of libraries that come with Mathematica. Without those, one cannot do a lot in terms of scientific computation.
I often like to compare Python and Mathematica to English and Latin.English is not really a beautiful language - it’s a wild mess of different influences, but it’s easy to get to a basic level of fluency as there are few rules (but many exceptions due to the many influences). And it’s in use by large parts of the world.On the other hand, Latin is beautiful and pure. It has more rules, but very few exceptions. You can also see how it influenced other languages (hello Jupyter notebooks…) But it’s simply not a very practical language today, as there are few people who use it.
>It has more rules, but very few exceptions.... That we know about. It's a dead language, so the exceptions would've been lost to time as it hasn't been spoken in ages.Your point stands regardless, just felt like being nitpicky
I feel that choosing the language based on how close it is to thinking in maths is putting the cart behind the horse, because in all scientific and applied scientific code I've seen, the actual math models is something like 10-20% of the code, and the majority is all the data management and plumbing  around that; so you should pick the language based on how easy and maintainable the majority of the code will be, which is not the 'mathy' part of it.
> Mathematics is functional, not object-oriented.I beg to differ.  If by "math" you mean arithmetic and calculus, then sure.  Combinatorics, graph theory; probably most of discrete math is very much object-oriented.
Consider a graph G, with vertices (a,b,...,z). Say, we want to find the shortest path between vertices a and m. A mathematician might write an algorithm called shortest_path(G, a, m) which might call the algorithm breadth_first_search(a) etc. Functions are called on objects to determine their properties. Or to modify them into other objects. This is what you see in math or theoretical CS papers.In python, in popular libraries, the above will be attained by something likeG.shortest_path(a,b)which seems to imply as per OO that graph G has a property shortest_path. In mathematics we don't think like this. Because it prevents mathematical abstraction. An abstract algorithm, like say Eigenvalues can be applied to a matrix M or to a graph G. In a functional language, the user would just do Eigenvalue(M) or Eigenvalue(G) as needed.In python, these would be M.eigenvalues() and G.eigenvalues(), which makes them distinct.
What you're saying is not true of the most popular graph package in Python (networkx).  Graphs there are objects with attributes (edges, nodes, etc) and methods (add_edge, etc), but algorithms such as shortest paths are functions as you have called most natural: shortest_path(G, a, b)
Well, I am glad that at least this library is being functional, rather than object oriented.I wish all the others did as well.
It's still object-oriented, though.  The graphs themselves are objects, which helps with ergonomics.There are also functions that operate on graphs, because the alternative would be to stuff perhaps thousands of methods into the graph class -- which would be extremely annoying to maintain as well as abysmally slow.
Since you capitalized it, it looks like a static method on the “G” class. There is nothing OO about static methods - this is purely and organizational construct.
I think it's the superclass A of both G and M that defines the eigenvalue() function. Then when both G(A) and M(A) inherit from A, it captures the mathematical relationship. The subclasses indeed should implement the eigenvalues computations differently, like in real mathematics.Funcional programming is used in Coq because it captures logical chains, for theorem PROOFS, but not for specific COMPUTATIONS, such as eigenvalues.
I understand that this is possible. But this is not how mathematicians think. If you got together a bunch of mathematicians and asked to invent a programming language to do mathematics, they would never ever invent the concept of a class.Mathematics (outside of stuff like category theory etc) is simply sets and mappings between sets. Anything more complicated is forcing the user to think in a way that mathematics does not.
> But this is not how mathematicians think. If you got together a bunch of mathematicians and asked to invent a programming language to do mathematics, they would never ever invent the concept of a class.Hi, mathematician here.  Please read the source of SageMath: written by mathematicians, for mathematicians.  Therein, you will find thousands of classes.  Almost all computer algebra systems, written by mathematicians for mathematicians, have a notion of classes.> Mathematics (outside of stuff like category theory etc) is simply sets and mappings between sets.This is an extremely narrow-minded view of mathematics.  Mathematiciansthriveon abstraction, (category theory is literally mathematics; that's a very strange exception for you to carve out), and if we were to boil everything down to "simply sets and mappings between sets" then we'd be bogged down in utter tedium and nothing would ever get done.  Object-oriented programming, specifically class hierarchies and inheritance, areextremelyvaluable for doing all sorts of math at high levels of abstraction.Hell.  If I were to be especially pedantic, I'd point out that category theory itself is "simply sets and mappings between sets" except that sets aren't quite large enough so it's actually "categories and mapping between categories".
Since the eigen decomposition is specifically a property of the matrix representation of the graph, but other things like shortest path distance between two nodes are naturally enough computed on graphs formed by objects with pointers, perhaps the correct interface is G.adjacency_matrix().eigenvalues().
object orientation here means boxing side effects behind methods, math doesn't seem to bother with implicit mutable state
"Most discrete math is object oriented"...what?
There are a lot of hierarchies in the families of objects that discrete mathematicians are interested in.  Inheritance is extremely natural in such settings.
How does the speed of Mathematica compare to python or C?
There is Octave and Julia
Mathematica is so much more it’s hard to even describe. It’s free on a raspberry pi, so if you have time and access to hardware, take a look.
I think the so much more/hard to even describe is sort of a problem?There is a lot to it, and in my experience it's a very long road to getting your first problem solved.There are a lot of very cool pieces but I want it to be something I can pull off the shelf once in a while and be productive rather than something that I need to be an expert in before I can get started.
Another big one that many languages treat as table stakes these days is the whole 'batteries included' thing. Whenever a new language comes out and I have to make my own (or install) core capabilities, it feels like a huge waste of time.
"A lot of batteries included" cannot be repeated enough. This is huge. Some languages you have to write your own. But the flip is also true. Take Node. For function X, there are 100 ill named "add ons" of variable quality and repute. Discoverability is a nightmare. Which-to-use in your mashup leads to paralysis analysis. I use a handful of libraries for some pretty large Python apps, but for so much of the basics, it's all in there. The quality and documentation vary a little, but the similarity/consistency is much better than you find in the wild. Even in Elixir (a much smaller universe than Node/JS), I experience this "15 poorly named packages that do the same thing in different ways".
Agreed.  I am a Perl refugee.  I was so tired of searching CPAN to find ten packages, but some wouldn't install on Windows, and then I would have to evaluate the survivors.  They would cover sixty percent of the problem, maybe seventy, all different coverages.Now people talk about Python's standard library being "where code goes to die," they want to remove old stuff, makes me sad.
I haven't found that in Elixir... I often find one of two that haven't been updated in a couple of years but still work just fine because the Elixir language itself doesn't change much.It may depend on what types of libs you're looking for, of course.  It's definitely missing a lot of stuff.
Wait until you have to upgrade and update your Node application a year later.
Which Elixir libraries do you think should be in the stdlib that aren’t?
Having to piece together a Python installation can be an annoyance for a beginner. I always offer to help them set things up the first time. Since most of my workplace is on Windows, it's easy to have people install WinPython.This is especially true if they've already tried setting things up, and have made a mess of it. Because WinPython is self contained, it can work on a computer that already has a working or non-working Python installation.
What do you mean by piecing together a python install? Most linux should have one pre-installed or easily available via the package manager. After that venvs and pip seem to be generally enough for most tasks.
Packaging Python applications that are outside of containerized apps can be a headache. You can't assume that the system's Python suits your needs, or even that Python versions in package repositories will, either.A big pain point still remains when it comes to packaging and distribution.It's not insurmountable, but if you're used to compiling and/or cross-compiling and shipping binaries, shipping Python apps can be headache inducing. The headaches increase when you're working with Windows or macOS, or using bleeding edge Python versions.That said, for 99% of Python apps out there, the default tooling should be absolutely fine for packaging and distribution, as should 3rd party solutions like PyInstaller or Nuitka.
Oh of course, packaging python apps for final distribution is a different matter. I was assuming they were talking about the process of setting up a dev environment not deployment.
Oh yeah, 99.999% that's the case for dev environments. The only issue I've seen is that some versions of Linux distros have Python shipping with Tk and cryptography support in separate packages to be installed from repositories, where they might be installed by default on other distros, or are just included with the Python package.
I've been using Python for about 6 years, my last company wrote it's core commercial product exclusively in python.   I've never used venvs, but I've yet to run into a situation where virtualenv (maybe with virtualwrappers as sugar), and pip + requirements.txt haven't been able to handle even fairly complex install situations.
My workplace is a Windows shop. I'm multi platform, but by and large the folks using Linux don't need my help. ;-) So when I help people its almost always on Windows.
I think the desire for batteries to be included is a holdover from the time of really really bad (or no) package managers. With a good package manager it doesn't matter if your batteries come included or not. It also provides a way for packages to battle it out external to the language -- compare Python’s `urllib` and `requests`.
The curation of the batteries is the value add. Which grpc package do I want? Which json?  Which random number generator?  Finding which rust crate is the norm for any given thing, is a task in itself. Then there is the security aspect. Pulling in hundreds of repos with many authors each, is a security risk.
"Does last year's code still work" is very important to almost all programmers. I wouldn't want to accidentally use a library that gets abandoned or deprecated a few months after I made it an integral part of my software. Being able to mostly stick to the standard lib makes this a lot easier.
That works for Rust's standard library, which won't abandon anything stable (stuff gets deprecated, but that just results in a build warning).It doesn't make as much sense for Python's standard library where you'd need to be paying attention to goings-on in the community to know if one of the batteries that are included has been judged expired and will be removed.
SO would disable a question of this type for being opinion-based.I would assume the Python devs review the code for a package before including it in the standard lib, right?  That seems like a pretty big deal, well beyond someone just telling you that they tried a package and it worked for them.
This argument is also a holdover from a time where supply chain attacks weren't considered a serious threat.
Exactly.  The single biggest hurdle for me using some open source tools written with newer languages is the ridiculous dependency surface due to a preference for package repositories over curated “batteries included” bundled libraries.  I work in an environment that is hyper sensitive to supply chain integrity, which means a lot of languages that have a culture of “use all the third party packages” are out for us.Give me a batteries included standard library please - much easier to audit and track.
Nearly every place I've worked, the supply chain attack problem has been solved or at least mitigated by using an Artifactory instance with a curated list of packages.
Python is nowhere near as "batteries included" as .NET for example.
Perhaps the next programming language / ecosystem can remove this problem entirely . Why is it so hard to have access to everything while shipping only what is actually needed?
The need to runtimes shared by multiple applications on a single machine makes this a hard problem to solve, unless it's statically compiled. Of course, Docker renders this moot, and I'm unaware of any languages written in a "Docker-first" manner.
Testing, versioning, deployment
> On the other hand, some features are simply over the heads of beginners, making the code found in packages practically unreadable.That's too bad. I taught myself Python last year but have kept it pretty "101". That is, I write codesimply. Since I am new to Python I don't know if the unreadable code you're describing is because it needs to be (perhaps I am still tooling around in the parking lot of Python) or if it is the result of programmers being too cool for school (ha ha).Perhaps if the latter I ought to blame the language for giving programmers a basement of esoterica to plunder rather than the programmers themselves.As obtuse as C could get with pointer arithmetic and the cryptic looking "question-mark-operator", there really wasn't much esoteric stuff in C. Contrast that to my experience with Swift where seemingly every week or so I would come across cryptic code where someone was using a capital T or some bizarre case expression I am unable to mentally parse.> Turbo PascalYou suddenly made me miss an ex-girlfriend. Maybe they still code in Turbo Pascal inPortlandia.I can dream.
There's a fine one just like the ex, Free Pascal, waiting athttps://wiki.freepascal.org/to be checked out.  Now the dream can become reality, but do take into account that satisfaction can depend on being realistic.
I think one big factor is easy entry but almost no limit:Like BASIC back in the day it's a language that allows newcomers to do things long before they are comfortable with the added syntax requirements of C based languagesDespite that the sky is the limit, almost all problems a developer will encounter can be tackled with python. Yes for many problems there are languages that are better suited for the task, but in most cases a project does never even reach a state where that will matter.And it's installed by default in many Linux distributions.
But I think this may be evidence for the argument that scientists should be paired with research software engineers who take the science codes and turn them into usuable libraries. Scientists don't necessarily need to produce codes that others use, simply ideas that can be translated into useful libraries. Certainly some scientists can do this themselves, but not all can nor should be expected to.
Have you tried Julia?
Aah Turbo Pascal. That was the first "big pants" language I learnt and enjoyed.After that... C++ was fun initially and later felt way too featured. I don't like C++ code now (especially with heavy template use and stl and boost).I now code in Python (because most of the things I work on are in Python) though I don't like the dynamic typing.My potential new love is Rust but we are still working out some issues
> I don't remember needing a package that I couldn't install with pip.I don't think there's even a (reasonable/non-contrived) way that a package could be available to you that pip wouldn't install?(Or do you mean that you don't remember desiring a library functionality that wasn't available in some package?)
Some projects are distributed on PyPI as source code, and sometimes that source code has C modules that need to be compiled. The same can be true with packages that ship with Rust modules.Both might require you to have compiler toolchains installed.
Also some compiled code might need to be statically linked to other deps.A practical example: on Windows, try 'pip install tokenizers'.
I was curious what would go wrong, this just worked for me:py -3 -m pip install tokenizers...Building wheel for tokenizers (pyproject.toml) ... doneCreated wheel for tokenizers: filename=tokenizers-0.13.2-cp311-cp311-win_amd64.whl
Looks like if you try to install it via source you might need a compiler/linker toolchain installed for its Rust bindings.
It's rare, but I've run into packages that don't install easily with pip, due to not having binaries for a specific Python version + platform (something like this one where the combinations of Python+platform+MacOS version are limited, for example -https://pypi.org/project/virgil-crypto-lib/#files).Also there are probably tons of "packages" which were never published officially to pypi but exist on github, that people have made public but decided not to maintain.
> Also there are probably tons of "packages" which were never published officially to pypi but exist on github,I'm doing this from memory, it's hardly a frequent thing for me, but err something like:pip install -e git+https://github.com/vonseel/...
Similar camp. Two reasons I enjoy Python, both related to documentation:1. docstrings2. keyword argumentsDocstrings mean I can do REPL experiments without the additional friction of opening a browser to RTFM. Keyword arguments reduce how much I have to lookup the semantics of a function's signature.
> The editor should have a final option, that turns your code brown if it's just so bad that nobody should ever have to read it, including yourself.Getting the editor to measure the cyclometric complexity of the code and then colour offending blocks?
"Can visualize what the array operations are doing under the hood"Either you take the time and trouble to understand what you're actually doing or you're just a lazy wizard with some facility for incantations.
Python does a great job at putting together powerful scripts quickly. But I have a really hard time opening up a big Python codebase and making sense of it quickly. No static types can make data pretty hard for me to follow. This may just be something I need to improve at, but I have a distinctly better feeling working with unfamiliar code with static types. Python makes me feel I’m at the will of the documenter to be informed, whereas the types self-document in many cases in other langs.
I think this is actually a big difference between SWEs and programmers who are scientists/data scientists/analysts etc. first. In my experience, people with more formal education in programming find type systems to be very helpful, while people from other backgrounds, find them confusing and an nuisance.
I don’t think you need a “formal education” to see the benefits of strong typing. Whether someone is attracted to it or not probably has more to do with their specific use case.Strongly typed languages is simply a trade off where you get peace of mind by paying for it with extra time and effort spent. For some people that’s a no-brainer and for some people that’s just something that gets in the way.My background is mostly in sysops and monitoring, and for me types are a life-saver because I value stability and predictability over almost anything else. If my job was something more similar to “ship new stuff fast” I’m not sure that would be the case.
I agree it's a trade off but for me the ratio of effort spent/effort saved in lack of bugs and peace of minds is like 1/1000. Such a tiny bit of effort for huge payback in effort/mental energy saved.
> If my job was something more similar to “ship new stuff fast”Ironically, the slowest moving codebase I have ever seen was written in Python.  It was impossible to "ship new stuff fast" without breaking things.  I think Python works up to a certain size/complexity level, then it completely falls apart.
Yes; I've come to realize the yarn "Internal quality and productivity rise and fall together" is more true than I ever thought.  And with python, (and IME most dynamically typed languages), the internal quality has far more ways to go awry.
> the benefits of strong typingA couple of comments here:1. Python is very strongly typed,everysingle item has a clearly defined type. That said, it isdynamicallytyped, meaning that the variables are not a "containers" for predefined types, but simply labels on objects.2. What brings benefits is not static typing itself, but static analysis which is mandatory in most statically typed languages (i.e. the program won't compile/interpret if the analysis breaks). With tools like mypy Python has a perfectly capable static analysis - even withoutanytype annotations, although they massively improve it - it's just not mandatory and the program will happily run even if it fails.
> I don’t think you need a “formal education” to see the benefits of strong typing.Which is not what P said.  They said those that have it tend to favor strong typing; those that don't tend to not.IME I've seen the same thing.  It's not a rule, it's a generalization that is often wrong, but more often right.  Again, IME.  YEMV.
Just anecdotal, but I dropped out after a year or so of CS and I value types more than the vast majority of developers I've ever worked with, most of whom have much more formal education than I do.
You may well be right. Personally, I dislike writing python because it lacks static types and all too often I end up triggering runtime exceptions, especially when integrating with third-party code. Do you suppose scientists/etc are more tolerant of runtime errors, at least while writing the code?
In my experience, the biggest issue in numerical/scientific code is to get correct results, these cases will hardly every be caught by typing. Moreover in many scientific programs you deal with well defined inputs, i.e. the chances of e.g. calling a function with an incompatible type are quite low. The most common error I have encountered is a mismatch in dimensionality/shape of input arrays (which I believe isn't straight forward to type for either, in particular if you want the shapes to be flexible, but all inputs to have the same shape).
Try pyflakes, it will find a majority of those.
Wemake [1] is much more comprehensive, although you might find it overwhelming at first. It includes a lot of useful flake8 rules that tackle complexity, enforce consistency and best practices and much much more.[1]:https://wemake-python-styleguide.readthedocs.io/en/latest/
Styling is not the problem the poster was complaining about, and why I specifically chose pyflakes out of dozens of such tools.
Relevant:https://danluu.com/empirical-pl/
I feel naked without static types and my background is in humanities.
Python has optional type annotations. Most new code tends to have them, and they help tremendously navigating and understanding large codebases.
It's honestly not very good compared to a "real" type system (platform). I've used it about a year ago for a couple of projects, and it was painful and ultimately not very useful exercise.
I've used Mypy since 2016 on big as well as small codebases, and it has been extremely useful for me. It caught numerous bugs at typecheck time. The benefits of better readability and e.g. better jump to definition and autocomplete are harder to quantify, but subjectively they feel substantial. If you are gradually annotating a big codebase, it does require a "critical mass" before types start to pay off, I agree that adding them later can be painful.Mypy's type system is quite advanced compared to some statically typed language like C and Go; it has generics, union types, inference, and it can prove properties of types from control flow. I work mostly in Rust, Haskell, and Python, and I rarely find Mypy limiting.You do have to embrace types though; if you have a dictly typed program where everything is a Dict[str, Any], then putting that in annotations isn’t going to be very helpful; converting the dicts to named tuples or dataclasses is.
As an alternative perspective, I've found mypy to be pretty poor in comparison to other rich type schemes. Particularly in comparison to the Javascript/Typescript ecosystem, it really feels like taking a huge step backwards.Partly that's because the ecosystem support isn't there - lots of libraries don't have types, or have types that behave oddly, or even require their own plugin for mypy. I suspect that's going to slowly change over time, but I feel like the infrastructure doesn't feel as strong as it did in the early days of Typescript, and the gradual change feels even more gradual.Partly it's just that the syntax is painful as soon as you want to do anything remotely complex. For example, generics are defined in different ways depending on what you're making generic, and the TypeVar system is usable, but ugly and very unintuitive. There's also missing syntax for things like inline type assertions, which aren't great, but are often useful for mixing static and dynamic code together.And I think partly it's also that Python has a much higher level of dynamism in the type system - lots of "clever" things are possible in Python that just wouldn't be possible in the same way in Javascript - which means that mypy has a much more difficult time in trying to describe the idiomatic Python patterns that people are actually using. In Typescript, figuring out the correct types feels like an extension of writing natural Javascript code and understanding the flow of data through the program. With mypy, it feels like I'm restricted to writing the subset of Java-like code that conforms to the type checker.It's a disappointing feeling, because I like static types, and I had hoped it would help solve the problem of large codebases in Python. But in my last project it became so painful to use, and felt like it was adding so little (and preventing so few actual issues), that I kind of regretted pushing for it.I hope a lot of these problems are just teething issues, and that over time it'll get better. But right now I would be very cautious about using it in production.
> - lots of "clever" things are possible in Python that just wouldn't be possible in the same way in JavascriptJS has Object.setPrototypeOf(), among other things, so I doubt this.
In practice, that's very rarely used, partly because inheritance is so uncommon in Javascript programs. However, for a long time, Javascript lacked anything like the __getattr__/__setattr__ methods, it has no real operator overloading, and decorators are more limited and generally rare outside of certain ecosystems. These sorts of metaprogramming techniques that are very normal in Python are more rare in Javascript, and when they are present, they're generally easier to type.
> You do have to embrace types though; if you have a dictly typed program where everything is a Dict[str, Any], then putting that in annotations isn’t going to be very helpful; converting the dicts to named tuples or dataclasses is.Or even just TypedDict, which often works without any changes besides annotations.
>> It's honestly not very good compared to a "real" type system (platform).> I've used Mypy since 2016 on big as well as small codebases, and it has been extremely useful for me.You can both be right.  It's both not very good compared to a strict type system, and still way better than not having it.
The mypy experience is awful with numpy and pandas.
While I agree that type hinting by its very own nature feels a bit bolted on, I vastly prefer going into code bases which include type hinting. I personally always add type hinting to the code I write, as I actually consider it quite useful.In what ways do think it's painful?
I remember mypy being slow and buggy. I remember one mypy upgrade broke all our builds because they changed some type of resolution thing. IIRC after some outcry they backtracked and started providing some migration path.The other thing which rubbed me the wrong way was that the python was happy to run the code with completely wrong type hints.I guess I went into it with wrong expectations, even though it says right in the name - it's "typehints". The whole experience felt more like a formalized documentation with partially working optional verification (which can't really be relied upon).
I've also had a mixed experience with mypy. Take a look at using pyright for static type checking instead, it's worked quite well for me.But do write type hints. I recently got thrown into a large-ish project where neither types nor docs where used. Trying to figure out wth a parameter was supposed to be wasn't a pleasant experience for a newcomer. In addition to improving DX, I also believe it's alot more effective in the long run.I saw how these guys were developing: write code, run code, deal with the runtime crashes they encounter, then run code some more and deal with other unexpected runtime crashes. It would have been a lot faster and more stable if they'd just used type hints and static type checking, as their IDE could've easily found many of these bugs for them immediately.
Type hints are basically for documentation and metadata. You also find a bunch of third party libraries and frameworks, like pydantic, fastapi, etc. that makes use of them.
> Type hints are basically for documentation and metadata.They are also for static checking.If you choose to run the code despite that failing (which you can, because there is no execution dependency on type-checking) that’s a choice, but its kind of odd to complain that Python lets you do that.
I'm not the original poster and not complaining about it. I once worked at a shop that ran mypy checks as a precommit hook and never really found it terribly useful, but to each their own.
I don't follow. Python's static types can be gradually introduced to an untyped code base. Sure, they may be unhelpful if you don't use them everywhere. But how can they be painful? It's not like they prevent your code from being compiled?Having a Scala code base not compile because someone went all-in on type-level programming, and now simple changes require an understanding of category theory and the associated compiler flags .. that's real pain.
I have experience in both and I agree with OP.python's type-documentations are useful but sometimes they are just wrong which makes it impossible to actually trust in them.> Having a Scala code base not compile because someone went all-in on type-level programming, and now simple changes require an understanding of category theory and the associated compiler flags .. that's real pain.Well, the same can happen in python if someone goes crazy and uses a lot of reflection / dynamic changes (i.e. overwriting builtin methods etc.). In both cases it sucks and should have been prevented by other people, but at least in the case with Scala you still have a compiler that can help you "unroll" those changes because it tells you when you screw up. In python you can only have tests or pray.
Oh wow you should definitely give this a shot again. Type hints in Python save the entire language for me.People do have bad habits of cramming everything into dictionaries but if you do some type hinting and use data classes heavily you’ll really have a good experience.I could take or leave mypy personally.
Indeed.I wish I'd kept it but a few years ago someone did an analysis of all the public python code in github to see what functions were called the most.#1 was `type()`.  <shocked face>
It’s as real as typescript… not useful for code generation or optimization, but very helpful for correctness.
It's a far cry from an actually typed language. I like Python and deal with its code bases for a living, but frankly it has gotten too big for its britches.
> Python has optional type annotationsMoreover, it has static type checkers with varying degrees of support for type inference.
I find they clutter the code more than they help. Good names and docstrings and comments are more valuable.And static types are for people who are too lazy to write test code.
Sorry but this is a garbage take. Typing negates the need for writing useless tests that just verify the correct value types are passed - it does not negate the need for writing functional tests.Where did you come up with this?
You seem to not understand duck typing.Functional tests will test the correct types, too.Edit:
If you need an object that swims and quacks, you don't need to care if it is a rubber duck or an animal.
For quick scripts, I've recently taken to DenoIt has typescript built in so I can very quickly make a script.ts file anywhere and run it in the CLI with `deno run script.ts`. Works flawlessly and I get access to TS's amazing type system without any build step or setup or even any additional filesfor any data-intensive scripts I still sorely miss pandas though
What's the story in Deno with the standard lib and filesystem interaction? Because those are the two vital parts of scripting for me. I dabbled in Node scripting for a bit and ditched it because I didn't feel it was a viable option compared to Bash or Python.
It's all built-in. No extra dependencies or even imports necessary. Relative and absolute file paths work as expected. You can save and read any files freelyYou can import synchronously, asynchronously, as a stream, as a string, etc. All the functionality you'd expect is built-in with the Deno module (e.g. `Deno.readTextFile('./my/path.json')`) or even with module imports
When reading large projects written in C I find myself surprisingly little helped by static types. Almost everything is structs, pointer to structs, or structs with pointer to more structs.I could imagine that if developers choose to use less complex objects and less indirection then types in such large projects would be more useful in explaining the data. It just hasn't been my experience so far.
I feel exactly the opposite, compared to Python at least. It's usually easy to find the definition of the structs, and then you can quickly make sense of what a given function can and cannot do, and what it as access to.With Python I never know, since something might have dynamically added or changed some methods or fields along the way. I almost always end up sprinkling dir() all over just to figure out what exactly is going on.
I think that's because it's C, where you have to use void* occasionally, structs are often anonymous to avoid compile-time increases from including another header file, and there's a hellscape of pointers involved in doing anything significant.  If you picked up a modern language with static typing, like Rust, Go, Kotlin, or even C++/Java, you might see some significant readability benefits.
Imagine how much worse those structs with pointers to structs would be without static typing though. This feels like a complaint against C, not a complaint against static types.
It is a comment about how large projects, at least from my experience, seem to use complex data structures that takes several indirection to follow.In both C and python I have also see something akin to a mini language inside the large projects, where understanding the code becomes almost impossible without documentation. In C, both macros and pointers to structs with more pointers can do a lot of heavy lifting to hide every detail of how something is being done and just leave the intention. Great if one want to see a high level concept and creating new features, but terrible if you want to know where that one bit of information is being stored and how to inject your own code into the core parts of the project. Similar, large projects in python tend to use meta, monkey patching and other dark magic patterns to really hide the low level details while making it easy to create new features.
I think that's a take in the category of 'you don't want types, you want better names'.Static types are very useful for compilers but looking at a function and seeing int -> int -> int -> string -> bool -> int, says very little about the semantics of a program. It'salwaysthe names and documentations that tell human beings how to make sense of a program.When we put things in record types, the sense-making value isn't in the static analysis but in the fact that our vague collection of parameters now has a proper name that indicates what it's all about.
> Static types are very useful for compilers but looking at a function and seeing int -> int -> int -> string -> bool -> int, says very little about the semantics of a program.Sure, but on the other hand a type of APIProxyEvent -> LambaContext -> APIGatewayProxyResponse says quite a bit more about the semantics.Unless a function is highly abstract, int -> int -> int -> string -> bool -> int is probably an underspecific type signature.EDIT: To be clear, I generally find that the thesis “you don’t want types, you want better names” comes from assumingbadtypes, and suggesting replacing them withgood names. And, for casual inspection, yes, good names may be superior to bad types. On the other hand, I can’t statically check good names, I can statically check types (good types, or bad-because-underspecific types, but good types, as well as telling me more as areader, will also statically catch more possible errors.) Ultimately, what I want is good typesandgood names,
It's not so much assuming bad types as saying that names and types properly used serve different needs. For example, if you have types defined in your program, you could literally replace them with some random characters and the type-checking would be equally good, for the compiler, even if you don't undestand a thing. The value of types really is in the structure they represent, and enforcing certain constraints, not in any human understanding of the program. You could even have badly structured types with decent labels.When you're using types as a means to check names you're likely to misuse types. Synonyms are a good example of this, where people will make so many types each type only ever occurs once, instead of having a well named variable of a more generic type.
> It's not so much assuming bad types as saying that names and types properly used serve different needs.Different but overlapping needs, yes.> For example, if you have types defined in your program, you could literally replace them with some random characters and the type-checking would be equally good, for the compiler, even if you don't undestand a thingSure, but for human consumption you want good names of types, not just good logic of types, just like you want good names of variables.But, while you can (without types) overload names of variables with the human information that would be in names of types, this is bith less ergonomic that separating the two kinds of names, and doesn’t support type logic the way types that are both well-structured and well-named do.> The value of types really is in the structure they represent, and enforcing certain constraints, not in any human understanding of the program.I could not agree more strongly with this, it is no more true of types than it is of the rest of code: yes, with any part of code the logic is was mattersfunctionally, but humans maintain the code, so if its not written (both names and structure, within the variations that produce correct behavior) for human understanding, its less useful, and potentially useless.> When you're using types as a means to check names you're likely to misuse types.I don’t know what this is referring to. If there is a statically verifiable feature, it is a real type constraint.> When you're using types as a means to check names you're likely to misuse types. Synonyms are a good example of this, where people will make so many types each type only ever occurs once, instead of having a well named variable of a more generic type.Synonyms/aliases (at least in languages I am familiar with) are explicitly not types, but alternate names for types. They aren’t checkable, only the underlying type is. They are useful in much the same way as named constants.
The other day I had to make sense of some Python code that used numpy heavily. It was an absolute disaster to figure out what the code was actually doing because of Python's lack of proper typing.Take for example, the numpy.dot function. This is from the documentation:> numpy.dot(a, b, out=None)#> If both a and b are 1-D arrays, it is inner product of vectors (without complex conjugation).> If both a and b are 2-D arrays, it is matrix multiplication, but using matmul or a @ b is preferred.> If either a or b is 0-D (scalar), it is equivalent to multiply and using numpy.multiply(a, b) or a * b is preferred.> If a is an N-D array and b is a 1-D array, it is a sum product over the last axis of a and b.> If a is an N-D array and b is an M-D array (where M>=2), it is a sum product over the last axis of a and the second-to-last axis of b:So to figure out what this call todotactually does and what it's output type is I need to know the actual types of 2 inputs. Of course, those inputs are the results of other function calls, that arealsodependent on the types of multiple inputs. When reading code you have to manually keep track of each type as you read through it, you have to look up every function to see what it does and what it can return under what conditions.Programming languages are not for computers, they are there for humans to understand what is going on. Python absolutely fails at this because python code is almost totally unreadable. It is at best a write-only programming language.
You're complaining about a library, not Python.
> Static types are very useful for compilers but looking at a function and seeing int -> int -> int -> string -> bool -> int, says very little about the semantics of a program. It's always the names and documentations that tell human beings how to make sense of a program.Sure, agreed, but if a program contains poorly named types then it's a good bet that if types were not mandatory, those authors who could not be bothered with properly naming their types would be equally incompetent at naming their variables, parameters and functions.IOW, if author competence is important for typed programming to be readable, then it iseven more important for untyped languages!
One thing about math heavy fields is that their core primitives are well rounded and concise, you can write complex math formula because you have a mental map of domains and projections.On the other hand every business comes up with its own little world.. and suddenly you're in the dark. Here the need for strong and static typing helps.
datatypes are a great way for making static types.  Python's power is you can use as little or as much typing is right for you.
I've been thinking (and researching) heavily in preparation for a new (offline, desktop) app I want to build. The app has a lot of data wrangling, and probably a decent amount of ML. Python seems like the logical choice, but...I've written a lot of Python, taught classes in it, deployed production code... and I still feel a semi-conscious urge to reach for something else whenever I contemplate starting a new project. Something about its approach, syntax, common idioms, always feels just a tad clunkier to me than I'd prefer. The whitespace makes it hard to paste lines into my repl, and (probably the biggest thing) comprehensions ARE NOT SUFFICIENT replacements for easy anonymous inline functions (JS () => , or Ruby's blocks).I like dynamic languages, I really like the advances in tooling with type checking and LSP support. I like dynamic notebooks (either inline in VS Code #%%, or straight Jupyter), the massive package ecosystem (but obviously hate the actual packaging tools), cool tools like Rich... but it just doesn't make me as happy to use as other languages.I'm still trying to articulate why. Maybe I was just ruined by learning Ruby first.
Unless you have a clear specification for what you are going to build (as in, you have most of your data schemas and processes sketched out), stick with Python and benefit from the development velocity as you figure things out.Then rewrite it later when you need to scale.
I have embraced this workflow completely. I used to be more concerned about which language, but now I find I much more useful to just start immediately in Python. I spend most of the time working out the kinks and edge cases, instead of memory management or other logistics. Maybe ~75% of the time, that's it, no need for further improvement.Recently I chose to rewrite several thousands of lines of Python in Go, because we needed more speed and improved concurrency. Already having a working program and tests in Python was great. After figuring out a few Go-isms, it was a quick couple of days to port it all for big improvements.
When you say tests are you referring to end to end tests, did you rewrite unit tests or did you do some cross language magic?
End to end tests mostly. Those were kept static throughout the process as a baseline and for benchmarking. That let us have simple metrics like "test 1 had a 100x speed up" and "test 3 took a way too long to finish before the rewrite."Any unit tests got rewritten along with the test's relevant code. Now that we are sticking with this Go based solution, adding more unit and regression feels more reasonable now.
This is what I do. Hack it together in Python to get something running, then rewrite everything in C++.
Or even better, rewrite the python code in Rust! Like Asahi Lina did.https://asahilinux.org/2022/11/tales-of-the-m1-gpu/
This works especially well if you test the python version as you go, then run the same python tests against the C++ replacement. The up front bother of pybind or similar is minor relative to not having to recompile the C++ to iterate on test scripts.
Gp was saying their biggest complaint is better in JS and Ruby, so aren’t those just as good for velocity and not for scale?
The same thing can be said about Lisp, Ruby, or JS/TS. Start a REPL, shape things as you would clay.What Python gives you, and what's not easy to get elsewhere, is access to really high performance numerical code, wrapped into quite ergonomic interfaces: Numpy, Scipy, Pytorch, etc. Many other things choose to make Python the glue language, like above, or to embed it (from Gimp to Blender).This makes Python stand out, despite its shortcomings (which are well-known), and make it an even more reasonable interface language for whatever next big thing. Network effect in action.
Notice the rewrite most often will never come when you do this because it will probably not be needed. And if it comes to it that you do need a rewrite, celebrate the success of your project!
+1 for the Elixir recommendation. Whenever I'm looking for ergonomics, I try to look for the functional languages (Haskell, Elixir, Ocaml, Idris, etc.).And since you mentioned dynamic languages and Ruby, I think it might be a really good match for you!
Elixir is nice is you are looking for something new to try.
I recently discovered it. It's pretty amazing for how incredibly easy it is to build distributed applications with it, that is the part which impressed me the most. It handles concurrency well for sure but same program seamlessly across multiple computers is just awesome. I know it's basically just taking this functionality from being built on top of erlang already but it's still very impressive. Plus like crystal if you already know ruby, having tried to base it's syntax on it, it's an easy thing to pick up if you can grasp the functional aspects too.
>> and (probably the biggest thing) comprehensions ARE NOT SUFFICIENT replacements for easy anonymous inline functions (JS () => , or Ruby's blocks).I'm confused by this statement. As I understand it, list comprehensions exist to transform data. Inline functions in JS would be equal to lambdas in python, I.e. anonymous functions. So what differences between JS and python do you think is missing?
Multi line anonymous functions. An anonymous function is just as good as a true function in JavaScript.Lambdas are incredibly limited and encourage the declaration of a whole separate function that now lives physically far from its use.List comprehensions are also really underpowered and I personally hate the map and filter functions and their goofy list-like types.Check out linq in .net, streams in Java, array in JS, collections in scala to see the expressive power of a fluent interface on collections
> declaration of a whole separate function that now lives physically far from its useWhy are you doing that? Just declare the (named) function right there where you’re gonna use it. If it’s any endorsement CPython does it all the time.> I personally hate the map and filter functions and their goofy list-like types.You mean iterators? There’s nothing else they could possibly return. Map and filter are lazy and work with arbitrary iterables even ones that never end or have no possible way to define bind.
> Why are you doing that? Just declare the (named) function right there where you’re gonna use it. If it’s any endorsement CPython does it all the time.I think a lot of people have no idea nested functions exist in python...
And nonlocal, if they want to go to js-land for a second.
Completely agree. Once I discovered Java Streams it became so much more frustrating for me to write Python code that manipulated collections in anything beyond the most trivial of operations.
Whenever I want a lamba that's multiline, I usually just declare a nested function. Usually pretty clear, and reusable, and same scope rules as a lamba
just make a function at that point??
ptpython does a pretty good job of handling pasted code, in my experience.
It sounds like you're incredibly picky. I moved away from Ruby to Python years ago for 99.9% of my professional work. Ruby to me is write once read nowhere. "Professional" developers invent all sorts of creative DSLs to make code impossible to use. Rails is insufficient for a project of modest complexity owing once again to it's 9 levels of hell worth of DSLs. If you follow the prescribed formulas exactly, to the letter, and never stray from the DSLs given in Rails, and Ruby code in general, is fantastic. Once you start to stray you end up in hell.Python has it's faults. Most are handled by a good editor. I only switch from Python when I need something lower level. With Python a company gains:1. Simple language with relatively low ramp-up time2. Reasonably fast with proper tuning. I've been on projects processing impressive numbers of RPS built entirely in Python.3. Comprehensions. You claim they are not sufficient. With them I rarely need to lambda anything. When I do I have `functools` to do any other work.4. A massive ecosystem of libraries, resources, etc.A company loses:1. Projects become difficult to understand at a certain size. This is not properly addressed by even the proper use of MyPy.2. Somewhat more involved testing process compared to it's contemporary - Ruby.To compare apples-to-apples you can even look at the interpreters themselves. Python's mainline interpreter has been able to run CIRCLES around Ruby's for years now. I can understand using something like Go for systems level work, but there are few languages that give you so much for very little investment. Even dropbox was run entirely on Python for LONG time before it became too unruly. That's INCREDIBLE given the simplicity of the language.What you use on your personal time is irrelevant. Your complaints apparently are not experienced by the swathes of companies switching from almost every language under the sun to Python. It's here to stay. At least until Go's ecosystem catches up to Python's. My belief is Go will be the only language to unseat Python at this point. Python will still be around as a "perl-replacement" for basically ever as far as I am concerned.
So, the reasons are:* I’ve been using it for a long time* I have lots of friends that use it* Even though I’m interested in other languages I don’t have time to learn themThese are all perfectly valid reasons! But, they say very little about Python.
This is usually the case with people who use andlikePython, which can be a stubborn take. And I can’t quite put my finger on why Python seems to draw out these sentiments. They usually act like there's some objective reason when the reason is usually because they like Python and simply don't want to learn or use anything else. The concluding paragraph of this article confirms this.> Most criticisms I see leveled at Python are still completely unfounded. Many times the criticism can be addressed by using the language in a different way.Is that true? Functional programming missing, slow, poor module system and REPL, weird scoping, environment and distribution issues, the nightmare that was 2.x to 3.x, tacking on features a la C++, etc.> So be it; if I’m not working in one of those areas, then Python is still probably the best fit for me. I used to hear that Python wasn’t the best at any one thing, but it was second best at most things. I agreed with that line of reasoning for a long time, but these days Python is as good as any of its peers for many things, and it’s still quite effective in many areas where it might not objectively be the “best” fit.This is just weird, especially if one doesn't know or use other modern languages. F#, Rust, Elixir, Ruby, Racket, OCaml, etc.In my opinion, unless Python is being used for scripting, machine learning, or scientific programming, then it's the wrong tool. And I think other languages can even compete with the scripting and scientific programming aspects.
Racket?Racket had a moment a few years ago where it looked like it might take off. That ship sailed. It’s the ruby problem with extra steps.
Yea, and then the Racket team decided to pull the rug out from everyone and rewrite the surface layer (still not anywhere close to complete).But I was mainly listing languages that one should probably look into before claiming Python is a “best fit”.I also would like to know what the Ruby problem is? Is it referencing meta-programming?
The effort you refer to is called Rhombus, it is not a rewriting of any part of Racket, which continues to be developed and supported.I'm not a fan of the new project, since it means the core team is less focused on Racket than they otherwise would be. But, it's their life.
What Ruby problem?
> What Ruby problem?I suspect they mean that Rails gave Ruby its 15 mins. (and why the lucky stiff!) I, personally have no issues with Ruby (I was a very early adopter coming from Perl, C, C++, Python), but find it to be "Python with extra steps" more or less.
I'm a relatively inexperienced developer compared to a lot of people on HN, so I suppose take my perspective with a grain of salt. For context, I started with JS, spent some time with C because I wanted the history/perspective (didn't have a practical need for it, though), then got into bash for purely practical reasons. I also have a bit of experience with C#, primarily with Unity, and C++, because ultimately I'm looking to build audio plugins and applications, but at this point I've done little more than take a tour of those two languages. A year ago I began writing Python because I inherited a lot of code from a former coworker. At this point I'd consider it my main language.I've heard people echo the "Python is the second-best language for anything" sentiment a lot. A bit broad and a touch pithy, but over all I'm inclined to agree. It's a language clearly (and explicitly, as said by Guido) designed to be readable, and I think that more than anything else is why I have a case of the warm fuzzies for it. Compare even a small thing, like f strings in Python vs string interpolation in JS -- f strings are simply less noisy and therefore easier to read. Decorators, when used well, make it a fantastic language with which to write libraries that a user can grok quickly. Etc.If I could design my perfect language, it would be Python, just with clear variable declarations via a keyword such as `var`, optional true static typing and consts, and better tooling -- though, I have to say, after diving in and really learning the ins and outs of venv, poetry, all that stuff, the "Python's tooling is a disaster" meme is IMO a touch overblown; I felt that way as well at one point and in hindsight it was due to me feeling overwhelmed, as opposed to any objective evaluation of the tooling; that said, there is definitely room for improvement.I myself am incredibly interested in properly learning C++, Rust, Go, and improving my JS skills, but overall it never quite feels like the juice is worth the squeeze, because Python really does just feel like "the second best language for anything." And since my interests are pretty wide -- everything from web dev to scripting to desktop apps to audio (well, Python is perhaps theworstlanguage there), most of the time it just seems more practical to figure out a way to do the thing I want to do in Python, especially because there's usually a library for it already. That said, I'm a solo developer at a non-tech-related-industry job, so I'm not rubbing up against many of the same frictions I see discussed so often here on HN.As I said, though, I'm still pretty green and am aware that I know just enough to be dangerous, so I'm very open to hear why anyone disagrees with this viewpoint.
> If I could design my perfect language, it would be Python, just with clear variable declarations via a keyword such as `var`, optional true static typing and consts, and better toolingI highly recommend taking a look at F#. It is functional first, but it is multi paradigm in that it supports imperative and OOP programming just as well. You can write code in F# effectively how you’d write code in Python, if you’d like. F# is indentation sensitive, has sane scoping, the dotnet CLI tooling, modules, pattern matching, easy and regular async, scripting, notebooks, static typing with type inference (meaning you don’t need to type annotate everything), etc.I would argue that of everything Python does, F# does it better and more. So if we accept that Python is the second best language at everything, then F# becomes a rather interesting language to consider.
Thank you! I've always wondered if/when I'd have a reason to check out F#, so now I do! :)Also, after I wrote the above comment, I checked out Nim, and it in many ways is exactly what I was describing. And Cython as well, even for all its (thankfully continuously reducing) weirdness.
One of the reasons for me:* It's preinstalled on my favorite OSBut seriously. I like how fast I can start getting results with it. Sometimes I don't even need to create a file, I simply do "python3 -c ..." or use it as an interactive shell
If you like `python3 -c ...`, you'll love Bash ¯\_(ツ)_/¯
Eh, no thanks.
Thanks for the tldr
Python has only one really serious drawback for the kind of tool it is and its not remotely its own fault: its not a first class resident on mobile.In a different universe its sweet easygoing manner would have created enormous value by enabling all sorts of casual programmers to have some control over this most ubiquitus of computing devices.Alas we dont live in an era where tech aims to empower users.NB: There are a number of projects that allow some of this (kivy, beeware) but they need to swim hard against the current.
Python is weak on front-end web and mobile, but I suppose its impossible to expect Python to be great at everything.  For the number of niches it can fill, I think Python is still ahead.
Nothing interesting happens on the front end anyway.
maybe thats precisely because the frontend has turned into a monoculture. having multiple competing stacks with different pedigrees helps innovation. one example I can think of is the erlang/elixir/phoenix/liveview stack that revisits old patterns and gives them new life.who knows, maybe wasm and projects like pyscript will stirr things up
> Nothing interesting happens on the front end anyway.That's just like, your opinion, man
I know thats a big part of the reason I wish it was accessible natively and frictionless in Python.  I'd like to not learn a whole new inferior language to make a decent UI.
Back in late 2010, we worked with Python for mobile (Series 60, Android, iOS).For consumer grade applications, the issue is slow startup time due to module imports being dynamic and slow.For scripting use case by a programmer, tools exist in Python. However use cases are rare, often better served by Raspberry Pi and others.
> the issue is slow startup time due to module imports being dynamic and slowyes that is still the case e.g with kivy based apps (and apk size too, as you need to ship the entire stack). but such issues could be helped if python was to be promoted to "first class citizen". apparently, at least on the android side, the possibility was considered and rejected early onin any case, whether python or something else, what is missing is easy programmability on mobile. current devices feel more suffocating than Microsoft Windows desktops ever were. you can also see it in the open source app collections in f-droid which I would say is on the underwhelming side.
Most developers need to have at least two languages at their fingertips, so none of them needs to be perfect. What is important is to a spanning set for all the use cases that are relevant to you.I think if we switch from endless arguments about best languages to the optimalpairsof languages we'd book huge gains (and less online noise :-)
Python hasfarmore language features than say, Objective-C.That's not why it has never really been used for mobile development.
and those are....?
Off the top of my head, it lacks decent support for functional programming (like multi-line lambdas - pretty basic functionality even for a non-functional-oriented language!), properly supported static typing, proper multithreading, decent performance (in the main implementation)...
> like multi-line lambdas - pretty basic functionality even for a non-functional-oriented language!Lambdas with one or more statements instead of a single expression (the actual limitation: “multi-line” is a misnomer) are only an issue because python is a strongly statement-oriented imperative language, and not expression-oriented like most functional and some other languages.
Functions are first-class objects.  If you want a multi-line lambda thats just a function.
> Functions are first-class objects. If you want a multi-line lambda thats just a function.Yes, lambdas are just anonymous functions that are restricted to a single expression, no statements. This is a problem for programming in functional style, because python idiomatically uses statementsa lot, and doing a named definition for a single use function is more verbose and less readable in mant cases.
My stylistic advice in that case would be to name it _lambda() (note the underscore that solves keyword issues). Though I don't disagree.
It’s gross to have a function floating off somewhere that has no true reuse value at all and doesn’t live close to where it is used.I like Python but this is probably my biggest gripe.
You can define a function anywhere, including in the scope of another function. So it doesn't need to be floating somewhere far away from where it's used. (This is the idiomatic way to write decorators, for example.)
Why do your anonymous functions have to live far from where they're used? What's the non-aesthetic difference between this:def func(g_func, a, b):
        g_func(a, b)

    def scope():
        c = "c"
        def anon(a, b):
            print(a, b, c)
        print(id(anon))
        return func(anon, "a", "b")and this:def func(g_func, a, b):
        g_func(a, b)

    def scope():
        # NOTE: The `|a, b|: (...)` syntax is made up
        c = "c"
        return func(
            |a, b|: (
                print(a, b, c)
            ),
            "a", "b"
        )?Note that the `anon` function in `scope` is only compiled once. You can verify this by copying the first version to a file named `temp.py` and then running `python -m dis temp.py`. You can also run `scope()` twice in a row and see that the same object ID is printed both times.That said, for purely aesthetic reasons, I would like it if Python had some kind of syntax like version 2, but that's tricky with significant whitespace, and I've never found the lack of such syntax to be particularly limiting in Python.
I think its gross to try to inline a multiline anonymous function usually inside of what should just be a function call.
I mean, it is Python, if you are using it you aren’t aiming to be super-lean, right?Apparently it is possible to delete a function.https://stackoverflow.com/questions/10367414/delete-function
You can delete references to any object in Python, including functions:>>> def f(): None
    ...
    >>> del fbut it's pointless to try to manually manage memory in Python inmostcases. If you're processing huge amounts of data, there are probably better approaches than using `del` and/or `gc.collect()` to keep memory usage down (like batching and/or using subprocesses).My other comment in this thread is relevant too:https://news.ycombinator.com/item?id=34197904
This is how we end up with another Swift.
Python's been my main language for 22 years now.Whenever I think I should switch to faster, more efficient language (C#/Go/Rust/...), I am repeatedly blown away by what Python lets me do, with an incredibly ecosystem of packages, and all the ergonomics of incremental development from a REPL.Case in point is my current project: building a parser for PDF bank statements from all UK banks. I can match a 10page bank statement against a library of 100 templates, and then extract its data in a standardised format, in around 50ms per statement.That's broadly comparable to the time for load the source file from cloud storage.And that 50ms is processing pages sequentially, using a single core on my little laptop. Plenty of scope to parallelise if I wanted to.The reason why I'm still using Python, to borrow a slogan from Bruce Eckel long ago, "Python fits [my] brain".
50ms doesn't sound especially fast. If you had a million of them to process thats 4 hours, maybe an hour with some parallelism? A 100x speedup from going native then becomes quite welcome. Python has its place, but the fact you even think the tens of ms domain is "fast" or even fast enough on modern CPUs shows the real strength of Python, which is most people dont actually care at all about performance. Thats not to say its performant though. Just that no one cares anymore. Some rando boss is happy to wait 4 hours for your script to chug through a million statements, because no one actually told them it can take 2.5 minutes in a native language. If they did maybe the boss would suddenly speak about their dream to not only process the data but have a near real-time BI panel instead of a batch report so they can react within one business day. The issue with Python is missed value, not the value it can deliver.
Why limit parallelism to 4x? Spin up a ton of lambdas and get it done in 10 seconds.You're also forgetting that 50ms time to load each file from cloud storage. It's still 4 hours and 2.5 minutes with your native code compared to 8 hours with Python. Suddenly not such a massive improvement.Even then I don't see the issue with it taking 4 hours to do a million of them. Do you need to do a million per hour? Is it even likely they'll need to do a million of them total?Do bank statements even come in frequently enough to do a realtime dashboard with? I get my bank statement every 30 days.How much longer does it take to develop the native version? How much longer does it take to modify when a bug is found or a bank changes their statement layout? How much more do you have to pay a native code engineer compared to a Python dev and how easy are they going to be to replace eventually?
One dimension to consider here is cost of compute.Going from 8 hours to 4 hours is a 50% reduction in the time to compute and we're assuming this is occurring on the same relative hardware/instance size.At scale, that could translate into hundreds of thousands of dollars in savings.But your points are relevant - as with anything related to development, "it depends" rules the day. There isn't a clear cut "x is objectively better than y" in general.
> The issue with Python is missed value, not the value it can deliver.I'm very aware of the business value here! The limiting factor in these types of "messy real-world data" problems is the developer time to get 100+ templates right on all the different variations encountered in the wild. I can iterate on each template extremely effectively in a Jupyter notebook REPL, and immediately rerun a sample of 100 statements for that bank in a few seconds.While the total corpus of statements I have access to is actually around a million, no one cares how quick processing them all are if the extraction isn't reliable enough!
Exactly. The time spent developing a solution for your problem in pretty much any other language is going to cost magnitudes more than processing millions of documents in python. And that’s ignoring the ongoing maintenance where the hackability of teasing data out of PDFs in ipython is going to top any other system.I have a soft spot for the work you’re doing since I’ve spent a good portion of my life now extracting data from PDFs and can appreciate the joys of the process more than most.
> If you had a million of them to process thats 4 hoursIf you had 20 bank accounts sending you monthly statements for 100 years you'd have 24,000 of them.  50ms each would take you 20 minutes to process the 100 year backlog.If you have a million of them to process then you're a bank or similar type of institution that can devote resources to this, either computational or developer time to optimize things.  A 128 core c6a.32xlarge would turn the runtime from 4 hours into 1.9 minutes and cost $5 to run for an hour.
I agree with your reasoning and your insight about missed value is valuable, but this is not a Python problem. It's a scaling problem.You can solve scaling problems in many different ways with different costs. Any reasonably sized company has a Kubernetes cluster, just launch 10 instances and you're down to 24 minutes instead of 4 hours. You could also buy faster hardware. You might increase single-node performance by rewriting in a performant language (this won't help much if I/O is the bottleneck though, which often is the case). Talking to your data supplier to check if they can send the data in a machine-readable format is probably also something to consider. Or you might conclude that any effort is not worthwhile at all. Who knows?Scaling problems are not be avoided as a negative thing, they're beautiful and ought to be celebrated. What's not beautiful is letting the thought of potential scaling problems lead you to make decisions that optimize for long-term results instead of short-terms results.
I understand where you're coming from, and I do care about the climate as much as the next person, but this comparison seems downright silly. Basically, for your example to work every single person have to run the same script every week and wait for 4 hours. Are there even that many bank statements? And then, if you, your spouse, and a child take a single flight coast to coast, round trip, that is 4.5 tons right there.
My problem with Python, especially when reading someone else's code, or my own old bad code, is that I find that Python doesn't fit [my] brain.The lack of typing (in my experience you always end up with a bunch of libraries that don't have type hints) means I spend most of my time just figuring out what I'm supposed to pass to a function (I hate the django docs. Give me something like docs.rs where I can quickly scan what functions something implements, and see what they accept and what they return instead of forcing me to read an 800 page novel that STILL doesn't give you that basic info), and writing tests and trying to guard against passing the wrong thing around.
> The lack of typingIt's gotten a lot better with type hints and typeshed, but I agree, not knowing what type an arg should be and hoping duck typing works out isn't great.
In my own code, I always use typehints and write good docstrings (nearly) everywhere.Visual Studio Code's type checker saves so much time and has improved my code quality to no end. It is especially powerful on polymorphic inputs, making sure the different code paths operate on the input type you expect.
PyCharm is good for this too.I've recently started using Type Hints by default. At the very least, it makes your code more readable. Nothing bad comes from that.
I started enforcing type hinting in my personal projects. 99% of the time it's easy and useful to add. When I can't figure out how to make a mypy error go away within 30 seconds, I just disable it for that line. I feel this makes for very good 80-20 value/effort tradeoff.I will say that more than one bug has been found after I disabled the single line hint though! Always surprising to me how powerful types can be.
I do not see the benefit of type hints. Good docstrings (and naming of the function and arguments) are superior, at least for the human.
Type hints are too much clutter.
> type hints are too much clutter.Any sufficiently detailed python docstring contains an ad hoc, informally-specified, bug-ridden, slow implementation of half of a type annotation.
Which suits duck typing better than type hints.
There’s a certain program size from which they start to make sense and further still the benefits are obvious - you have a computer to help solve puzzles for you, so why not use it if the puzzle is ‘will this peg fit into that hole?’ when you have thousands of pegs and holes.
And so you end up writing climb_the_wooden_ladder(l: WoodenLadder) plus climb_the_aluminium_ladder(l: AluminiumLadder) or press all into an OO hierarchy instead ofclimb(thing):
'''Climb a thing with steps'''
# prevent run time crash:
if not hasattr(thing, 'getSteps'):
    hitDeveloper()
No, you define a Ladder (or Climbable if you’re feeling fancy today) Protocol and all remains good in the world.
No need for OO hierarchy, just use a protocol
Oh, I missed the Protocol class of the typing module. Have to further investigate the usage of this.Thanks to you and baq!
Docstrings are great until you change your mind about something fundamental.Once you make that big scary change you might have to rerun your unit tests dozens of times before you've found and fixed all of the bugs that your change caused.A static type checker, plus a bit of foresight and diligence, will give you a much more complete view of the carnage up front, so that you have a good idea about the cost of making that change while it's still cheap to decide differently.And the best part is that with python you can only bother with the type hints where you need them (e.g. at the boundaries between teams)
Never experienced that. Maybe you should make your code more modular.
I agree with you there.  The experience I was thinking of here involved taking a codebase which wasn't modular enough and making it modular.  So the "big scary change" involved changes to the module boundaries (which are the only thing I bother with type hints for anyhow).
I have a fear that Python will be improved to the point it offers no more advantage over other languages.
Docstrings won't tell you if your code is valid or not. Type hints with proper linting will. Shorter feedback loops = increased productivity.
Since I'm programming in Python, I experienced invalid code only in very few cases, more or less just where the function expected an iterable and I gave a string instead of a list of strings (typing errors are well prevented by the colour hints e.g. neovim gives with the right plugin).And some libraries sould be better documented.But the compile time error messages of C or C++ or Delphi most of the time do not deliver a shorter feedback loop, because they are generally ugly and hard to understand.
And you should write tests in all languages, so static typing isn't a timesaver in that respect, too.
>Case in point is my current project: building a parser for PDF bank statements from all UK banks. I can match a 10page bank statement against a library of 100 templates, and then extract its data in a standardised format, in around 50ms per statement.I'm interested in management of domestic documents and similar institutional correspondence, and I'd love to hear more about how you approached and solved your problems with the PDF bank statements.I have lots of bank statements ... and other documents like utility bills, rates invoices, etc ... and I'd love to just be able to feed them to a script and automatically tease out salient details.
Plenty of languages have a huge package ecosystem. Your problem is that you don’t know them. I’m not saying the distinction is helpful for your situation, but your problem is “I have too much time invested in learning Pythons ecosystem” and not “other languages don’t have all the packages I need.” For REPL that’s another mindset. You use a REPL to experiment and prototype, I use unit tests. You use python because you already learned it. Your brain has been fit to python, not the other way around. You can fit it to other languages if you choose. I am currently learning my 7th “use in production” language.
You're partly right. However Python's sweet spot for me is when writing code to process complex, messy, poorly understood data. Using a Jupyter notebook lets me keep partially processed inputs as live objects, examine and change their in-memory representations, and quickly prototype the next stage of processing. It feels like sculpting with playdoh.Once that's working, the code moves from the Jupyter notebook into a proper code module with unit tests. Then the emphasis is on building the production system rather than manipulating the data.I get what you mean with unit tests. Just for me it feels further away from the data, which is where most the complexity in my business domain lies.
Sure. I do use Jupyter in a decent IDE for some adhoc data diving or for a spike prototype before “downcoding” into a cluster.
I have Python analytics capturing HTTP Headers, processing them, and finally storing them in less than 8ms on a single core dev instance. Python is plenty fast for many things.Also, I love the syntax. It reads like a sentence.
> in less than 8ms on a single core dev instance. Python is plenty fast for many things.What’s that, nowadays? 25 million cycles, 75 million instructions?Python isn’t plenty fast, modern hardware is.
More precisely, modern CPUs are so much faster than network or file I/O that if your program has to wait on I/O, the CPU is going to sit idle most of the time anyway, so trying to optimize CPU time is pointless. The GP's use case is an example: he's capturing HTTP headers, so the bottleneck is network I/O, not CPU. So Python for his use case is, as he says, plenty fast.For use cases where CPU is the bottleneck, such as numeric simulations, Python users reach for something like numpy, where all the CPU intensive stuff is being done in C extensions, not Python bytecode.
The person you’re replying to is saying that Python meets their needs. Judging by what they’ve said about their use case, I doubt it’s a meaningful affirm to their overall pipeline.Your counterpoint is that it’d be slower if it were running on a Pentium 4.  Do you honestly think that they don’t know this?Yes, this is precisely the point. Things are at a point where Python’s benefits are worth more than what another language would bring in speed improvements. I imagine that there would be less of a benefit to busses if we had to Flintstone them everywhere instead using a combustion engine. That’s not the current reality though.
Let's have a contest then. Pick a (relatively simple) web product and your "fastest" language. I bet I'll build it faster with pure Python.
There's no need for a dick measuring contest, there are plenty of life-like benchmarks available online that show Python is agonizingly slow.> I bet I'll build it faster with pure Python.What? We're talking about runtime speed, not development time...
You said: "That sounds insanely slow."Anti-up.
When building a large system, the choice of language is always non-binary. You do not have to commit to one and only one language for the entire system. Python offers a great stating point for most cases.When you scale, certain modules will start becoming the bottlenecks. At this point one can just re-write the given module as a sidecar and Python by design is easy to bind external libraries.
How are you matching a file to a template like that?
One ofthesingle language features that makes me stay with python is list comprehensions. So maybe something like that:stuff = [cleanup(s) for s in stuff if s.unprocessed]This, the way you can handle/manipulate strings and the powerful included libraries make python a good language.Downsides?
Dependency managment, tooling, speed
I have a completely opposite reaction, one of the things I hate the most with Python is its list-incomprehensions. They quickly become hard to read and very imperative, instead of declarative. Something like stuff.filter(it.unprocessed).map(cleanup(it)) conveys the intention behind each statement a hundred times better. And list comprehensions becomes impossible to reason about once they involve flatmapping or other relativesimplefunctional expressions.
I agree very much so.  List comprehensions and can be nice and concise and readable in many situations, but due to the whole "one true way" thing in Python, they're used in every situation, even when a map/reduce/filter etc would be better.  Although since there are no pipes, I sorta get it.
Yep. What bothers me is when you start looking at list comprehension is that you don't know if it's filter(), map(), or a combination. You have to read the list comprehension till the end to understand.
Definite agreement. I started a long time ago with Python2, and what attracted me was how simple and readable the syntax was.With Python3 there is a move towards "idiomatic" Python code, which to me means moving away from clear and concise to the old programmer trap/readability nightmare of "look how many things I can get it to do with one line of code!"
Let's not even talk about those insane people who use nested list comprehensions.Not sure if it would make my top-5 Python-hate list (1-4 would probably be dedicated to packaging and distribution), but list comprehensions definitely feel like a misstep that contributes little value to the language.
You can easily replace this with various forms of map/filter in many other popular languages. Assuming cleanUp is a single-argument function/static method:// JS
    stuff = stuff.filter(s => s.unprocessed).map(cleanUp);

    // Java
    stuff = stuff.stream().filter(s -> s.unprocessed).map(Main::cleanUp).toList();
    
    // C#
    stuff = stuff.Where(s => s.Unprocessed).Select(CleanUp).ToList();Java streams and C# LINQ extensions also expose other nice data processing functions, eg. sum, takeWhile, distinct.And if you like Python’s dictionary comprehensions:{str(n): n * 2 for n in range(1, 11)}you can use ToDictionary in C#:Enumerable.Range(start: 1, count: 10).ToDictionary(n => n.ToString(), n => n * 2);
These are also easier to read and write than the Python version, as you can just follow the dataflow from top to bottom (or left to right if it fits into a single line). In Python, your eyes have to jump around to find where to the next bit of processing happens, not just in comprehensions but also with map/filter/list/len and co which are freestanding functions for some reason.
Sure you can do that and I use things like this all the time in other languages, but the python example was very basic. There are other cases that are sometimes harder to reproduce e.g. when iterating over dictionaries to create a list, when you have tuples  etc.
All Python list comprehensions do is [(expression involving foo's) for foo0, …, fooN in (iterable) if (expression involving foo's that should return a boolean-ish value)]. Nothing more, nothing less. Nothing that can’t be expressed by filter-then-map.So, given the dictionary {"a": 1, "b": 4, "c": 2}, if you want ["b=4", "c=2"], you can do this in Python:d = {"a": 1, "b": 4, "c": 2}
    l = [f"{k}={v}" for k, v in d.items() if v % 2 == 0] # replace [] with () if you want a generator instead of a listOr this in C#:var d = new Dictionary<string, int> { {"a", 1}, {"b", 4}, {"c", 2} };
    var l = d
             .Where(pair => pair.Value % 2 == 0)
             .Select(pair => $"{pair.Key}={pair.Value}")
             .ToList(); // remove this if you want an IEnumerable<string> instead of a List<string>The Python version has tuple unpacking, whereas the C# version iterates over KeyValuePair<TKey,TValue>. Slightly more typing, and perhaps slightly less ideal if you’re dealing with tuples without field names, but still pretty readable. The C# solution is also more obvious about the execution order.And if you want to sort the output by the dictionary value?l = [f"{k}={v}" for k, v in sorted(d.items(), key=lambda kv: kv[1]) if v % 2 == 0]
    #    5              3       2      1              2a                   4           <- Execution order

    var l = d                                             // Execution order: 1
             .OrderBy(pair => pair.Value)                 //                  2
             .Where(pair => pair.Value % 2 == 0)          //                  3
             .Select(pair => $"{pair.Key}={pair.Value}")  //                  4
             .ToList();                                   //                  5
It's the opposite, I feel. When the cases are not basic, the python way gets even messier. Or do you have any examples?
“You can…”Sure, but the Python code is so much nicer.I don’t even like Python all that much but it’s comprehensions and generators are very sweet.
I find the non-Python versions easier to read, since they show the exact data flow in order (instead of Python’s [3 for 1 if 2] order) and they allow more advanced scenarios.
I almost always prefer to read nested loops and conditionals than list comprehensions.I find the syntax of list comprehensions ugly and inscrutable.
Another effective technique for making readable, maintainable code is to break the list comprehension out into a generator (as a closure):This example…:a = …
  vs = [
    v(x)
    for b in a.f()
    for x in b
    if x and c1(x)
    and not c2(x)
  ]…becomes:a = …

  def each_v():
    for b in a.f():
      for x in b:
        if not c1(x):  # comment
          continue
        if c2(x):  # comment
          continue
        if x:
          yield v(x)
        
  vs = set(each_v())Line orienting each conditional makes commenting much easier.  The collection used forvsis clear.  The formatting is less susceptible to being churned up by black.  You get to give the thing a name, which helps.
Additionally I find that it's easier to add complexity to the loops; once you want to start doing nontrivial things in a list comprehension, you often need to rewrite it into a loop first anyway.
> It's easier to add complexity to the loopsThis is basically selling point for comprehensions. You can't add complexity to them so any comprehension you see fits a few common loop patterns you can grok immediately.If you see an actual for loop in python it means "pay attention something odd is probably going on."
I feel like this is a lot cleaner and more clear in Ruby:stuff = stuff.map {|s| cleanup(s) if s.unprocessed }.compact
Only knowing Python and not Ruby, your snippet looks confusing to me.1. What does the anonymous function return if s.unprocessed is false?2. If it returns nothing, do I get a missing value element in the iterable that results from map?3. And what does it mean to compact the result of the map call?The Python snippet raises none of these questions in me. But it could be because I am familiar with Python’s quirks.
The compact gets rid of all the null values returned when unprocessed is false.Interestingly I wasn't exactly sure what the python code would do, which is why I used the compact. In the python code, does 'stuff' end up only having the result of the cleanup function for items that are unprocessed? Or will it have all of the items, and the ones where unprocessed returns false just end up being returned unmodified?My Ruby version returns the processed subset of items that were unprocessed. The python version was not clear to me, since I don't know what happens if s.unprocessed returns false.So basically, it sounds like we were both confused by the same parts of the language we are unfamiliar with... what happens to elements where s.unprocessed is false? It was clear to me that in Ruby it returns a nil, but I have no idea in Python... what happens?
Huh, our mutual confusion is interesting indeed! Thank you for teaching me something about Ruby. What compact does makes sense.Python’s list comprehension combines map and filter.[process(s) for s in stuff if s.unprocessed]is equivalent tomap process (filter isUnprocessed stuff)in Haskell.
Nothing, literally. This is map+filter optimized (or a for+if+append but using dedicated opcodes for efficiency) so you don’t have to do multiple passes and/or create temporary lists with superfluous elements.
I feel that this is not the case.
List comprehensions are great but certainly not unique to Python.
C#'s LINQ is far more powerful in my opinion.
I like list comprehensions now after having used the language for a while, but I will say they were the hardest for me to grok when I was first learning the language. even now it can be difficult to follow what's going on if you have nested ones.
I love list comprehensions but my brain starts melding with nested list comprehensions. The syntax is not obvious and I have to Google it and figure it out again 100% of the time. The JavaScript .map() method is much easier to understand.
List Comprehension is just syntax for functional coding (filter, map) but a very good one!
I may be the outlier here, but I have a very hard timecomprehendinglist comprehensions. They've always seemed like a SQL query compressed into a single line (or two if you're lucky!): readable when it's simple, Lovecraftian when it's not. I've always found the functional pipeline style much more readable and much easier to explain to others, especially with IDE type hints.
SQL queriesaresequence comprehensions!Python comprehensions in particular are unfortunate because the flow of the query, like in SQL, is not linear - the projection part is written first, but happens last. Thus, reading a non-trivial query requires moving back and forth to resolve the references.Compare that to C# LINQ, which is also a kind of sequence comprehension. That one not only has linear syntax where the data flow in the query is strictly left to right, but it's explicitly defined by mapping it to functional pipeline style. Thus, it ends up being a strict improvement on the latter.(Another example of "good" sequence comprehensions in this sense is XQuery FLWOR)
> they’ve always seemed like a SQL query compressed into a single line (or two if you’re lucky!):If its more than a very simple expression, with one simple for, and no if or very simple if, I try to use at least (more, with parens, if necessary): one line for the result expression, one line for each for clause, and one line for each if clause.But, while the boundary is subjective, it doesn’t take much before functional pipeline style is clearer (Python lambdas being more limited and syntacticaly cumbersome, functional pipeline style isn’t as clean in Python as it is in other languages, though.)
IMHO the key to legible comprehensions is to use them only to express composition and to put the logic into verbosely named functions.Chained pipelines (`foo.filter(...).map(...)`) are fine to me, certainly more verbose then comprehensions for better & worse, but I get lost in pipelines expressed as nested functions (`map(filter(a, ...), ...)`).
it depends on your problem but in many cases simple is enough imho. There are map and filter in python avalaible. I just didnt need to use them.
Being pedantic: This isn't true in Haskell, because list comprehensions can use pattern matching, while map+filter can't.heads :: [[a]] -> [a]
  heads xs = [y | (y:ys) <- xs]

  -- heads [[1],[],[2,3]] == [1,2]Doing the above using maps and filters looks very different:heads' = map head . filter (not . null)Python doesn't really support Haskell-like pattern matching, so the above doesn't apply.
The thing you're looking for is easily found with a Hoogle search for type(a -> Maybe b) -> [a] -> [b]Which yields mapMaybe:https://hackage.haskell.org/package/base-4.17.0.0/docs/Data-.... so you end up withheads = mapMaybe safeHead
That doesn't look like a direct substitute that covers every case.
> Python doesn't really support Haskell-like pattern matchingIt does as of 3.10:https://peps.python.org/pep-0622/Not as sophisticated as what Haskell can do, I'm sure, but I think it's a good addition to Python.
Sorry, but Python list comprehensions are not very good compared to other languages.
why?
In F# list comprehensions, for example, you can have full blown expressions such as loops and conditionals. This is really nice for templating.[
      if List.isEmpty items then
        p “No items”
      else
        ul
          [
             for item in items do
               li [ item ]
          ]
    ]
so?if len(items) == 0:
    return [p("no items")]
else:
    ul(
        [
            li(item) for item in items
        ]
    )I am also not a fan of convoluted list comprehension (in python) so powerful is not necessarly a good thing.
That only works in a single purpose function.And consider this example:[
      h1 “items”

      if List.isEmpty items then
        p “No items”
      else
        ul
          [
             for item in items do
               li [ item ]
          ]
    ]
h1(items) + rest of my code...
I might see what are you using for but I am not sure if concenating implicitly (or with line breaks / spaces) is a good design decision for a language.
The yield keyword is optional. The result is a List<HtmlElement>I don’t see how this can be done in Python without using mutation, which makes code scattered across multiple statements
your example has also multiply statements. The question is more important: Which syntax to a more generally better readability. (as this is solvable in most languages)
No, it is built from pure expressions. This means that our list is defined in one block (everything within the [ ] tokens) and immutability is enforced by the compiler.
> Downsides? Dependency managment, tooling, speedWhat's wrong with its tooling?
Have you tried Haskell vor Scala?
It's the ecosystem. All languages have libraries for bottom-up parsing. But few are as well-documented, feature-full, and easy to use as SLY:https://sly.readthedocs.io/en/latest/Many languages have libraries for ANSI color support and pretty printing, but no other language has Rich:https://rich.readthedocs.io/en/stable/index.htmlWhile other languages may have rudimentary datetime support, Python has (multiple!) libraries for converting between Hebrew, Hijri, Coptic, and Armenian dates.
> Many languages have libraries for ANSI color support and pretty printing, but no other language has Rich:https://github.com/ajalt/mordant
You are making my point for me. :) That library is nowhere near as well-documented and feature complete as Rich.
They should put energy labels on programming languages. It’s convenient to use Python, but a waste of cpu cycles
A group of researchers published a paper on this topic, "Energy Efficiency across Programming Languages" [0]. They have tables listing the relative energy usage and memory consumption.It's just one paper of course, but the energy results weren't too surprising. C was the baseline. C++, Rust, and Java close behind. Languages like C# and Go near the middle, and then Python, Ruby, and Perl at the bottom for most energy used.[0]https://greenlab.di.uminho.pt/wp-content/uploads/2017/10/sle...
I only skimmed it, but it looks like they forgot to account for the extra energy used to run the coffee pot, for the programmers using less productive languages.
the brain is pretty expensive to run
This got a reasonable amount of attention, but it’s not particularly relevant. The example solutions would never be written in pure interpreted Python - you would import numpy and use the numeric functions from there, effectively using C rather than Python.
You seem to favor human brain cycles over CPU cycles. Conversely, time spent on memory management and pointer arithmetic is time that could’ve been used to add value to the world.
Well for code that gets executed billions of times spending more human cycles seems a fair trade off. For boring old corner shop crud, maybe not.
Most code isn’t fire and forget though. Bugs occur, requirements change. The human cycles are a perpetual investment. And Python is simply very, very maintainable.I do agree that there is a point where the scale tips. I wonder where that is, and what kind of application we’re talking about then. Many applications are at their basic level old corner shop crud, really.
> Well for code that gets executed billions of times spending more human cycles seems a fair trade off.Do you feel the same way about (e.g.) modern mechanized farming compared to classic farming that used human labor (generally unfree and unpaid labor, such as serfs or slaves)?"Efficiency" is not the only goal that matters.
I don’t get your analogy.Comparing manual labor to industrialized farming is comparing (paper) accounting books to programming.Whether you add gps based differential seeding to just doing it by ‘feel’ but still with machines is the difference of programmer brain cycles. Efficiency is not all obviously and there are different efficiencies one can find relevant. Why is this controversial?
You're advocating for more programmer work and less machine work. The situations are exactly the same. Just because programming is "brain work" rather than "muscle work" doesn't somehow make it not work.
You not saying you are not a troll does not make you any less of a troll.
You suggesting that I am a "troll" does not exculpate you from answering the question.Your argument is that programmers should use less-convenient and more painful languages to save energy.The argument that agriculture should be performed by unpaid peasants or slaves is exactly the same.Edit: it doesn't actually matter if they are paid or not (although they generally weren't).The history of human progress is pretty much defined by using energy to replace human scutwork.
On the other hand, when you spend more programmer hours on less productive languages, those programmers end up having a larger energy and natural resources footprint with the increased amounts of money paid out.99% of programming projects aren't "web scale" and the development costs far outweigh the operating hardware costs.
Why hasn't anybody created a more efficient version of Python? Slap some static types on that baby, get rid of the heavy runtime, and you've got a good start toward something special.
There are more efficient interpreters and compilers, problem is they don't work with the existing libraries. If you mean another language, there is Lua for scripting purposes and Julia for math stuff. JavaScript also exists, which despite its fame it is actually MUCH faster than Python, and you can even run it in a runtime such as bun.js and get even more out of it.IMO the biggest problem is that the Python libraries ecosystem is just too good to miss out on. I absolutely hate Python but even I have to admit it is much easier to do some stuff in Python compared to other languages simply because of the libraries available to do basically anything you could dream of.
Python performance, both single core and concurrent, seem to be its primary Achilles heel. However, Python is unmatched for developer speed in compute heavy AI / ML since it uses C, etc., under the hood. I don't really like Python but it's impossible to avoid in data science because you don't have to re-invent the wheel.Several languages have persisted beyond their natural shelf life due to their library ecosystems. For a period of time, CPAN was one of the best arguments for using Perl. More recently, Java's ecosystem is also a pretty good reason to use Java right now, even if you don't like the language.Languages seem to thrive early due to initial ease of use (Python, particularly, but also relative uptake of Go vs Rust), but can wane due to a thousand cuts (or sigils in Perl's case).
> However, Python is unmatched for developer speed in compute heavy AI / ML since it uses C, etc., under the hood.John Carmack seems to think otherwise.> "That means that in the time that Python can perform a single FLOP, an A100 could have chewed through 9.75 million FLOPS"https://twitter.com/id_aa_carmack/status/1503844580474687493...
Am I missing something?The OP's comment is that while Python's native interpreter is slow, Python code as a whole can still be fast since people will delegate the hot spots to non-Python libraries optimized for speed.To refute that, you linked to John Carmack quoting Horace He saying that Python's native interpreter does CPU-based math slower than a GPU. But...that's why people writing Python use libraries to delegate math-intensive work to a GPU, which is the OP's point.
If one is forced into writing code that needs to be fast in a language other than Python, then I'm not sure I understand why Python gets to claim any credit?
Slight nitpick: the credit that was being claimed is that Python allows fast developer speed while not sacrificing overall runtime performance.The code that is written in a language other than Python is often not written by the developer writing the Python code.As an example, I've been fiddling with inferring automatic data extraction rules for data in scraped webpages.The meat of the algorithm and its heuristics is in Python. The heavy lifting of parsing HTML and evaluating CSS selectors is done by a C parser that I did not write. For me, prototyping the heuristics in C would have been quite a bit slower.
I generally respect Carmack, but it's clear he wasn't considering Jax or even numpy, but just python flops.  Jax code running on TPUs often reaches order of magnitude of the hardware's capabilities.
Wouldn't surprise me if a subset of Python compiled to asm.js would run faster in V8 than cpython.
But would this "subset of python" be actually useful?Once you break compatibility stuff doesn't work… and a fast python that can't run my software is less useful than a slow python that runs the software.
> Wouldn’t surprise me if a subset of Python compiled to asm.js would run faster in V8 than cpython.I’m certain that there existssomesubset of python for which this is true, but so what?
Probably doesn't have to be a subset. Call back to cpython for the really dynamic madness, much like a jit tiers back out of machine code when assumptions don't hold.
Nim [0] might be one similar example. Similar syntax as Python and trying to be just as extendable as Lisp.[0]https://nim-lang.org/
> Why hasn’t anybody created a more efficient version of Python? Slap some static types on that baby, get rid of the heavy runtime, and you’ve got a good start toward something special.The biggest strength of Python is an ecosystem built on a blend of python code and native extensions, leveraging Python’s strength as a glue language. Dumping the runtime while remaining compatible with the extension ecosystem is quite a challenge, as is adding static typing and taking full advantage of it whilealsomaintaining compatibility with existing ecosystem of code which is a mix of untyped and typed in the existing (optional) type system.Which is probably why most “more efficient” Python efforts don’t try to do both of those things. Somedid, or at least replacing the runtime, but most of them fizzled, not because they didn’t offer benefits, but because burning access to the existing ecosystem wasn’t worth those benefits. OTOH, what we see now is efforts to improve the base interpreter while maintaining compatibility, and opt-in compilation tools that can be used within Python, with a subset of Python or a statically-typed Python-like language that builds to extensions for the Python runtime. Examples include mypyc, Cython, Numba, etc.
Also languages like OCaml, which while less known, are still getting improvements all the time. This was an interesting blog post series from a few years back:https://roscidus.com/blog/blog/2014/06/06/python-to-ocaml-re...
https://github.com/py2many/py2many/blob/main/doc/langspec.mdReimplement a large enough, commonly used subset of python stdlib using this dialect and we may be in the business of writing cross platform apps (perhaps start with android and Ubuntu/Gnome)
You may be interested inhttps://en.wikipedia.org/wiki/Cythonwhich was a fork of Pyrex which dates back to the very early noughties.  It is basically as you describe and even has a way to "bypass the GIL" in extension modules.  There is also an easy way to create a "compiled script" using `--embed`.  This is essentially a gradually typed system [1] like the Common Lisp `declare` facility.  Cython even has a warning system to tell you what you forgot to declare, and an annotated HTML generator to highlight "more Python C API heavy" portions of your code.Personally, I think going all the way to Nim [2] is more satisfying than a "gradually typed" system, though.[1]https://en.wikipedia.org/wiki/Gradual_typing[2]https://nim-lang.org/
There are several "close to python" languages like this, actually, I remember one popping up on HN semi-recently.If you expand into just "kind of Python-like", you have languages like Nim that approximately fill the hole of "efficient Python".My impression, though, is a lot of the popular frameworks/libraries for Python lean heavily on runtime reflection in Python (e.g. Django). So people end up stuck to the full Python interpreter/runtime.
Nim has impressive compile-time reflection which with its syntax macro system can (some of the time) get you similar powers to Python's dynamic reflection.  E.g.,https://github.com/c-blake/cligeninstead of `autocommand` or `click` or `argh` or you name the automatic CLI generator, only with full C-like speed for your programs and a very low effort FFI to C.  People have done web frameworks, too, but I do not know them well enough to compare to Django.  Perhaps someone else could follow-up.Compile times are not the 25-50 ms of a Python interpreter startup, but they are similar to the 250-500 ms of a Go or D compile, at least for small light on metaprogramming loops kinds of programs, and with, say, the TinyC tcc backend.Of course, big frameworks take a long time to import (or to compile).  So, your comparison mileage may vary.  And once "ready to go" and finished a Nim program can start up in sub-millisecond time like any C program (esp. if statically linked).
I consider Ruby to be quite similar to Python. However, it's kind of like Python's weird brother, with optional parentheses for calls without arguments, auto-returning the result of the last expression, and some odd-ball syntaxes. It manages to be even less efficient, though.
As someone who probably has more experience with Ruby than you do, and probably less with Python, I'd characterize the relationship as inverted -- Ruby is more consistent than Python.In Ruby, parens are optional for all methods, and only required if you need to force non-default precedence.Returning the value of the last expression seems reasonable to me (just like a UNIX shell).In Python, I'm bothered by the little inconsistencies. Why is str.len (or length, or size, or count, etc) not a method? Why len(str) instead?And Python has plenty of oddball syntax: significant whitespace, triple quotes?? You get used to it of course.Ruby and Python are about equally efficient -- if you're optimizing for code efficiency, both are bad choices. In many domains, that's not a critical metric, so we talk about developer efficiency. I'll argue that developers are more efficient when they are more happy, and for me that selects Ruby by a mile over Python.But I won't pretend that it's more than a matter of taste. :)
I feel very similarly about Python vs. Ruby inconsistencies! I remember starting a job and used python for the first time coming from Ruby, and being extremely disappointed in the inconsistencies in the standard library and the sheer… lack of features in the Stdlib compared to Ruby. I’ve yet to use a language with such a magnificent stdlib and documentation. I main python nowadays, and I find the ecosystem and typing to be better than Ruby, but Ruby is the best language I’ve ever used for many reasons
> And Python has plenty of oddball syntax: significant whitespaceYes. Especially this. The whitespace thing in and of itself has kept me from ever developing a fondness for Python. Clearly there are plenty of people who aren't bothered by it. De gustibus.
Significant whitespace is probably my favorite feature of Python, which might have to do with the German keyboard layout making it very cumbersome to enter curly braces.
Maybe not oddball syntax, but rather syntax that doesn't make intuitive sense. With Python, only nested list comprehensions come to my mind that are a bit tricky to read. With Ruby, I often felt lost reading code and it was sometimes hard to figure out the name of a thing or search for a specific syntax, e.g. with a single character like @ - especially in the official reference documentation. But maybe it's on me for not learning Ruby properly first.
> I consider Ruby to be quite similar to Python.They are both dynamic, OO scripting languages, whose main implementation has a GIL, but beyond that, they aren’t all that similar.> However, it’s kind of like Python’s weird brother,Methods-with-self-in-args-list isn’t the “weird” one?> with optional parentheses for calls without argumentsParens are optional in Ruby on method calls and method definitions except where necessary to resolve ambiguity (including in the newer special single-line method definition syntax, its not a special syntax option for no-arg methods> auto-returning the result of the last expressionRuby is basically an expression-oriented language [0], everything returns a value, and a sequence of expressions returns the last expression in the sequence. Explicit “return” lets you short-circuit that. Python is a statement-oriented language, and statements don’t return things except an explicit return tells the function its in to return something. Both are common kinds of languages, just very different. Neither is “weird”.
> Methods-with-self-in-args-list isn’t the “weird” one?I agree that it's uncommon, but I do like the clarity it adds compared to something like "this" which magically refers to the current instance. Hasn't C++ just added something like it with "deducing this"?
Because it honestly doesn't matter most of the time.In the majority of use cases, your runtime is dominated by I/O, and for the remaining use-cases, you either have low-level functions written in other languages wrapped in Python (numpy, etc.) or genuinely have a case Python is a terrible fit for (eg. low-level graphics programming or embedded).Why bother making a new variant language with limitation and no real benefit?
This perspective is a common one, but it lacks credibility.https://twitter.com/id_aa_carmack/status/1503844580474687493...
Look, Carmack is a genius in his own corner, but he is taking that quotevastlyout of context. The actual linked article[1] is quite fascinating, anddoespoint to overhead costs as being a potential bottleneck, but thatspecificquote is more to do with GPUs being faster than CPUs rather than anything about Python in particular.More specifically, overhead (Python + pyTorch in this case) is often a bottleneck when tensors are quite small comparatively. It also claims that overhead largely doesn't scale with problem size, so the overhead would only matter when running very small tensor operations with pyTorch with a very tight latency requirement. This is... rare in practice, but it does happen to occur, then sure, that's a good reason to not use Python as-is!1.https://horace.io/brrr_intro.html
You’ve posted this multiple times in this thread, and not once has it been relevant to the point being made. You are sticking your fingers in your ears and deferring to a contextless tweet by a celebrity.
If you want somebody to engage in a serious discussion, insulting them is not the way to go.The post is highly relevant. Next time, if you don't understand why, just ask.
His code has had 16.6ms to execute since before a lot of people here had been born. Of course Python is hopeless in his domain. It’s creator and development team will be the first to admit this.
John Carmack is hardly an unbiased source.In any case, if your program is waiting on network or file I/O, who cares whether the CPU could have executed one FLOP's worth of bytecode or 9.75 million FLOPs worth of native instructions in the meantime?
It's trivial to prove that this is true for most software. Luckily modern OS's are able to measure and report various performance stats for processes.You can open some software such as htop right now, and it will show how much CPU time each process on your system has actually used. On my system the vast majority of processes spend the majority of their time doing nothing.Is it true for all software? Of course not! Something like my compositor for example spends a lot of time doing software compositing which is fairly expensive, and it shows quite clearly in the stats that this is true.
The "vast majority of software" is now defined as "processes that happen to run in the background on chlorion's machine?" That reasoning is not sound.
I would add high-volume parsing / text processing to the list of bad fits for Python, although I'm not sure if there are native extensions for the different use cases?
Quite possibly; do you specifically mean NLP work? I'll admit, it's not something I work in myself, spaCy seems to be the go-to high-performance NLP library, and does appear to use C under the hood, but I couldn't say how it performs compared to other languages.
I had SAX-style parsing of XML and XSL transformation as concrete use cases in mind, because that happened to be what I worked with. I believe I went with Node.js at the time, which had a library that was much easier to work with than what was common for Python. Although, I mostly used Microsoft's or Saxon's XSLT processors overall in that job.Another use case was parsing proprietary, text-based file formats with ancient encodings. I believe I did use Python for that as there wasn't that much data to convert anyway and it just worked.
That's the spot filled by Go, and previously Pascal. Native code with good efficiency while still being fairly easy and productive.
Go and Python have a quite different set of strengths. Python heavily leverages operator overloading and other metaprogramming features that Go does not support (well).If you pick up Go expecting it to be a "more efficient Python", you will be sorely disappointed.
In my experience go's libraries are generally not so high quality
Hard to judge. In Python it's very easy to create nice porcelain APIs for powerful frameworks because you can hide complex behaviors behind operators. Imagine Pandas or Django without overloaded access operators.This is not the case in Go.
I didn't mean how beautiful the api looks like… In my experience authors of go libraries are somewhat noobs on linux/terminal stuff and their libraries fail to take things into account.
You might take a look at Nim.
https://nim-lang.org/
There are plenty of statically-typed languages which are a bit further along than 'a good start'.
OCaml would have been awesome for scientific computing, had it got enough adoption.
General-purpose processing units are convenient to use but waste so much electricity and materials compared to dedicated hardware.…A silly proclamation, of course.
Or to go one step further, phase out (outlaw) energy-inefficient programming languages like we do with high-emission cars.I'm not advocating for it, but it's an interesting thought experiment.
Tax carbon and let the market sort it out.Generally I’d expect less efficient languages to be more user friendly (well, a language which has neither advantage is just bad, why is anybody using it?). So, hypothetically these companies should get away with spending fewer programmer-hours on things. They won’t have to run the coffee pots, and air conditioners as late.
Pointless when heavy industry utterly dwarfs computing.Might be nice for embedded devices though, but they already run C/C++...
If so, there would only be room for C and assembler.Give me at least ksh and awk, they don't use much resources and are infinitely handy.
I wish that the pgadmin team hadn't rewritten pgAdmin4 in Python. The GUI performance is abysmal. I can see it lagging when typing SQL text in the window. The experience is really worse than the worst Java IDE I happened to use in the early 2000. The previous version was written in C++ and worked much better.So while Python might be good for some stuff, please, please do think twice before choosing it for GUIs or other kinds of apps that should be snappy.
> So while Python might be good for some stuff, please, please do think twice before choosing it for GUIsThe GUI for pgAdmin4 isn’t in Python. Between 3 and 4 pgAdmin didn’t just change from C++ to (largely) Python with otherwise similar architecture, it changed from a classical desktop app to a web app with a Python backend (so you could run it on machine close, in network terms, to your db server, to which your workstations would have only an HTTP, not a pg protocol, connection, without maintaining a separate code base for that and desktop use.)
Ok, I stand corrected. So that's not just Python but also some Electron-like madness. That explains everything. Looking for a different client now...
I’ve had very good experience with dbeaver.
psqlNever needed anything else.
As a person who has written Rust code professionally for 4, here's why I returned to python: batteries included.That's it. Having cargo download 1000s of package from who knows who for basic functionality is unacceptable. Rust's features, while absolutely phenomenal to work with, just aren't worth having insane npm-style dependency graphs and all the risks they entail. In comparison, Python's built-in modules are a godsend.So all in all, I think you should continue to stick with python.
I still really like Python for scripts and small programs, but I’m always going to use Rust now for CLI’s or anything larger, I get the problem you have with it, but the trade off is worth it for me being able refactor quickly and with confidence as the program grows.
Fair point. I dearly miss Rust's type system.I think python vs rust is always going to be a tradeoff either way. I just wish we had the best of both worlds in one language. Rust's base language with python's extensive library. Perhaps a new language will emerge that can satisfy both requirement now that Rust has a somewhat stable "safe" FFI. One can only wish.
This was also discussed in the last day:Breaking up with Python-https://news.ycombinator.com/item?id=34177703- Dec 2022 (172 comments)
I worked with Python for quite a few years but at 2013 it became too painful for "DevOps". The more I was thinking about how things could/should be the more frustrated I was. Python and bash were the "inspiration" that pushed me to start working on Next Generation Shell.Particularly annoying in Python is running external programs (yes, I know there are libraries) and manipulating structured data (list comprehension is not aligned with how I think, which is map() and filter() and lambdas not limited to single expression).
I just find it funny how my post on why I wrote a SQL engine in pure Python is right next to this one on the front page
I’ve started using Python more for fun lately (coming from C and C#). I wish more languages used white space as things are so much cleaner - the odd messed up return statement / parallax error isn’t worth all of the curly brace noise imo.
I like any language which has opinionated style rules. I don't especially care what code looks like, as long as it's legible and consistent.C# actually has great comprehensive defaults, they're just not enforced as strictly as they could be.
I don't like it because at the top of blocks it looks fine but at the bottom I don't know what's going on:something
   anotherHow nested are these things?  I never know.
If your blocks are big enough that this isn’t obvious, that itself is a code smell.(Brackets also have the same problem.)
If you have a loop inside another loop and say and if statement, it can be hard to tell where the end is:I'm in the IF
    What am I in?vs:I'm in the if
         }
      }
   }
   What am I in?I'm sure it's just personal preference and I don't like it.  I don't think significant whitespace is sort of a universal good that maybe it seemed like when it was proposed.  It now seems more problematic to me.
> If you have a loop inside another loop and say and if statement, it can be hard to tell where the end is:In either case, the aligned visible lines above (presuming reasonable block size) will be what clarifies that, assuming correct indentation (which is necessarily the case with syntactic indentation) and the brackets just add (in the example) three additional lines of separation making that harder.
Turn on "indentation guides" in your editor.  A dotted line will extend vertically across the block.
I think it can become non-obvious in 10-15 lines. It is a trade-off, not a universal advantage. I suppose an IDE could cleverly draw little lines exactly when needed. One of the nice things about Python however is no IDE is required. This is one misgiving I have about C#, it is great but an IDE is nearly required.
This is what I mean by parallax error. It is a trade off for sure but imo a worthwhile one.
With indentantion lines its clearer. And without indentantion lines,something}}}}} anotherisnt much clearer anyway imo.
Right but then you can auto-format it to have indentation.
I continue to reach for Python first for my personal scripting, especially gluing together existing libraries.Building tools multiple people will be using regularly? Might be worth speeding up at least the slow parts with another language. (I don't know it well enough for it to by my first choice here).Also: I appreciate typed languages more when working with a team. I'm not familiar with the options Python offers to keep teams on the same page.
all the reasons i switched away from python (ranked most important to least)
1. packaging python is awful. Turning a large python code base into a deb is awful. I mean really, how many _different_ setuptools or pip do you really need?
2. not strictly typed. Really impedes large code refactors
3. not concurrent. The concurrency primitives are a joke compared to any other language. The GIL kills everything.
4. slow. Python gains all it's performance by doing the important parts in Cpython is not a good fit for anything I do these days
Good decision to move away. Tools are supposed to help, not get in the way. Though types are there, opt-in, and who cares if C modules make it fast if the end result is fast?
What did you switch to? Rust?
Probably Go. All of those concerns are addressed by Go, but with a much easier transition and DX (dev experience) from Python than Rust.
As of late, my "language" of choice is a mashup of python and nim.  I use python for the ecosystem and nim for parts that need to run fast.  It's the easiest interoperability I've ever worked with.
Wow. Why did you say 'still'? I use python a more than decade, with other languages as well (go, typescript). And I even don't think to abandon it. I do so many things with it, that it would be nonsense.Yes, the drawbacks are here (async is not as good as in Go, typing I would say is rigid, packaging is not perfect at all). But I have a lot of projects where it just doesn't matter.
This language seems to require at least one positive front page post per day so people keep using it. Compare with the anti-golang posts today.
How popular would Python be without the scientific users and the machine learning ecosystem?I have the feeling that its user base is pretty lopsided, but I might underestimate its importance in other areas, like teaching programming. I'd love to see a breakdown of its popularity by field.
> How popular would Python be without the scientific users and the machine learning ecosystem?That’s tail wagging the dog. ‘Why Python became the scientific computing language?’ is the right question.
This. Somebody should actually trace the milestones that led to the current state as it not by any means obvious why it happened. At some point a winner-takes-all dynamic obscured some direct competitors like R or julia but prior to that all bets were open. It could also have been c++, since libraries like armadillo and eigen make it easy to write script-like code. Or even java that is everywhere in enterprize
Julia came too late to the scene. When I first started using Julia 0.3, there was already Theano for Python, and Tensorflow was in the making. R for some reason is not as easily navigable as Python. The slowness of compiling Armadillo and Eigen makes it a no-go for iterating on new ideas. Maybe it should be asked instead why Octave didn't take hold, as Matlab is popular among engineering communities and the syntax is also simple enough to understand.
> Why Python became the scientific computing language?Some guesses:- Because scientists aren't that much into programming and Python is one of the easier languages to start with?- Some aspects of its language design, like the syntax for slices, making it easy to express often used operations in a rather intuitive way?- The two points above leading to the numpy project, enabling high-volume computations with a friendly programming language?- Maybe Jupyter Notebooks played a role as well? It's a great teaching tool.
Very. Unless you're a diehard JavaScript head, it's still the language of choice for smallish projects like a Discord bot, or for any kind of sophisticated script.
Here's the link for Jetbrains survey results last year. There's web dev (django perhaps), dev ops and sys ad, education, and software testing.https://lp.jetbrains.com/python-developers-survey-2021/
All the top tech companies use Python for product.GoogleFacebook + Instagram (largest deployment of Django)Spotify (millions of lines of Python)NetflixRedditDropbox (millions of lines of Python)YouTubePlenty more examples.
Google / YouTube no longer use Python “for product”, at least, not in the serving path. Dropbox has also been moving away and towards Golang.Instagram (Cinder), Google (Unladen Swallow) and Dropbox (Pyston) have also all experimented with heavy engineering investment trying to improve Python performance and only one of them (Cinder) has outcompeted the “just rewrite it in a faster language” strategy.
Also...https://devblogs.microsoft.com/python/python-311-faster-cpyt...
I think it's a great pattern to start with Python and do something once performance becomes a problem. You can afford it when you're successful thanks to the code you wrote in Python, or it won't be a problem anyway.
Reddit is also transitioning away to Go, and Netflix is not a Python shop, they're far more Java with some Node.
Netflix uses Python for their recommendation engine, correct?
> How popular would Python be without the scientific users and the machine learning ecosystem?
All those use dozens (hundreds?) of other tech for product too.How is this an answer to the question?
"How popular would Python be without the scientific users and the machine learning ecosystem?"... do I really need to explain this?
Yes.P used forsomethingin places in parallel of hundreds of (several exotic, rarely used) technologies is not really predicting how much P was used without scientific and ML uses. What if P ismostlyused for scientific and ML purposes in those places, or as an experiment, study, not necessarily being a backbone? Or with other secondary agenda, overstated, etc. The mere fact that P is used in a huge amalgam of A,B,C,... tells very little alone concerning the question. Almost nothing.Yes, needs some unwrapping what youbelieve.
It's not solely used for scientific and machine learning at any of the aforementioned companies. It is the (or was) chosen by a number of technology companies who have the resources and knowledge to select the correct languages to address one or more of their existing problems. That is evidence of use and use case.I would argue moving away from Python at global scale doesn't even negate my point. All products change with scale.
Agreed. And sur, shouldn't move away. The whole matter is a hypothetical thing anyway.
It's also the primary language used for everything regarding VFX.
Think Pixar, ILM, WETA, Disney etc. it's mostly inhouse tools so nobody ever sees them but the code bases are huge and are growing as fast as the demand for more and more high quality VFX from streaming services and studios.
Now that you say VFX, Python is indeed heavily used in this industry. It's used in internal tooling but many of the open-sourced projects under the Academy Software Foundation (ASWF) umbrella also have a Python interface. Python is also popular among color scientists, of which many work in VFX it seems. By the way, the industry also makes heavy use of Qt, also in combination with Python, to quickly build production tools with a GUI.
That's interesting. I wasn't aware of this. Thanks for the share.
I really struggle with this because I'm a C++/Java dev who is 4/10 with Python. I dont understand why anyone would choose a single threaded language but its just everywhere I can't avoid it.
I'm C#/Java dev who works with Python and ML devs. I'm amazed how fast they can put things together and solve problems. We've embedded Jupyter to our product recently, and what I can tell, that's the way. Even the integration team started to use it to glue things together. I'm becoming a huge fan, it does the job.
Do you write a lot of multithreaded code that can't use a shared nothing model?
so is javascript, single threaded language. somehow these two are super popular.both can do async, both have libs for multithread workloads.I wonder how critical the language itself is as far as multi-threaded goes.
CPU-bound tasks are limited to a single core due to GIL but, for sure, it's not single threaded language!
If your problems need threads and raw CPU, you’re doing well, since that obviously isn’t Python’s niche. The thing is, most problems aren’t like that and if some parts are, Python probably has a C extension for it, so it doesn’t matter nearly as much as you think.
Python is pretty decent for small to medium sized stuff where performance isn't a big issue (setup stuff, simple backends, ...). A lot of stuff falls into that category.I especially enjoy the types. Coming from Typescript and being quite a fan of the "dynamic language with optional typing" pattern it was quite cool to find that Python just has that.Sadly quite a few pieces of software are likely going to stick with Python 3.7, so we are probably going to have to stick with the old syntax (explicit imports from typing and uppercase types) for a long time.
I had a team recently who were getting really frustrated with Node. They are systems people, integrators that sort of thing. I have been careful about pushing my own prejudices onto them.  I made a throwaway comment about how x problem would be so easy in Python and one of the senior guys asked to try it. I showed them Flask about a month ago and they are over-the-moon. The next day they were showing what they had built!Now they have plans for a whole set of simple webapps. It's like a new lease of life!
What was the task and why was it hard with express?
I had to install Mailman 3 a while ago.It would not run on a $5 VPS from DO, because to deploy it required more memory (two gigabytes I think... mēh).Mailman 1 ran in 40K.  It was written in Perl.  Clunky, not flash, and functional.Mailman 3 is written in Python using Python tooling - Django I believe.Clunky, flash, and functional.  And costed my $5 a month extra.I do not hate Python, I forgive the language for people misusing it.  But it is ascriptinglanguage.  That is what it is good for.  Calling other systems.  Not building the tight loops
It’s easy (and common) to point to Instagram et al as examples of people using Python and even Django at scale. Beyond those big hitters though, Python is obviously a very popular language, and Django is a very popular web framework. The people making these tooling decisions aren’t just noobs. Python and Django obviously meet the functional and performance characteristics desired by a lot of people.I have Django projects, some of which I am going to assume are more complex than Mailman, using far less than two gigabytes in production. Not through any extreme optimisation efforts. It’s just…what’s happened. In my experience, the resource footprint you experienced with Mailman is not representative.Notwithstanding the fact that we’ve seen amazing performance improvements in Python as recently ad 6(?) months ago, if speed were my primary concern, I am obviously not picking Python.  This doesn’t mean that it should be relegated to the frankly at this point outdated bucket of “scripting languages”. The language’s features, performance profile, and package ecosystem all surpass these use cases. The conventional wisdom, which I completely agree with, is that these days things are good enough that speed need not be a primary concern for most people most of the time.  Sure, oldschool Mailman was fast, but did anyone want to or know how to actually work on it anymore? Evidently not.
> to deploy it required more memory (two gigabytes I think... mēhThat sounds like frontend was written in something requiring a webpack or similar Node tooling, or you also ran a database on the same server.In my experience, small Django setup with PostgreSQL can run fine on droplets with 512mb of ram, provided the traffic is not too heavy.Add containers or anything node-related to the mix, and it'll be 2G+.
Front end was Django, what ever that is, from memory.No Node.js or other nonsense.Did use docker (another example of making simple things more complicated... )
We ported a client-deployed command line program from Python to Go two years ago and couldn't be happier. It's solved all our problems around shipping code to customers in different environments. It greatly reduced our support workload.However, we still use Python for APIs and Web Apps. No language is better than another, some are just better for one solution more than another.
After 10 years of nonstop use, I have stopped using Python almost completely. The main reason is that working with Go makes my life much easier when it comes to building distributed stuff on AWS, which is my main focus at work. I miss Python's development speed and how easy it makes it to test things, and I still consider it the king of modern monolithic apps.
Python is the modern perl. It connect useful and fast things build in C in a more easier more expressive but way slower package.That’s his quality but also the biggest problem. When you have something that cross the boundary python/c it get painful as you have two language to jungle with the handling of packaging, compilation.
If one could use python in the browser and could program mobile apps with it, Python could take over the world.Otherwise I fear it will be Javascript that will ultimately conquer everything.
Why do you publish the words you write on a website that makes it difficult to read what you have to say?Python apologists seem to be looking for excuses to avoid the hard work of learning proper programming skills.
For serverless with AWS Lambda, ironically enough, Python is the fattest runtime, and the language that makes more sense, since lambdas are small functions.
Nobody uses Python anymore, it’s too popular.
Is JavaScript worth looking at, as an alternative to Python?
For most web-based things, frontend and backend, Typescript is where the zeitgeist is these days. Better types, web native, more performant, better async support, better library ecosystem, new cutting edge tech projects, etc. Python's forte and niche is in ML and scientific computing. For quick scripts, either are fine.
As an alternative for web apps, yes. In other domains, not really, but it’ll work, it just doesn’t solve any problem better except it isn’t Python.
People use Common Lisp for data engineering? If not your response is terrible and the correct answer would be ‘what are you trying to code?’.
I was mainly asking what do people use today instead of Python. Things that Python was usually used for, but now people use something else? Hence the whole "I STILL use Python after all this time" kind of thing.
Good post. I think this is the mature and somewhat inevitable lens through which to assess which programming language you're using. I have been using primarily Python for the last ~4 years or so. It's probably the most boring language I have ever used (it probably doesn't help that I've used Scala, Haskell, Rust, etc).Obviously, some languages are better than others for specific use-cases and one should think through the strengths and weaknesses of each before beginning a new project (assuming you expect the project to have some longevity). Similarly, it definitelyispossible to make the wrong choice about which language to use. But even as a PL "enthusiast", I've learned over ~15 years of leading successful projects and teams, that evaluating languages is always team/org/business-dependent and the considerations that factor into those contexts are distinctly different from the kind of considerations that I, as a PL enthusiast (and I suspect many others in the HN crowd) would prioritize. You have to consider things like:1. What stage in the business in, i.e. early stage where you may simply want to get something,anythingworking and it's viable to do so in whatever language will get you there fastest (warts and all, tech debt be damned, etc) vs the critical juncture where you're beyond finding product-market fit and you now have a business that is working and you need to increasingly focus on reliability, scalability, etc?2. What does the pool of engineering labor in the market you have access to look like? For example, it may be the case that you'll have difficulty, for one reason or another, finding developers who work with language X, but could easily find many who can work with Y (of course, good devs should theoretically be able to ramp on any language, but whether you'd want them to do depends on how crucial using that particular language is to your venture, whether you can afford the ramp-up time, etc.3. Also somewhat related to the quality of engineers you have access to, the community/packages/ecosystem surrounding the language may matter a lot to such a degree that even if some other language were a better fit from a purely technical perspective, it may leave you to have to fend for yourself in ways that your team simply isn't up for... and many more considerations.Beyond all of this, I resonate with the author's orientation of wanting the language to just get out of the way. Sometimes you're looking to geek out on a stimulating and interesting language. Other times, that's the last thing you're thinking about. Bonus points if the language you find most compelling is also the one that, for reasons like the ones mentioned above, is the one that makes the most sense for you and your team. All in all, the point is that assessing a language in isolation, without any regard for what you're actually trying to accomplish, what your team looks like, etc. doesn't make much sense.Side note: I do wish more Substack authors would allow comments even from non-paid subscribers. I could understand restricting it if you already have an established paid subscriber base and a chatty comments section. But if comments are non-existent, it seems to me like the author is potentially losing out on valuable feedback/commentary by restricting commenting to paid subscribers.
I wish I could just stick with a language forever and thoroughly master it. What did Bruce Lee say about it? He didn’t fear the man that practiced 1000 different kicks. He feared the man that practiced the same kick 1000 times. Something like that. The industry fetishizes the constant stream of new languages and frameworks, primarily based on nothing more than the fear of “falling behind”. It’s dumb, and essays such as the “blub programmer” feeds into it.
There is nothing abstract about a kick however. A programming language is always an abstraction, with different languages optimizing for different things. Understanding more than one is helpful imo.The “Bruce Lee” of programming would definitely use assembler and deeply understand computer architecture at a fundamental level. The idiom of Bruce Lee is someone who is hyper passionate about their craft.
"I wish I could just stick with a language and thoroughly master it."Assembler, C and shell script have been and will be around for many years.As an end user, i.e., someone who runs programs more than she reads/writes/edits them, I find Python's startup time is just too slow.  I have a folder full of tiny, fast shell scripts and C programs that I rely on year after year.  Replacing this with a folder full of Python scripts is difficult to envision.Assembler, C and shell script will still be ubiquitous and foundational no matter what subsequent programming language hype comes over the internet. Boring stuff that works.  I am typing this comment from a program written in C."The industry" (cf. the end user) seems to have endless time to burn because the stuff it promotes through hype always presents a massive timekill to those who embrace it. A conspiracy theorist might imagine that the industry is trying to keep itself busy and maintain peoples' attention.  Regardless of intent, that seems to be the end result.It is like that hardware company that wants people to keep buying new computers every few years, and tries to prevent/discourage anyone from repairing and retaining them.
>It’s dumb, and essays such as the “blub programmer” feeds into itI don't think the Blub essay is about learning a constant stream of new languages. I mean, the author of the essay doesn't seem to be constantly learning new languages.The Blub essay, whatever its flaws may be, is about people being unaware of languages and features more advanced than their tool of choice, and finding them strange. Or in other words, that it's easy to see how poorer tools are more limited than the ones you're using, but very hard to understand how better tools are better, or even acknowledge they are better at all.
The one thing that scares me about that sentiment, which otherwise I mostly share, is that "forever languages" tend to become kitchen sink languages. Typically to their detriment.
You can learn a language just to explore new ways of thinking and eventually return back to your kitchen sink language.I think it's worth learning a lisp, a functional language, a logic pl, or something from some other paradigm you don't typically use. Maybe do a side project in it. The lessons you learn will surely make you a better programmer overall even if you don't maintain your mastery of it
If you’re creating the language, i totally see the value but If you’re just a user of a given language then there’s always going to be more value to be extracted from advancing your knowledge of computation instead of any one lang.If your business is trying to solve hard problem X and your best idea is to use this tricky advanced language feature and then apply these compiler flags… then you’re going to lose to the person who knows of a programming paradigm (e.g. logic programming) unlocking a simpler solution or a data structure unlocking a more performant solution.That sounds a bit abstract. To make it more concrete - imagine a problem where you need to apply a function in concurrent windows over a time series but you’ve never experienced any of the array programming languages.
No language will stay with us forever, as the types of problems we solve will change.You might think that C would be a contender for a long-lived language, but what about a world where humans don't do the code writing anymore?Languages are scaffolds. You need them for a time, then you build around it and are onto something new.Everything changes. Time will ultimately wash all that we consider permanent away.
As a language that celebrated its 50th birthday this year, C is already a long-lived language. It's not terribly far behind the first non-research compiled language, Fortran, which celebrated its 65th birthday this year.Both are, for all practical purposes, immortal languages at this point. You correctly point out that they aren't guaranteed to survive the next technological mass extinction event, but I think that might just be a truism.
I think we're about to enter an era where more code will be written on an annual basis than all previously existing written code.The same holds for music, art, photos.
Nothing really stops you from doing that, as long as you're still willing to learn other languages, libraries, paradigms and whatnot that are needed to get stuff done.I consult as an X "expert", but have worked, and do work, extensively with tools outside of X's scope.
…those ChatGPT responses are getting old real fast by now.
Exactly what I thought reading the comment.
In my and many other developers experience and as indicated by studies, the expected number of bugs per line of code is constant andindependent of the programming language. Thus, say, 400 lines of Python will contain the same number of bugs as 400 lines of C. But 400 lines of Python contains much more functionality than 400 lines of C. This is what you have been missing.
>Like I can use Node, Go, C#, and Java at scale without being concerned about the low-level details, however, that's not the case for Python.Well, if you chose not be concerned about the low-level details with these languages, then you can chose not to be concerned about the low-level details with Python. There's nothing inherent in Python or those other languages that makes it otherwise.Or you mean "but Python is slow"? That's mostly irrelevant for many use cases, which either don't need the speed (web, administration, glue, controllers, etc), or depend on Python packages written in C/Fortran and plenty fast (which is the case for AI / ML / DS and such).>it doesn't seem to offer any benefits compared to Node, Go, C# or even JavaEase of use, less ceremony, huge package ecosystem including several de-facto standards for many use cases/industries, suitable for glue work,arebenefits.
>But purely from an computational perspective (GPUs, multi-core, concurrency, etc)Most of the stuff people do with Python isn't hampered by the "computational perspective". For the things that are, we usually don't need to interface with C/C++, because somebody else has already written the library that does it.
> does it offer anything natively without interfacing with C/C++ that validates it to be called a general purpose language.In fairness, a huge amount of C/C++ functionality is managed by the kernel anyways. I'd bet most of the stuff C is used for in this situationcouldbe replaced with Python code, but isn't for maintainability and performance purposes.
Python is easy to use and easy to start programming in. Much easier than the other alternatives you mention. This from a guy who uses python but does not particularly care for it. I love me some curly braces and hate significant whitespace but there is no getting around the ease of teaching in python and its beginner friendliness.Why cant you use python at scale? Many ML/AI/Data tasks are exceedingly resource intensive but python still plays in thoses spaces as you elude to.Are people writing realtime systems in python? Probably not but dont be quick to dismiss python before you know it is not performant enough for your use case.I'm not saying python is the best choice, but it is often the easiest choice.
> Python is easy to use and easy to start programming in. Much easier than the other alternatives you mention.In the case of Go (used in the comparison), would have to disagree.  Learning Go (along with similar offshoots like Go+ or Vlang) is arguably as easy as learning Python.  Go was purposefully designed to be that way.  The more significant distinction (in terms of learning) would be compiled versus interpreted, but there are many pluses and minuses that go either direction.Python's advantage is the long ago targeting of and being embraced by many school systems.  So is seen as a "go to" language to teach, along with many books written for that purpose.  Newer programming languages have to play catch-up, if they are even focused on academic circles.
Author here! I have finally come to realize why and where Python is required.- Python is a fantastic frontend (glue) language that interop well with C/C++ libraries. This seamless binding is not natively available in  languages in Go or Java or even JS.- Python has an excellent data science / modelling / data engineering / ml ecosystem. There is no other language that comes close.- Python is a fantastic MVP language. One can rapidly prototype and iterate and to a very good extend scale a product.
Python was favored by universities, professors and the like a long time ago. Maybe it just had this academic feel to it.This is even why it started to pick up in AI / ML / etc space. Some students that used it during class may also carry on with it.It was also common for sysadmins before Go took over. A lot of the earlier tools were Python based.Usually languages are created by people and because people like it.
Can you please give me examples on what Go took from a Python? Just looking to see if I can gain something from learning Go.
You can't use Java at scale without worrying about the low level details (e.g. performance). So in a sense python is in the same club as java.I don't understand the need for python either. I've built data processing and visualization tools in C++ and prefer to do that so I am aware of the performance implications. With python you still need to be aware of what happens under the hood, but then you also need to learn the syntax and identation, so it's like you have multiple jobs. Why not learn C or C++ and use that? There are endless libraries you can use. AFAIK anything that exists for python can be used from C or C++.It's especially puzzling when getting to a coding interview and the person only knows python and doesn't understand why you never had the need for pandas or any other python specific libraries.I'm wondering if python hasn't been pushed such that more coder drones can be created easily which makes it easier to hire people and pay them less.
There are advantages working in an interpretive (scripting) language and there are several science applications that use Python as the top level control language and a c-like language as the heavy lifting code. This plays to the strength of each language and casual users can use the complex functionality without looking at the complex code.
I got into Python from C/C++ for data plumbing in the late 2000s, before data science / ML really took off.I think much of what appeals to me comes in three camps:One: "Zen of Python" philosophy. The idea of both explicitness and being "exactly one way of doing things" helps with menial tasks I don't want to think too deeply about. Maybe I _shouldnt_ think too deeply about how I move some files around, parse JSON, or hit an API.Two: Batteries included. The standard library has always been extensive and "just works" in ways other language ecosystems have long struggled to catch up to. Especially for data / file plumbing tasks. It's also not very complicated to do most simple things in without a 3rd party library.Three: C integration. Writing native C modules seems to have been baked into the language from day one which has led IMO to much of the data science ecosystem. The ecosystem seemed to connect with the practical, old-school C programmer part of my brain, and make a lot of sense from a perspective of "get shit done" imperative programming style.One maybe critique -I think the nature of Python, and how people historically approached it, can lend to a kind of lazy/bad software engineering.People historically had gotten into Python because of dumb scripts, and not because they care to think deeply about how code SHOULD be structured. Python's practicality is a bit in contrast with the culture of Ruby where aesthetics are highly prized. So a criticism of Python could be its very easy to get started with a dumb script, to solve a practical problem, that eventually becomes a critically important project. Unfortunately everyone just focusing on "getting the next thing done" means it can morph into unmaintainable spaghetti mess because its some side thing.I don't know if that's the languages fault per-se, or just a side effect of the "lack of ceremony" needed to do work. Certainly, you can and should have high software engineering standards for your Python project. Just something I've observed perhaps as Python itself can often be a "side" thing, not the primary focus of practitioners.
ecosystem + simplicity. performance matters once the time to write code that works is less than the time it runs for. and then once that gets surpassed, port the hot path into c/c++, boom.
Thanks to Numba, you can even JIT python to native machine code and gain 10 - 30x performance boost. And you can even compile the code to CUDA GPU code! Pretty cool to do that in python, rather than in a C dialect.
>however, that's not the case for Pythonin what way?
My experience has been that to efficiently write computationally expensive operations I need to know the low-level libraries that Python interfaces with. Other languages provide me this functionality natively and I only go to the low-level stuff only after a few iterations.
You bring up a valid question. The value of Python as a general-purpose programming language comes from a variety of its attributes.Readability and Simplicity: Python was designed to emphasize readability and simplicity, making it an excellent language for beginners and for prototyping complex systems. This simplicity means developers can spend less time understanding the code and more time creating functional elements. Even experienced programmers appreciate Python for its simplicity and how it encourages good programming style.Wide Range of Libraries: While you mentioned AI/ML/Data, it's worth noting that Python's rich set of libraries (both built-in and third-party) makes it useful for a massive array of tasks beyond just those fields. It has powerful libraries for web development (Django, Flask), data manipulation (Pandas), image processing (PIL, OpenCV), GUI development (Tkinter, PyQt), and many others. This versatility allows Python to be used in many different problem domains.Glue Language: Python is also often used as a "glue" language to connect different components of an application. Since it's easy to interface with C/C++, it can be used to control and orchestrate low-level modules while providing a high-level interface to the user.Automation and Scripting: Python's simplicity and wide range of libraries make it a popular choice for automating tasks, which is a large part of what any scaled system needs to handle. These tasks range from managing file and directory operations to web scraping or interacting with network resources.Testing: Python is often used in the development environment for testing other code. Its simplicity allows for writing tests quickly, and its wide range of libraries allows for testing various programs.Education and Research: Python is also widely used in education and research due to its ease of learning and wide range of applications. As these researchers move into industry, they often continue to use the tools they are most comfortable with.In terms of using Python at scale, Python's indeed interpreted nature and Global Interpreter Lock (GIL) can limit its performance in some scenarios compared to compiled languages. However, many organizations find that Python's benefits outweigh these costs, especially when the limitations can be mitigated. For instance, using Python as a high-level interface to low-level modules written in C/C++, or using multiprocessing to take advantage of multiple cores and systems.So while it's true that Python might not be the best choice for every situation (for instance, real-time systems, high-performance computing, or mobile app development), it's a powerful tool with a wide range of uses that many organizations find valuable. Different programming languages often have different strengths and weaknesses, and the best language to use often depends on the specific needs and constraints of the project.
> emphasize readabilityThis is a claim that has never, ever been true.Nothing is less readable than defining scope with whitespace. Nothing.One really has to boggle at the notion that there are people who consider Python (or YAML for that matter) even remotely readable.
Good points. with arrival of MOJO, we can probably keep all the benefits of python but also getting great performace. And then perhaps MOJO python will be used everywhere.
Python is a pretty terrible language to work with. Tooling sucks. Dependency conflicts are common. There's no test framework/runner worth a damn. Web frameworks are inferior to those in most other languages.If you're doing data science things, it's hard to beat pandas/numpy. I get that those are popular in that community because the barrier to entry with Python is low. People who are just looking for a tool to solve immediate problems would do well to reach for Python.The problems start when you try to write more complex things. Then you run into the weaknesses in tooling, testing, and performance. People would do well to skip Python and go right to another solution.I say this having spent half of the last decade working on Python projects. If not for data science and academia keeping it alive, it'd be disappearing along with Perl.
> Web frameworks are inferior to those in most other languages.That's quite a statement. Go on, for most of the other languages, show me a web framework that's better than Django.Python absolutely has deployment challenges, but the performance is Good Enough™ and the speed of modelling and maintaining and accessing databases in Django's ORM is so much better thananythingelse I've found. Its Admin interface too is superb for same-day turnarounds on little CRUD projects. Nothing comes close.And I've written quite complex systems around Django. Ones that are multi-headed websites, APIs to physical hardware IO, ANPR, card readers, ID printers. Python hasn't let us down.
> That's quite a statement. Go on, for most of the other languages, show me a web framework that's better than Django.I think that’s subjective, so take this with a grain of salt. I do have a different opinion though. Also, my point isn’t to argue, but to encourage consideration.I’ve used Django and Python quite extensively in the past and I would say that, for me, Phoenix/Elixir and Ruby on Rails are both better web frameworks than Django.The reason I feel this way is that Phoenix/Elixir, for example, has much better dependency management and tooling than Python/Django (e.g., Mix is vastly superior to Pip, in my opinion).Also, when I was using Django in the past, even the core team suggested using a different directory layout than is generated by default. This meant that every Django application I worked on had a completely different project layout. Both Phoenix and Rails are more opinionated regarding their project layouts. Some may consider this bad, but the benefit is I can go to any Phoenix or Rails project and instantly be productive because I know where all my controllers, models, views, templates, and contexts are going to be. I also like that Phoenix is much faster, more scalable, and makes better use of hardware resources than either Python or Ruby.I think Python and Django are excellent, but I’d place them at #3 in my top-three list of web frameworks. That’s just my opinion though.
That's fine. I disagree, but that's fine too.What I took issue with was the suggestion that "most other languages" have a better web framework. I'd wager most other languages don't even have a web framework. And even amongst those that do, there's some real dirt out there, and much worse examples of packaging, tooling, etc. Two Python frameworks, Django and FastAPI would be in myas-objective-as-possibletop 10.It was a silly thing to say.
I see. I can agree with you assessment. I also agree that Django is a great framework. It's one of my top-three favorites.
I am a self admitted python- and ORM-hater and I agree. Django is pretty fantastic, and I have successfully used it to spin up several complete CRUD projects in a day or two
If you use a DB, the DB will be the slowest aspect of a web framework, or any other kind of IO.90% of the performance gains I've achieved are by optimizing/reducing large DB queries, or adding an index to the DB.
These are the kind of comments that really made me feel insecure when I started out to program. Every programming environment/language has its advantages and drawbacks and python is obviously not a terrible language. People build amazing stuff with python.
> Python is a pretty terrible language to work with.That's just like, your opinion, man.> Tooling sucks.Not in my experience. Lot of tools could be better, but I would not say there is a lack of un-sucky tooling at this point. Poetry and pytest in particular are largely excellent to work with.> Dependency conflicts are common.This has been a problem historically but it's leagues better today, especially with lockfiles.> There's no test framework/runner worth a damn.Um, what? Unittest (stdlib), Pytest, tox, nose, hypothesis, schemathesis, and a few other lesser known ones.> Web frameworks are inferior to those in most other languages.FastAPI is pretty amazing. Flask is well regarded as a good intro framework. Django I'm not a fan of personally, but many love it.> If not for data science and academia keeping it alive, it'd be disappearing along with Perl.And machine learning. And web dev. And sysadmin scripting.
For the little data sciences like statistics and mildly complex ML, R is really good. At least for data exploration. The REPL/emacs combo I use is much better than python/jupyter. By better I mean it's far more productive to test ideas, compute statistics, charts, etc. Unfortunately R programs I write are not as structured as python programs. I wouldn't like to maintain that kind of code for a long time, nor would I build big applications in R.
Sounds like inexperience or confusion, to be honest. None of those are problems particular to Python.  Meanwhile you did not mention any of Python's significant issues, such as performance or deploying end-user apps.  But it is best-in-class for what it was originally designed for.
>There's no test framework/runner worth a damn.The built-in unittest module is essentially a clone of JUnit, so it can't be much worse, and most of the remaining limitations are fixed by pytest which people seem pretty happy with. What test frameworks are you comparing them to?
You're right.The thing I want is a good monorepo solution for Python. There's at least 3 for JavaScript.As much hate as JS gets, its package managers are also much better than Pip.In order to manage complexity of Python as you do your big projects, you really need to do "enterprisey" patterns like DI. Even though it's rare for Python programmers to write like that.Re: test runner: pytest is pretty good
What are you looking for in a monorepo solution?
probably managing requirements.txt of sub-projects and virtual environment management?
This is possible with existing general monorepo tools. We use Bazel for Python and other languages. With Python, we have a single requirements.txt at the root of the monorepo, but each target (a Python package, a module, an app, or some combination thereof) depends only on the packages it needs and the transitive packages of its dependencies.Then if you need to do something like build a distributable archive for your app (say, to deploy it to lambda), you can use Bazel's dependency graph to get only the packages that the app transitively depends on.
What about the opposite case? I have several python packages with one requirements.txt each. But for development I want to have a single “root” virtual env?
In that case it seems like you could just have one all_requirements.txt that includes the individual files like:-r package_a/requirements.txt
  -r package_b/requirements.txtetc.
yes I get it. Good point.Is bazel also a good choice for managing the virtual environments of my developers? Do you have any examples?
At this point I would say no, but work is in progress to improve in this respect [1].At my place of work we use some rules [2] to build virtual envs from Bazel dependencies. It's been a great stop-gap for us and allows us to use traditional Python tooling (e.g. PyCharm) with Bazel-managed dependences.[1]https://github.com/aspect-build/rules_py[2]https://github.com/cedarai/rules_pyvenv
Of things you mention I feel the testing part the most. I started python recently enough that I've only ever used pytest, but something about it just feels too...magical? I'm holding out hope for a new test framework that I'd feel more at home with, but I'm not aware of any such projects; do they exist?
You could give the built-in unittest module [1] a try. It's less magical (although also less flexible) and many of its old limitations that people used to cite as advantages of pytest (e.g. built-in test discovery) have since been fixed.[1]https://docs.python.org/3/library/unittest.html
I'm relatively new to Python, coming from Ruby and JS, and the built-in unittest module is just fine. I haven't had any issues with it, besides the documentation for setting it up following the conventions is really hard to find. But once it works, I like how simple it is. If you know OOP you'll feel right at home. You can simply create your own test case classes if you want to re-use stuff. No magical bloated configuration.
If "too magical" is the only complaint that is mentioned, then pytest is not too bad :)
> People would do well to skip Python and go right to another solution.Okay, so what solution?  What do you recommend?  I'm guessing if you're qualified to make statements like your first paragraph, you can bring your wealth of skill and experience to the table and show us what we should be using.
> Dependency conflicts are common.Is it really?
