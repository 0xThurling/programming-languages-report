"I'd use it but give me a garbage collector"
'It's useless because memory bugs in C are a skill issue' is one I've come across a fair bit. Not as much these days but definitely in the past
I talked to a guy who had sort of the opposite perspective but coming from the same place:
He was hiring for a company and the core of their product was mostly C++ but they had begun moving some parts over to Rust. I asked if memory safety had been a problem and got the "no. Capable programmers do not make mistakes"
But that was exactly the point. You can't rely on having only senior devs. Rust allowed them to train new developers, and get them to a productive level much faster, and not have their senior devs spend all their time reviewing code.
Memory bugs in C is a skill issue, and that's exactly why Rust is useful.
Also, the impression I generally get from people coming from C, is that it's a relief to have the compiler verify and enforce these things. Even if you could do this on your own, it removes some of the cognitive load, letting you focus that on problem solving instead.
I'm so tired of that, and variations of it -- "just don't write bad code" OH RIGHT, I'm such an idiot; I should just have written bug-free code from the start.
I thought this sub was about the oxidation of iron. Leaving.
So… what are the unpopular opinions on the oxidation of iron you’ve come across?
The standard library and idiomatic uses of it look really bolted on and arcane. I'm thinking of all of the error and result helpers. It feels almost like various lisp dialects where you're supposed to memorize function names rather than using/recognizing syntax.
Edit: bonus round, it's unreasonably hard to provide iter, iter_mut and into_iter for your own types, even though all the standard library stuff does it.
Ok, a really unpopular opinion: Rust ecosystem is riddled with *coin- and NFT- scambros.
not sure about popularity of anything, but those two keep thoroughly surprising me:
async rust is bad
function coloring is bad
I do find those deeply problematic ! But so does the Rust team, else they wouldnt specifically cite async as needing some tweaks soon in their roadmap.
Souce:https://lang-team.rust-lang.org/roadmaps/roadmap-2024.html
It's more fun to watch an edited video of a highly skilled player than it is to actually play the game imo.
That’s basically the rub of it.
I play, get my face stomped against a curb, lose hours of my life so some random chad or cheater can mop up the winnings.
I watch a YouTube video, spend a lot less time in total, enjoy every minute of it, get to live vicariously through them, experience all of the joy and none of the pain/misery.
I dunno if there’s really an answer to this. Loot acquisition is so much easier now than before, so loss shouldn’t feel as debilitating. And yet it still does and it still takes ages to build up your base either way.
Its different thats for sure. I remember playing years ago (like 8 or 9) and there was AK fights for hours straight at dome. That just isnt happening anymore.
Yeah ground roaming in general is just dead. Y Half the time you fight people 1 square away from their base, half the time you fight hazzies running monuments.
Tech tree ruined interesting pvp. No reason to leave your surrounding squares. People play incredibly greedy and I understand why, but at the same time it's unfun to play against.
I started playing in 2013.
Rust isn't the same.
It's still fun but just different.
Rust had a sense a of whimsey back then.People would just try things.We built a temple and threw a bunch of flares over a pit of campfires and nakeds would battle to the death.Pillar bases, hapis, rad bears, zombies.Building to the height limit for a suicide tower because the game would give you vertigo during the fall (non of this fancy lag out you get now).There was always interaction with people, everything was over voice chat, most people didn't use teamspeak, discord wasn't a thing. Airdrops were the big event.
Then rust changed and we got the beta version and rust started getting more popular, more clans, more monuments, more guns, more tools, more stuff in general. It wasn't rust any more.
But it was still fun, it was a new rust.
It was a lot of fun.
Building on monuments, building towns, walling off airfield,braw bridge bases, walling off the roads, Building where quarries gave you the most resources.Suiciding in mass to get enough fat for fuel. Hoping an a test server that had staging up and testing the changes the devs made. Finding the right spot to soft side a wall. People building things not off a youtube video or a meta, but just cause it was a fun base. running around finding blueprint fragments. Adapting to the xp system.  Running everywhere cause there were no cars horses or helis.
More people started playing.
Then came less Stability, no overlapping tc's, tool cupboards require upkeep. Safe zones, more monuments, vending machines, helis, cars, horses. the popularity has increased even more. More people sharing build guides, tip guides, team ui, more this is the meta content, lessadmins spectation clan vs clan battlesand uploading it to youtube.
Rust has changed.
I like all the stuff going on, I like the building choices, I like the skins, i love electricity and industrial changes. I love cars and horses.
But with that came the restrictions.
You can't build on top of dome. You can't build too close to this place. There's safe zones. did a clan get hold of a monument? Don't worry there's 20 more you don't have to ghost in or fight them for control. Want to sell something, you don't need to make a trading post we have vending machines outpost, bandit camp and drones.
I don't think the aim shit matters, the cheaters are the same as they were back in the day.
What's changed is the the lack of Chaos.
What's changed is the the lack of Chaos.
there it is
Raiding is way too easy, 40-60 rocket raids are done day 1-2 of wipe
Its the worst it has ever been, but there are no other games like rust.
2017-2021 rust was different era and in my opinion 2019/2020 was one of the better years for pvpers/raiders which was fun, i remember sitting in my base and looking at my fps jump from 180 to 70-80 and then i go on my  roof and look outside and see 50 people running to my base with rocket launchers, they slapped down beds, no turrets, no mlrs, no raid base, just a nice fun online raid.
Stuff like that doesn't happen anymore.
before HDRP backport, recoil, and removing the mini spawns from the roads the game was so much more fun IMO
Skill gap was wider but the game was also generally more forgiving for solo players since traversal options weren't gated behind a scrap paywall and things like bus shelters and especially triple cave bases gave you decent survivability and were typically ignored by groups because of how annoying they were to go in and out of
Getting on now even if I manage to snowball and get a base down I'm always raided the next day because the massive ego the current playerbase has won't allow anyone to just accept a loss and move on, instead I have my time and effort wasted over a SAR kit they lost at oxums
I feel you, but the game nowadays is like who owns more pixels on the server, people are too attached to the loot they have, and farm farm farm all wipe, never to leave the base and never roam, and then offline everybody, they use the game to get items/boom and screenshot to send to all their friends to get approval, it is turning to a hoard game and "controlling this" game but not a pvp game.
Strive to treat others with respect, patience, kindness, and empathy.
We observethe Rust Project Code of Conduct.
Details
Posts must reference Rust or relate to things using Rust. For content that does not, use a text post to explain its relevance.
Post titles should include useful context.
For Rust questions, use the stickied Q&A thread.
Arts-and-crafts posts are permittedon weekends.
No meta posts;message the modsinstead.
Details
Criticism is encouraged, though it must be constructive, useful and actionable.
Avoid posting links to web pages which allow commenting, such as Twitter, or Github projects/issues when criticizing them. Pleasecreate a read-only mirrorand link that instead.
Details
A programming language is rarely worth getting worked up over.
No zealotry or fanaticism.
Be charitable in intent. Err on the side of giving others the benefit of the doubt.
Details
Avoid re-treading topics that have been long-settled or utterly exhausted.
Avoid bikeshedding.
This is not an official Rust forum, and cannot fulfill feature requests. Use the official venues for that.
Details
No memes, image macros, etc.
Consider the existing content of the subreddit and whether your post fits in. Does it inspire thoughtful discussion?
Use text for code or error messages, not screenshots.
Details
It’s a general purpose language; you’ll find libraries for things, frameworks for things, and opinions everywhere. Like most general purpose languages.
It has a learning curve but it was worth the effort for me.
I use it for graphics. My first production rust code was back in 2016 so it’s not new or experimental as a language.
What API do you use for graphics in rust?
It's probably correct to say something like: "Rust is a general purpose language, you can probably use it for anything, though it's taken off in some fields more than others".
But that's not totally helpful so I'll give my own experience. Personally, I've used Rust for stuff like:
TUI/CLI applications - there's a very strong slew of libraries and community around this use case IMO.
High performance stuff - at work, we're moving some stuff to it where performance is critical, but don't want to touch something like C++, and it looks good.
Web backends - while not as mature as some other ecosystems Rust is pretty strong here and working with things like Axum has been pleasant.
Web frontends - IMO it's a bit more immature here but you can even use Rust here!
Compilers - for school, we wrote a full compiler in Rust for an older version of Java. There's a lot of good tooling here too around stuff like parsing, even if you're just working on something simple.
So... kinda broad experience on my part, but maybe that helps?
There are also people using Rust for things like scientific computing, GUI, drivers (see Linux and Android), entire operating systems, and more, but I haven't explored those domains as much so I'll let others speak for those use cases.
And yes, Rust is fairly opinionated, and clippy and/or the compiler may/will scream at you if it doesn't like what it sees. That's not a bad thing though, the compiler is probably one of Rust's greatest selling points with how helpful it is.
There are also some common coding conventions or concepts that are trickier or outright don't work in Rust (for example, programming around structs may seem confusing to some people, especially if they're very used to OOP-based languages and designing things around that paradigm), and there are concepts and conventions to learn that may be tricky (e.g., borrowing, ownership, lifetimes).
WebAssembly, embedded systems, kernel modules, APIs, et al. It’s a general purpose programming language much like C, so it can be used for most anything really.
It might be the most "general-purpose" language there is because of how "easy" it is to write compared to C, how good webassembly support is and how easy it is to write portable code. I use it for almost everything whenever I can.
The larger projects I've done are cryptographic implementations and retro console emulators that works both natively and on the web.
Is it for making cross platform apps? Is it for mobile apps and tablets? Is it aimed at device for is it aimed at deployments it is more like backend and server related?
Rust is aimed to becapableof filling all the niches C and C++ do, but with higher-level constructs that make it a bit of a paradox if you ask "Is it low-level or high-level?"
(Rust is capable of low-level things and does require you to think about memory a bit but, once you get used to it, many people use it in place of scripting languages because of the compile-time guarantees... both the ones it comes with and ones you can build using things like thetypestate pattern.)
When looked at based on the available ecosystem, its biggest strengths currently are:
Writing CLI tools (If you don't depend on C code, it'll produce Go-esque self-contained binaries, it starts instantly, and it's got great building blocks likeclap,Serde(andcsvandquick-xml),ignore,Rayon, etc.)
Writing resource-efficient web services (We don't have a Django or Ruby on Rails yet, but if you're OK with a Flask or Sinatra, frameworks likeactix-webandRocketblow things like Node.jsout of the waterwhen it comes to RAM and CPU requirements without compromising on memory-safety AND allow you to check more invariants for correctness at compile-time. SeeAre We Web Yet?for more.)
WebAssembly (Rust's combination of not needing a garbage collector or VM and providing a high-level experience with great dependency management makes it uncommonly well-suited to WebAssembly work and they'releaning into thatwith the tooling and documentation.)
Writing compiled modules for other languages in an "if it compiles, it's safe" manner. (Rust Interop,Are We Extending Yet?,godot-rust, etc.)
Its biggest weaknesses are:
Producing bindings to existing cross-platform GUI toolkits like Qt is hard work for a young language (I usePyO3and PyQt orPySideto set up a "frontend in Python, backend in Rust" configuration when I need QWidget GUIs, similar to how you have to use Qt's QML ECMAScript dialect for the frontend if you want to write a Qt Quick GUI, regardless of the host language. Youcanusegtk-rsfor GTK, but the GTK devs seem determined to unofficially deprecate using it to make applications that don't follow GNOME's increasingly alien-feeling HIG by neglecting that use-case and tying any attempts to catch up with Qt's level of convenience to libadwaita. That said, Microsoft does provide official bindings for WinAPI if you want to write something Windows-only, there are also equivalent crates for Apple APIs, and you can useTauriif you want an Electron-like solution. SeeAre We GUI Yet?for more.)
Anything not based on Java or officially supported by Google is going to have limited ability to interact with Android platform APIs. (So, for non-game development, you'd want to do similarly to what Firefox Mobile switched to and use something likeflutter_rust_bridgeto have a frontend in a Google-supported language and a backend in Rust.)
NoDjango ecosystemyet... but then that's more a case of Django being exceptionally strong than of Rust being exceptionally weak.
Nothing like Django ORM or SQLAlchemy+Alembic yet, which will provide "auto-generate draft schema migrations by diffing your authoritative schema against what's in your database" and/or provide a way to have a single authoritative schema support both SQLite for easy single-user installs and something like MySQL or PostgreSQL for multi-user installs.
Available game engines are young, so the best option for game development with Rust is something like usingGodotand writing the performance-sensitive bits withgodot-rust. (SeeAre We Game Yet?for information on what Rustdoeshave.)
The other question I have is it opinionated? Some languages are opinionated on how they should be written and it’s use case, others less so
Yes, but mostly out of necessity. There are limits to what the borrow-checker's "compile-time garbage collection" can understand so, if you don't structure your code in a way that aligns with what it can understand, you'll be throwing a lot ofRc<T>/Arc<T>or.clone()orunsaferaw pointers around.
...not that throwing aroundRc<T>,Arc<T>, or.clone()is necessarily a bad thing... especially when you're learning. Rust has a tendency to lure you into making your code more efficient than it strictly needs to be if you don't keep an eye on the big picture.
(I say mostly because the default compiler configuration does also lint for identifier naming conventions such assnake_casefor variables andSCREAMING_SNAKE_CASEfor constants.)
Bear in mind that:
In exchange for that opinionatedness, you get "If it builds, it usually works first-time", "fearless refactoring", and "fearless concurrency".
Build automation and dependency management via Cargo is excellent and many of the language's speed bumps when learning the more advanced stuff are mitigated by being easily able to pull in a ready-made data structure crate likepetgraph
rustfmtis included with the toolchain and you can set your editor up to run it on save so you don't have to think about code style (cargo fmt, if you need to do it manually)... and itisconfigurable (eg. I useuse_small_heuristics = "Max")
If you use something that supports the Visual Studio Code protocol extensions likecoc.nvim, therust-analyzerlanguage server has an excellent stable of fixes and refactoring assists.
A ton of effort has been poured into making the error messages from the compiler extremelyfriendly and helpful.
The toolchain also includes a linter named Clippy which is designed to be just as friendly as the compiler and will not only point out unidiomatic things, but also provide links explaining why they're unidiomatic.
I understand it has some role in blockchain and/or web3 most of which is because of its low footprint and it’s route to market /ship is easier than learning c
Yes, but we're not huge fans of that because blockchain people who see Rust as nothing but magic pixie dust for making them more money than their competitors tend to wander in here and try to drum up interest in things that are only tangentially related to Rust.
Also, I highly recommend checking outMy First Impressions of web3by Moxie Marlinspike andLine Goes Up - The Problem with NFTsby Folding Ideas so you have proper context for all this blockchain and crypto stuff. (And, if you have time,An Honest Conversation On The Problem With NFTs & Cryptocurrency, with @Folding Ideasby The Financial Diet for some coverage of what got cut for time.)
This might be unpopular, but I personally think Rust was (is--I'm still learning) harder to learn than C. The ownership model is restrictive in ways C isn't, for one thing. (I get that this is for good reason.) And its greater functionality requires more complexity overall.
But Rust's massive collections of libraries make lots of practical tasks easier on Rust than standard C.
These days, any task for which I would have used C or C++, I use Rust.
Rust is a general-purpose language. You can do almost anything with it, and there are libraries for many use-cases. Take a look on crates.io if you want to see the available libraries.
However, despite being general-purpose, libraries have ways to make it extremely ergonomic. For example, theserdelibrary can generate serialisation and deserialisation code for your data structures simply by attaching one annotation to the struct, like so:
The other question I have is it opinionated? Some languages are opinionated on how they should be written and it’s use case, others less so
Rust has opinionations about the way you write your programs. You have to learn to write in a way that satisfies Rust's checkers (if you have issues with this, it's usually the borrow checker). In return, you get a guarantee that your program is sound.
There is a learning curve to satisfying the checkers, but once you can do it, you will find the checkers to be extremely helpful.
Assuming a greenfield project (because the discussion iswaymore complicated for pre-existing codebases), I'd avoid rust if:
I'm targetting unusual hardware, where going off the beaten path and using immature tooling is going to become very painful very quickly.
I'm working on a project that will need to comply with some sort of regulation, and where the path to compliance is much more straightforward if I'm using something like, say, MISRA C or Ada.
I need to use pre-existing libraries that don't map well to Rust and would therefore lead to mostly unidiomatic code.
Adding on:
When the business hiring needs are important. Finding coders who understand high energy microwave engineering (insert some other highly niche industry where the senior programmers *need* to do more than just code to a spec. Someone has to write those specs) and the needs of that field is going to be a big deal. Adding in that you need the most senior of those engineers to *also* know rust versus something so central to the industry like c++? Yeah, no.
I don't recommend using Rust when you're working in a C++ team on an established project.
This can be extended to any language : if you have a working project and happy maintainers, don't change the tech stack.
RUST DEV, carefully mangling his symbol names: Happy little C++ symbols you could be, couldn’t you?
This won't stop me from trying, though.
For professional work, if you have a large cpp codebase, stick with c++.
For personal work, use what you enjoy. Use Cobol, some esoteric language, or the hippest JS flavor as long as you enjoy your dev experience. Especially for personal work, I think devs are too quick to disregard their (and others) enjoyment and happiness when making technical decisions.
Unfortunately, if you're doing something that is compile-time heavy, I would not recommend Rust. Macros are great from the user side, but on the library side they are just nasty. Even templates in C++ are more comprehensible and something like zig comptime is just miles ahead.
tight integration with CUDA code
many things related to machine learning - particularly things for which pytorch is well-suited - though this is changing really fast (for the better). Fingers crossed.
The CUDA issue is what's holding me back from doing more in Rust over C++. Particularly with libraries like Thrust abstracting away a lot of the lower level kernel programming.
Once the GPGPU situation matures (and maybe NVIDIA decide to make a Thrust crate) then rust will become a lot more attractive for the kinds of projects im working on
"There are only two kinds of languages: the ones people complain about and the ones nobody uses".---Glad to see fluffy negative articles about Rust shooting up the first slot of HN in 20 minutes. It means Rust has made finally made it mainstream :)---The points, addressed, I guess?- Rust has panics, and this is bad: ...okay? Nobody is writing panic handling code, it's not a form of error handling- Rust inserts Copy, Drop, Deref for you: it would be really annoying to write Rust if you had to call `.copy()` on every bool/int/char. A language like this exists, I'm sure, but this hasn't stopped Rust from taking off- Fetishization of Efficient Memory Representation: ... I don't understand what the point is here. Some people care about avoiding heap allocations? They're a tool just like anything else- Rewrite anything and it gets faster: okay sure, but there are limits to how fast I can make a Py/JS algorithm vs a compiled language, and Rust makes writing compiled code a bit easier. People probably aren't rewriting slow Python projects in C these days- Rust is as complex as C++: ...no, it's not. Rust really hasn't changed much in the past 6 years. A few limitations being lifted, but nothing majorly new.- Rust isn't as nice of community as people think: subjective maybe? People are nice to me at conferences and in discussion rooms. There's occasional drama here and there but overall it's been pretty quiet for the past year.- Async is problematic: Async Rust really is fine. There's a huge meme about how bad it is, but really, it's fine. As a framework author, it's great, actually. I can wrap futures in a custom Poll. I can drive executors from a window event loop. Tokio's default choice of making `spawn` take Send/Sync futures is an odd one - occasionally cryptic compile errors - but you don't need to use that default.I'm unsure why this article is so upvoted given how vapid the content is, but it does have a snappy title, I guess.
> Rust is as complex as C++: ...no, it's not.Maybe not yet, but it is heading in that direction; and I only say this because of the absolutely giant pile of features in unstable that seem to be stuck there, but I hope will eventually make its way to stable at some point.> Async Rust really is fineI dunno. Always thought it was too complicated, but as another person pointed out avoiding Tokyo::spawn solves many issues (you said this too, I think). So maybe, not Rust's fault :D
> Maybe not yet, but it is heading in that direction;It's definitely gettingmorecomplex, but C++ has a huge lead haha. C++ is like a fractal in that you can look at almost any feature closer and closer to reveal more and more complexity, and there are alotof features... Here's a page on justonedark corner of the language:https://isocpp.org/wiki/faq/pointers-to-membersand it interacts in interesting ways with all the other corners (like virtual vs non-virtual inheritance) in fun and exciting ways...Also, there are far more ways to cause UB in C++. Rust has a big lead on formalizingwhatconstitutes UB, and even those rules you only need to learn if you are using "unsafe", whilst in C++ you don't have that luxury.
> Also, there are far more ways to cause UB in C++.As well as lots of Undefined Behaviour, C++ also has what its own experts call "False positives for the question is this a C++ program" the Ill-Formed No Diagnostic Required features, nothing like these exist in Rust, they're cases where you can write what appears to be C++ but actually although there are is no error or warning from the compiler your entire program has no meaning and might do absolutely anything from the outset. I've seen guesses that most or even all non-trivial C++ invokes IFNDR. So that's categorically worse than Undefined Behaviour.Finally, C++ has cases where the standard just chooses not to explain how something works because doing so would mean actually deciding and that's controversial so in fact all C++ where this matters also has no defined meaning and no way for you to discover what happens except to read the machine code emitted by your compiler, which entirely misses the point of a high level programming language.One of the things happening in Rust's stabilization process is solving those tough issues, for example Aria's "Strict Provenance experiment" is likely being stabilized, formally granting Rust a pointer provenance model, something C++ does not have and C23 had to fork into a separate technical document to study.
I found their comment an interesting contribution to the discussion, pointing to a couple of specific pitfalls in C++. It's not just an empty "C/C++ bad, Rust good", and I don't see why it'd give the impression of an obnoxious community.
I just wrote that as an observation, and I did not mean to offend the parent.Now, let me explain why I felt that way. First and foremost, the phrase "undefined behavior" only applies to C and C++ because the specifications of those languages define it. The statement that Rust has no UB does not make sense because Rust has no specification, and all behavior is defined by the default implementation.For example, C/C++ specifications state that using a pointer after calling "free()" on it is UB. But an implementation can make it well-defined by adding a GC and making "free()" a no-op. Hence, memory safety is entirely orthogonal to UB.Another example: signed overflow being UB is not a memory safety problem unless the value is used for array indexing. Also, it is possible to enable bounds checking in STL containers (like _GLIBCXX_ASSERTIONS).It seems like that a lot of Rust fans read John Regehr's posts and use "undefined behavior" as a boogeyman to throw shade at C/C++. They repeat the same points ad nauseam. It also helps that the phrase "undefined behavior" evokes strong emotions (eg., "nasal demons"). I see the parent commenter doing this frequently and sometimes[1] even in the C++ subreddit (of all the places!). How is this not obnoxious?Here[2] is another person doing the same, but in a spicier tone. Linked lists and graphs are safe if you have an isoheap allocator (look at Fil-C).You can say that it is moral to endlessly reiterate the problems of unsafe languages, because it could lead to more secure software. But see the reply to my other comment by "hyperbrainer"[3] which says that Rust is "completely" memory safe, which is entirely wrong[4]. It is hard not to suspect the motives of those who claim to be concerned about memory safety.[1] -https://old.reddit.com/r/cpp/comments/1fu0y6n/when_a_backgro...[2] -https://news.ycombinator.com/item?id=32121622[3] - I am unable to reply because of the depth.
[4] - Rust requires unsafe to do a lot of things which can be done in safe code in a GC'd language. Thus, unsafe is pretty common in Rust than most GC'd languages. If a segfault can literally kill a person, it is absolutely immoral to choose Rust over Java (it does not matter that Rust "feels" safer than Java).
I really am interested in what Safer C++ proposes for [1], but I never found out.Your point [4] is very silly because you're assuming that while the unsafe code implementing a safe Rust interface might be flawed the code implementing a safe Java interface such as its garbage collector (which will often be C++) cannot be. As we'd expect, both these components are occasionally defective, having been made by error prone humans, such flaws are neither impossible nor common in either system. There are indeed even safer choices, and I've recommended them - but they're not Garbage Collected.> First and foremost, the phrase "undefined behavior" only applies to C and C++ because the specifications of those languages define it.Nope, those words have an ordinary meaning and are indeed used by Rust's own documentation, for example the Rustonomicon says at one point early on, "No matter what, Safe Rust can't cause Undefined Behavior". The purpose there is definitional, it's not a boast about how awesome Rust is, it's a claim that if thereisUndefined Behaviour that's not because of the safe Rust, there's a soundness problem somewhere else.> Another example: signed overflow being UB is not a memory safety problem unless the value is used for array indexingThis is wrong. Because Signed Overflow is UB the C++ compiler is allowed to just assume it will never happen, regardless of the systemic consequences. What that means is that other IR transformations willalways be legaleven if they wouldn't have been legal for any possible result of the overflow. This can and does destroy memory safety. Actually it would be weird if somehow the IR transformations always preserved memory safety, something they know nothing about, despite changing what the code does.
> The statement that Rust has no UB does not make sense because Rust has no specification, and all behavior is defined by the default implementation.It is in the reference.https://doc.rust-lang.org/reference/behavior-considered-unde...
> The statement that Rust has no UB does not make sense because Rust has no specificationI don't think it was claimed that Rust has no UB in this conversation, only IFNDR.From what I can tell, Rust does document a set of "behavior considered undefined" like using unsafe to access misaligned pointers. For practical concerns ("could code optimization change these semantics?", "is this guaranteed to work the same on future compiler versions?") it seems reasonable to me to call that undefined behavior, and to say that Rust doesn't have much of it.> I see the parent commenter doing this frequently and sometimes[1] even in the C++ subreddit (of all the places!). How is this not obnoxious?Both their comment here and their reddit comment look fine to me. Something like "C++ sucks, switch to Rust!" would be annoying, but specific relevant technical comparisons ("In Rust for comparison the static growable array V isn't dropped when the main thread exits [...]") seem constructive.> Rust requires unsafe to do a lot of things which can be done in safe code in a GC'd language. Thus, unsafe is pretty common in Rust than most GC'd languages. If a segfault can literally kill a person, it is absolutely immoral to choose Rust over Java (it does not matter that Rust "feels" safer than Java).Java does technically have the Unsafe class for low-level unsafe operation and JNI to interoperate with C/C++/assembly.I'd expect that the average Rust program makes more use of unsafe, but largely just because the average Rust program is lower-level (including, increasingly, parts of the Linux and Windows kernels). It's unclear to me whether the same program written in Java or Rust would ultimately prevent more bugs.
> Now, let me explain why I felt that way. First and foremost, the phrase "undefined behavior" only applies to C and C++ because the specifications of those languages define it. The statement that Rust has no UB does not make sense because Rust has no specification, and all behavior is defined by the default implementation.There are at least three classes of definedness of behavior:1. The behavior of a program is defined by a spec.2. The behavior of a program is not formally defined by a spec, either because the language has no spec or because it's imprecise, but it's defined in a sociological sense: that is, if a compiler doesn't follow the apparent meaning of the program, the people who develop the compiler will consider it a bug and you can report it to mailing lists or GitHub and probably get support.3. The behavior is definitely undefined: a compiler can do anything in response to the program and the developers of the compiler will not consider it a bug.C++ has a lot of 1, comparatively not a lot of 2, and a lot of 3.Rust has none of 1, a lot of 2, and a lot of 3. But safe Rust has very little of 3.
> Most (if not all) of your posts here on HN boil down to "C/C++ bad, Rust good".I haven't measured but it's easy to say categorically that it's not "all" unless somehow my posts about network protocols, aeroplanes, security and psychology among others fall into this vague category.And yes, like Ignaz Semmelweis I can see an obvious improvement to how my profession does what it does and it's infuriating that the response from many other practitioners is "No, I don't like change, therefore you're crazy for explaining why I should change"Ignaz Semmelweis died in an asylum. But on the other hand while Ignaz was correct and his proposals would have worked he couldn't explainwhybecause germ theory was only confirmedafterhe died. Rust isn't in that situation, we know already exactly what the problems are with C++. So that means I can tell you not justthatusing C++ is a bad idea, butwhyit's a bad idea.
What is "more memory-safe than rust" supposed to mean? Rust is completely memory-safe.
OnlysafeRust can guarantee this, and only as a consequence of anyunsafeRust being correct.Most of the popular Garbage Collected languages of coursealsohave a way to escape, in some cases via an "unsafe" keyword or magic unsafe package to a language where the same safety rules do not exist, in this sense the difference in Rust is that it's the same language.I'd actually say themorememory safe option would be a language like WUFFS where it pays a high price (generality) to deliver categorically better safety and performance. Most software could not be written in WUFFS but also most of the software which could be written in WUFFS isn't.
> Maybe not yet, but it is heading in that directionAbout 95% of the unstable features lift limitations that most people expect not to be there in the first place. I'm not aware of all too many that aren't like that.
> Maybe not yet, but it is heading in that directionWhen people say that Rust is complex, they often neglect to differentiate betweenimplementation complexityanddeveloper facingcomplexity. The implementation complexity is growing in part to support the end usersimplicity.I also don't understand why anyone feels the need to know every feature of the language. You can just learn about and use the features that you need.
That only works if you sit in isolation on a mountain and start with no_std and write everything else from scratch, yourself.The majority exist in a community and have to collaborate with others. They have to deal with the code written by others, code which may use any language feature.Every developer doing serious work will trip over every available language feature eventually.
> Every developer doing serious work will trip over every available language feature eventually.Steve Klabnik:“Just to provide another perspective: if you can write the programs you want to write, then all is good. You don't have to use every single tool in the standard library.I co-authored the Rust book. I have twelve years experience writing Rust code, and just over thirty years of experience writing software. I have written a macro_rules macro exactly one time, and that was 95% taking someone else's macro and modifying it. I have written one proc macro. I have used Box::leak once. I have never used Arc::downgrade. I've used Cow a handful of times.Don't stress yourself out. You're doing fine.“https://www.reddit.com/r/rust/comments/1fofg43/i_am_struggli...
> Maybe not yet, but it is heading in that directionI have little doubt that Rust will end up being as complicated as C++ eventually, but a big difference is how explicit and well documented the discusson of new features are.The Rust RFCs provide a ton of context to almost every feature of the lagnuage. I find that historical context extremely helpful when trying to figure out why something is the way that it is.There may be something like that for C++, but I feel like a lot of it is "you had to be there" kind of reasons.
ISO Rationales and papers.
Yeah I’m sure they exist, but googling “C++ ISO Rationales” doesn’t give me them.Searching for “Rust RFCs” reveals a git repo with thousands of markdown files describing features and their motivations with links to discussions.
Because ISO processes are only open to those in the know.Same applies to Ada, C, Modula-2, Pascal, Fortran, Algol, Cobol,.....
That's... what I originally said...
"in the know" and "you had to be there" are effectively the same statmentIt's is exactly why I feel more comfortable with complexity creep in Rust as opposed to C++, since I can easily find and read the rationale for just about every feature.
No they aren't, those "in the know" have access to ISO servers, mailing lists, meeting minutes, paper votes, and related content.Some of the public C++ stuff:https://www.open-std.org/jtc1/sc22/wg21Some of the public C stuff:https://www.open-std.org/jtc1/sc22/wg14/Some of the public Ada stuff:https://www.open-std.org/JTC1/SC22/WG9/And so on.Those "in the know" have access to the stuff that is beyond that.However that is already plenty of stuff publicly available at thosehttps://www.open-std.orgsubsites as well.
I don’t really know what your argument is> Those "in the know" have access to the stuff that is beyond that.Yeah “you have to be there”But these are all great!It’s a shame they’re not as discoverable.
> Fetishization of Efficient Memory Representation: ... I don't understand what the point is here. Some people care about avoiding heap allocations? They're a tool just like anything elseThe point is that dealing with the Rust borrow checker is a huge pain in the ass and for most Rust applications you would have been better off just using a garbage collected language.
> huge pain in the assMaybe if you structure your code weirdly? I haven't encountered a major borrow checker issue that I couldn't easily resolve in many years.
It's not appropriate to say that "having trouble with borrow checker means code is wrong". Sometimes you just want to add a new feature and the borrow check force you to do a big refactor.See also:https://loglog.games/blog/leaving-rust-gamedev/
I hear this constantly but never see any examples of what they actually mean, or it's coming from misunderstandings of what the language is. I've seen people say how well the async code could be if Rust got a garbage collector. For the borrow checker specifically, I think it's important to understand smart pointers, Cell/RefCells, other primitives, and the fact that you don't have to solve everything with references.
> it's coming from misunderstandings of what the language is“You are just not holding it right.”Rust borrow checker indeed does force you to make contorsion to keep it happy and will bite you if you fail to take its particularity into account. It’s all fine and proper if you think the trade-off regarding safety is worth it (and I think it is in some case) but pretending that’s not the case is just intentionally deluding yourself.The people here implying that the BC forces you to use a good architecture are also deluding themselves by the way. It forces you to use an architecture that suits the limitations of the borrow checker. That’s pretty much it.The fact that such delusions are so prevalent amongst part of the community is from my perspective the worst part of using Rust. The language itself is very much fine.
Can you give me an example of what the borrow checker prevents you from doing without calling Rust developers delusional?
The hardships are way overstated, in my opinion. One issue I can think of newcomers might have is immutable and mutable references. You can't borrow as mutable something already borrowed. Let's say you have a reference to a Vec element, then you add an item to Vec. The realloc could invalidate that reference, which Rust prevents. Using Cell/RefCell also helps if you don't want to deeply nest &mut.
Rust is definitely hard, but after a while it's fine and you kind of get how even if using another language you still have to think about memory.
I’m not calling Rust developers delusional. I’m calling people pretending the borrow checker doesn’t force you to specifically architecture your code to suit it delusional.> Rust is definitely hard, but after a while it's fine and you kind of get how even if using another language you still have to think about memory.That kind of comment is a typical exemple. It’s not that you have to think about memory. You have to understand the exact limitations of the analyser Rust uses to guarantee memory safety. I don’t understand why it’s so hard to accept for some part of the Rust community.
The advantage of satisfying the borrow checker isn't all that obvious. The BC is designed to make the program behave well with the fundamental machine model of a common computing device. You may be able to get away with spaghetti code for a new feature in a GC-based language. However my experience is that such technical debt grows over time and you're forced to carry out a massive refactor later anyways. GC isn't going to help you there. You might as well refactor the code in the beginning itself with the guidance of the BC in order to avoid pain in the end. This is why Rust programs have a reputation to run correctly almost always if they compile.And as the other commenter said, the borrow checker isn't all that hard to satisfy. BC complaints are often related to serious memory handling bugs. So if you know how to solve such bugs (which you need to know with C or C++ anyway), BC won't frustrate you. You may occasionally face some issues that are hard to solve under the constraints of the BC. But you can handle them by moving the safety checks from compile-time to runtime (using RefCell, Mutex, etc) or handle it manually (using unsafe) if you know what you're doing.Like the other commenter, I find some of the complaints about programming friction and refactor to be exaggerated very often. That's unfair towards Rust in that it hurts its adoption.
I haven’t had to „deal with” the borrow checker since like 2018. It’s quite smart
Having just delved into Rust a little (and then given up and decided to learn Dart/Flutter for more practical applications development - I don't need another language to make command line tools in), this one I did feel while I was going through documentation.The problem is most of the important problems you deal with while programming require heap allocations: i.e. a lot of Rust advice is liable to lead you astray trying to find over-complicated solutions to optimizations you probably don't need up front.So in terms of systems programming, Rust is technically good here - these are all things you'd like to do on low level code. On the other hand if you're making a bunch of web requests and manipulating some big infrequently used data in memory...Box'ing everything with Arc is probably exactly what you should do, but everyone will tell you to try not to do it (and the issue is, if you're like me, you're coding in the "figure out what and how to do it" phase not the "I have a design I will implement optimally" phase).
I mean, maybe?If you come into Rust thinking you're going to write doubly-linked lists all day and want to structure everything like that, you're going to have a bad time.But then in python you run into stuff like:```def func(list = []):list.append(1)```and list is actually a singleton. You want to pull your hair out since this is practically impossible to hunt down in a big codebase.Rust is just different, and instead of writing double-pointer code, you just use flat structures, `Copy` keys, and `loop {}` and move on with your life.
FYI this site doesn't use ``` for code blocks, it uses indentation (two spaces).https://news.ycombinator.com/formatdoc
A bit off topic, but how do people usually write code here or on Reddit, I always find it to be really cumbersome to make sure there's two spaces etc in front of everything? Is there some formatting tool that I'm not aware of that everyone else uses?Because in both forums I keep coming back to edits, and it takes forever to edit some of the things, manually. I feel like I'm being stupid or the UX of all of that is just so terrible.
I write it in play.rust-lang.org, then indent using the vim keybindings. I do this even for not rust code.
I actually use a formatting tool online if on mobile, or just vim if on the computer, which can add two spaces in front of every line.
> or just vim if on the computerI use Firefox + Tridactyl + the native extension, so with the cursor in any text field I can hit Ctrl+i and it pops up a gvim window with the contents of that text field.  When you save+quit, it copies the contents back into the field.So glad someone figured out how to do this again once Vimperator died.
I paste the code into an invocation ofsed s/^/  /
Specifically:1. Copy code to clipboard.2. From a shell prompt on macOS,pbpaste | sed 's/^/  /' | pbcopyLinux (Wayland),wl-paste | sed 's/^/  /' | wl-copyLinux (X11),xclip -o -se c | sed 's/^/  /' | xclip -se cWindows (PowerShell),Get-Clipboard | % { $_ -replace '^','  ' } | Set-Clipboard3. Paste into HN.
Thanks, I didn't know about xclip -se cI've been typing out "-selection clipboard" this whole time!
Code editor and then paste.
> this is practically impossible to hunt down in a big codebaseuse linters, they keep getting smarter
rustc is a good smart linter
And if you're really wanting to be stringent, clippy exists for more subjective or more expensive lints. And it's also very good.
I have literally never used a doubly-linked list in my life, and I'm pretty sure that most programmers can say the same thing.As for the example... yeah, Python is pretty terrible (for writing production codebases, I think its a great language for short-lived, one-person projects).  Interesting that you mention Python because if you're considering Python and Rust for the same use case that's pretty bonkers, for anything that you might possibly have used Python to do there are many more natural choices than Rust. If you wouldn't have done it in C/C++ ten years ago, you probably shouldn't be doing it in Rust today.
If the programmers have a proper degree, they surely have used them, additionally they probably have done it inderectly, depending on what languages they use.
Yeah. I wouldn't use Rust as a scripting language for that reason. But some critical applications want that enforced correctness and (hopefully) proper performance to be guaranteed if you pass the compiler.I want to eventually join the "50 engines for every game" race that is rust gsme engineer development, but I'm sure not going to have the fast iteration part of design be done in Rust. The renderer and all the managers should be absolutely solid, but some parts of games need you to break stuff quickly.
Enforced correctness is great.  Manual memory management isn't appropriate for most applications (games of course are an example of where it is!)
> Rust really hasn't changed much in the past 6 years.Even more importantly than this, Rust has a major emphasis on backwards compatibility. The author mentions a "hamster wheel" of endless libraries, but, in Rust, nothing's forcing you to switch to a newer library, even if an old one is no longer maintained.In general, the complexity of your project is completely up to you, and (at least to me) it seems like a lot of the new features (e.g. generator syntax) are trending towards simplicity rather than complexity.
> I'm unsure why this article is so upvoted given how vapid the content is, but it does have a snappy title, I guess.rust, sqlite, htmx... there is a small list of techs that always get massively upvoted on hn, whatever the content or quality of the article.
Well, if the entirely of that list is as awesome as those 3, then it's a good list to be.
>  Rust isn't as nice of community as people thinkIt's a numbers game. As the number of people using Rust grows, so does the number of Jerks using Rust. And it's not like the Rust community is a stranger to bullying maintainers of crates for various things.> Async is problematic: Async Rust really is fine.It's... OK. It has a few issues, that hopefully will get fixed, like making Pin from a generic struct into a type of reference. e.g. instead of `Pin<&str>` you would write `&pin str`.There is also the coloring problem which is quite a hassle and people are looking into possible solutions.
>it would be really annoying to write Rust if you had to call `.copy()` on every bool/int/char. A language like this exists, I'm sure, but this hasn't stopped Rust from taking offWell C++ does the same by default. You need to opt in for deep copies. C++ doesn't drop by default but modern practices like Smart pointers do.>I'm unsure why this article is so upvoted given how vapid the content is, but it does have a snappy title, I guess.Even HN isn't immune to the 90-9-1 rule.
What is the 90-9-1 rule?
I’m guessing 90% don’t care, 9% vote, 1% comment?
I've seen a case where the rust panic handler is used in FFI and this creates a memory leak.
"There are only two kinds of languages: the ones people complain about and the ones nobody uses." This is a famous quote from Bjarne Stroustrup in defense of C++. Source:https://www.stroustrup.com/quotes.htmlIMO, it's ironic to see Rust proponents using his quote in defense of Rust (and not crediting him).
I was going to write a rebuttal but then I read your comment and it mirrored roughly what I was going to write.> - Rust inserts Copy, Drop, Deref for you: it would be really annoying to write Rust if you had to call `.copy()` on every bool/int/char. A language like this exists, I'm sure, but this hasn't stopped Rust from taking offOne improvement here could be the IDE. I don't want to write `let s: String` every time but the IDE (neovim LSP) does show it. It'd be good if I can get the full signature too.> Async is problematicAsync Rust is by far the best Async out there. Now when I use other languages I am essentially wondering what the hell is going on there. Is there an executor? Is there a separate thread for this? How/When is this getting executed? Async Rust doesn't execute anything and as a result you can get an idea of how the flow of your program goes (as well as pick an executor of your choice, might not seem important if you are on the Tokio bandwagon but if you are in an envrionment where you need a custom executor and you need to control CPU threads, Rust Async suddenly makes a lot of sense)
> Rust has panics, and this is bad: ...okay? Nobody is writing panic handling code, it's not a form of error handlingAs far as I know, the issue with the panics is that things panic a lot. Times when C or C++ will limp along in a degraded state and log something for you to look at will cause your Rust program to crash. That turns things that are not problems into things that are problems.
First, things don't panic a lot in my experience writing Rust for the past three years.
Second, when things do panic, it indicates a defect in the code that needs to be fixed. Aborting the program with a stack dump is the perfect behavior for seeing the state and the invariant that was violated and then figuring out the fix. Contrast this to C or C++ "limping along", usually until a later invariant causes a crash and being further away from and obscuring the true root cause, and we see why C and C++ code is generally still so bug-ridden relatively speaking. Fail-fast is not just a buzz word and program bugs are not recoverable errors.  Seehttps://joeduffyblog.com/2016/02/07/the-error-model/
These arguments get said a lot and they are all fine in theory, but in practice, all code over a certain size has a tremendous number of latent bugs, even Rust code. At a certain scale, you are virtually guaranteed to be running in a degraded mode of some kind. If the consequences of those latent bugs are operational nightmares, that's a problem. Most people would rather be able to roll in at 10 am to debug a minor issue from logs and traces than get a page at 1 am with 1000 stack traces in it.
> These arguments get said a lot and they are all fine in theory, but in practice, all code over a certain size has a tremendous number of latent bugs, even Rust code.Are you claiming this from direct experience, or do you have some data to back it up? Apparently the rollback rate for Rust code in Android is less than half that of C++. [1]1.https://security.googleblog.com/2024/09/eliminating-memory-s...
I wonder how you could realistically end up in those two situations for the same issue though.
If your goal is to converge on correctly functioning software, you know, for the benefit of the users of it, then fail-fast can help.
If your goal is to optimize the sleep patterns of devops people and make changes to code without testing before releasing it to production, yeah... do what you need to do. :)
You can have correctly-functioning software when parts of it are operating in a weird way. The complaint I have heard about Rust crashes is that the default behavior is to crash in any situation thatcould possiblybe weird.By the way, the trade you're talking about is great for desktop software (especially for browsers), but server-side software at scale is a bit different.The borrow checker and all the Rust safety stuff is also completely orthogonal to most forms of testing. You don't get to do any less because your language protects you against a specific class of memory-related errors.
Things should not panic a lot, and when I’m going over someone else’s Rust code I will discourage them to use panic at all if it’s socially appropriate.Inasmuch as I am aware, the correct usage of panic is “there is no way to recover from this without leaving the application in an undefined state”.Not “a file I expected to exist wasn’t there” or “the user gave bad input” or “I didn’t implement this feature yet”.But more like “a cosmic ray must have struck the machine or something, because this ought to be logically impossible.”Or pretty much, if you literally don’t see a mechanism in Rust that can pass an error upwards and the program also cannot continue execution without the result being affected, then you panic.That’s a little stricter than what I understand the official guidance is, but not much.If you have something panicking it should be less “I can’t see what’s going on” and more “thank god it stopped itself so it didn’t write bogus data to production.”
>Rust inserts Copy, Drop, Deref for you: it would be really annoying to write Rust if you had to call `.copy()` on every bool/int/char. A language like this exists, I'm sure, but this hasn't stopped Rust from taking offIs it possible to disable this behavior? I think it might be useful as a learning tool to familiarize myself with the Traits.
It is not.
Maybe I suffer from brain damage due to knowing C++ since 1993, starting with Turbo C++ 1.0 for MS-DOS, however Rust is indeed getting into C++'s complexity.Lets not forget people tend to compare 40 year old language complexity, ampered by backwards compatibility and large scale industry deployment, with one that is around 10 years old, with lots of features still only available on nightly.The Unstable Book has an endless list of features that might land on Rust.
Only about 1/3 of those are language features. Out of those a ton are #[cfg] related (i.e. being able to more accurately doing conditional compilation), const (lifting limitations with compile time evaluation), documentation, architecture specific additions (like intrinsics) and co.I only see about like 30 or so that are actual proper language additions, some of which are just exploration without even an RFC either, leaving us with about 15 or so, which really isn't that bad.
Every single of them needs brain space, regardless of the use.Also any language designer knows that every feature has exponential capacity due to the way it interacts with everything already in use, that is why innovation tokens are a thing in language design.
I’ll try to keep this comment shorter. :)The thing about Rust abstractions is that they’re a lot more useful and forgiving than C++.Eg: In Rust, I cannot accidentally use an option incorrectly and have the program compile. When it fails to compile, there’s a good chance the compiler will suggest how I could do what I wanted to do.In C++, if I dereference an optional without checking it, I’ve triggered “undefined behavior”. The program will probably just segfault, but it could also return a bogus object of uninitialized memory, but technically it could overwrite my boot sector or call a SWAT team to raid my house, and still be in compliance with the C++ spec.Thus when considering code written in Rust, I mostly need to just consider the happy path. With C++ I need to pedantically check that they used the constructs correctly, and consider many more runtime paths due to how lax the language is.If I see someone dereference an optional without an if-guard, I now need to backtrack through the logic of that entire function to make sure the program doesn’t crash. If I see someone use a destructured value from an Option in Rust, I can rest easy that unless they used unwrap() somewhere, the compiler has done that for me.This scales well for larger abstractions, because if I’m not actively digging into some code I can treat it more as a black box where it interacts with the code I am working with, than as a box of firecrackers that might explode if I do something unexpected with it.
Use the C++ clippy version, plenty of variants to chose from.Which by way is a good point, even Rust needs its clippy, so not everything is so perfectly designed to make clippy superfluous.
> plenty of variantsAaaand you’ve lost me.I don’t want to waste my time either setting up multiple linters or having to drill down into the pros and cons of each. If the C++ community cannot even reach a consensus on which linter it endorses, I imagine it can’t reach a consensus on what it lints, which involves even more decisions.Secondly, both times I’ve tried to roll out or use a linter, I’ve encountered passive or active resistance from the other developers on the team.This resistance went deeper than the linter. On one team they didn’t want to use new language constructs from the last decade, on the other team they explicitly complained about me doing things differently than 15 years ago. In both cases they rejected what I understood to be the core C++ guidelines in favor of writing their own codebase-specific coding guidelines so they could pick and choose the constructs they understood rather than trying to adhere to what might be idiomatic for a particular edition.Unless something is 100% endorsed by the C++ community, it’s absolutely not something that I’m even going to try to champion. I’ve already been flat-out told “no one cares about your opinion” trying to explain how type-safety in C++ can improve readability in code reviews, which I thought was completely noncontroversial.To your second point, the point of linters is to guide code to be more idiomatic; it’s not an issue of language design, but of educating humans in mostly non-functional readability and best practices.
Rust is nowhere near C++’s complexity.And most of C++’s language complexity doesn’t come from “large scale industry deployment”, it comes from implementing a feature in a half-assed way, then updating it, but then the old feature needs to be kept around so all the libraries need to deal with two ways of doing things. Then something new and better comes along, and it needs to deal with three ways of doing things.Meanwhile, developers get frustrated with how difficult the abstractions are to use, and end up carving out their own codebase-specific coding standards.On Rust’s side, there’s 10x the emphasis on making things easy to use, so developers converge to consensus on pretty much the same modern style.Just look at project management. Before I even write a project, with C++ I’m hit with choosing between a barrage of build systems and package managers, none of them particularly good. Will I use cmake and Conan? Then I’m stuck writing several lines of boilerplate before I even get started in a weird non-imperative language.In Rust, I type cargo init and I’m ready to go.C++ has basically completely fallen down when it comes to language design, and from what I’ve seen, is simultaneously in denial that things are so horrible for its end users (Bjarne Stroustrup iirc putting out an essay where he claimed “C++ is fine for any project I’m concerned about”) and suddenly trying to rush to (badly) copy features from Rust, and only recently coming to the realization that it really needs to abandon some of its fundamental precepts to stop self-sabotaging by carrying around massive amounts of baggage that nobody should be using anymore.Meanwhile even the White House and other government agencies are saying “please use anything but C or C++”. Because ultimately, no one writes anything close to modern C++, and even modern C++’s memory safety guarantees are painfully minimal in exchange for massive amounts of code complexity (you still have to track every pointer lifetime yourself, and every safety abstraction is opt-in, so you still have to have the expertise to not cut yourself, and every codebase is unique and different in its conventions, which precludes running any kind of static analysis that could rival Rust without significant time investment).It’s just..really bad. The only way Rust will get there is if it falls prey to the same feature hoarding as C++But Rust already has a deprecation-and-removal process for features, as well as an edition system to provide backwards compatibility for old code, and standardized tooling for linting that’s 10x better at telling you how to refactor than anything I’ve seen with C++.And god help you if you have an error in your code, because the C++ compiler will probably dump you out with a dozen irrelevant errors of dense template code you need to skip over, while with Rust you’ll make a mistake with lifetimes that will generate a text visualization of what you did wrong with the compiler pointing to what you need to change. Plus the Rust program will probably just run the first or second try, whereas the C++ program will segfault for the next ten minutes or so, because all the strictness in Rust means the complexity is more meaningful and less performative.Look at what people are learning in schools today and I bet they’re still starting with new and delete or even malloc and free rather than things like std::make_unique and std::span.The whole C++ ecosystem is basically predicated on nearly everyone having incomplete knowledge and doing something different and having to support or account for infinite combinations of features, whereas Rust has a higher barrier to entry but you can presume that pretty much everybody is using an idiomatic set of constructs for a given edition.Anyway, sorry for beating that over your head. I started with C++ around the time of Visual C++ 6, and to me it’s absolutely shameful at how bad the language has gotten. Whole ecosystems (C#, Java) and subsequent ecosystems (Go, Rust) have arisen in response to how bad people have it programming in C++, and despite two decades of people running away from C++ to create their own general-purpose programming language, so many proponents of the language seem to still be in denial. They’ve simply shifted the goalposts from C++ being the general-purpose programming language to it being a “systems” language to rationalize why the vast majority of developers don’t use it anymore because it refused to evolve.I see people these days comparing it to COBOL, that is, it’s not that anyone wants to use it for the merits of its language design, it simply has incumbency status that means it will be around for a long time.
Editions only cover syntax changes, and are hardly any different from compiler language switches when semantic and standard library changes are part of the picture.Lets see how complex Rust turns out to be, if it is still around after 30 years, to actually have fair comparison.We can also compare Rust in 2024, with the equivalent C++ version at 10 years old, when C++98 was still around the corner, C++ARM was the actual reference, and in that case the complexity fairs pretty equal across both languages.As for safety, as someone that is a hardcover believer in systems programming languages with automatic resource management, I would rather see C++ folks embrace security than rewrite the world from scratch.After all, Rust is in no rush to drop the hard dependency on LLVM and GCC infrastructure.
The big difference (inasmuch as I am aware) is in source compatibility in practice.If I use a header file, as any pre-C++-20 library will (have the major compilers implemented modulesyet?), I am SOL. I am specifying a text-import of that library’s code into my code. You’d need an “extern C++11”.As for comparing them at 10 years old, apparent language size might be similar, but in terms of program complexity C++ would be DOA.You’re telling me it takes an equal amount of time to learn these languages, but with Rust I can write code that works on the first try, while with C++ I have to account for data races and memory mistakes at every level of my program? Why do I, a 90s programmer dealing with OSes without process separation and soon the dotcom boom, want to touch that with a 10-foot pole?Java and C# would not exist. There’d be far too little value proposition with an alternative to C++’s memory-unsafety to justify the development of a whole new language.You’d probably see the equivalent of Python and JavaScript (probably named RustScript following the logic of the time). There’d probably be a Go equivalent developed, ie “language that compiles fast and runs almost as fast as Rust that stresses language simplicity”. Language expressiveness and simplicity are at odds with each other and there are uses of both.To be fair, Rust was developed with the last 30 years of programming in mind. But the thing is, memory safety kept on being a central issue of the languages that followed.The next big design issue will probably have more to do with people trying to use LLMs as a first-class programming language. Eg something that’s easy for LLMs to write and humans to read.Or something to do with heterogenous computing resources all sharing the same “program”. However here Rust seems already positioned to do well with its compile-time tracking of asynchronous resource dependencies between threads of computation, and procedural macros that can invoke an external compiler.So I’m not sure that conventional language design is going to change the path it’s been on for the last 30 years until the human side of that interface starts to significantly change.Most of the language design considerations we’re discussing boil down to “make things manageable to humans with limited memory”. If cybernetic augmentation or bioengineering sharply expands those limits, I suppose it could change the direction. Otherwise it feels like things are going to naturally cluster around “complex correct thing” and “simple iterable thing” because those are the two strategies humans can use to deal with complexity beyond the scope they can keep in their head at once.
IMHO the biggest Rust async annoyance is exactly this:> Tokio's default choice of making `spawn` take Send/Sync futures... combined with lack of structured concurrency.This means async tasks look like threads in every respect, causing you to end up using Arc<> and other concurrency constructs all over the place where they ought not be necessary. This harms efficiency and adds verbosity.
It's not too hard to do tokio without Send/Sync futures. See the example inhttps://docs.rs/tokio/latest/tokio/task/struct.LocalSet.html...It's kind of annoying that the current_thread flavor of the executor doesn't automatically enter a LocalSet and make spawn_local work out of the box but it's easy enough to do at the beginning of your program.
I use Box::leak without shame.
I just coined a term for this: CRust. This is when your entire program is in unsafe {}.
This was an oddly defensive and vapid comment. Mostly just handwaving away any views the article brings up, of which at least the article expands on their thoughts. This comment is just "meh not a bad thing" repeatedly. Why is this comment being upvoted?
The title is inflammatory and yet there are few nuanced takes in the article. It's weird to see it shoot to the top of HN.I think the loglog article is a much better, nuanced, full critique of Rust.https://loglog.games/blog/leaving-rust-gamedev/The internet is just so full of negativity these days. People upvote titles but don't read articles. Reading about people's views on subjects is useful, but I don't think this one is.
Inflammatory? "My Negative Views on X" is pretty far from inflammatory. It is exactly what the post was, with some positivity sprinkled in as well.
It’s 2024. If I read some thing I don’t agree with on the internet it IS inflammatory.
> This was an oddly defensive and vapid comment.Even comparatively, next to your own comment? I have no specific idea of what you object to or why, but I have learned that you are upset.
My big problem with Rust is too much "unsafe" code. Every time I've had to debug a hard problem, it's been in unsafe code in someone else's crate. Or in something that was C underneath. I'm about 50,000 lines of Rust into a metaverse client, and my own code has zero "unsafe". I'm not even calling "mem", or transmuting anything. Yet this has both networking and graphics, and goes fast. I just do not see why people seem to use "unsafe" so much.Rust does need a better way to do backlinks. You can do it with Rc, RefCell, and Weak, but it involves run-time borrow checks that should never fail. Those should be checked at compile time. Detecting a double borrow is the same problem as detecting a double lock of a mutex by one thread, which is being worked on.
> I just do not see why people seem to use "unsafe" so muchBecause it’s impossible to implement any non-trivial data structures in safe Rust. Even Vec has unsafe code in the implementation to allocate heap memory. When you need efficient trees or graphs (I doubt any non-trivial software doesn’t need at least one of them), unsafe code is the only reasonable choice.C++ does pretty much the same under the hood, but that’s OK because the entire language is unsafe.C# has an unsafe subset of the language with more features, just like Rust. However, it runs inside a memory-safe garbage collected runtime. Even List and Dictionary data structures from the standard library are implemented with safe subset of the language. Efficient trees and graphs are also trivial to implement in safe C#, thanks to the GC.
> When you need efficient trees or graphs (I doubt any non-trivial software doesn’t need at least one of them), unsafe code is the only reasonable choice.To name one example, the AnimationGraph in Bevy is implemented with petgraph, which is built using adjacency lists, and doesn't use any unsafe code in any of the parts that we use. It is very high-performance, as animation evaluation has to be.
> Are you sure evaluating these animations is performance critical?Isn't this obviously true? A key part of UI work is avoiding "jank", which commonly refers to skipped frames.> I doubt games have enough data to saturate a CPU core doing that.Got a bit lost here: games?> Screens only have 2-8 megapixels.4 bytes per pixel, 32 MB/frame. 120 frames / sec = 8 ms/frame. 3.84 GB/second.> animated objects need to be much larger than 1 pixel.Got lost again here.In general, I'm lost.First, there's a weak claim that all performant data structures in Rust must use unsafe code.I don't think the author meantallperformant data structuresmustuse unsafe code.I assume they meant "a Rust data structure with unsafe code will outperform an equivalent Rust data structure with only safe code"Then, someone mentions a 3D renderer, written in Rust, is using a data structure with only safe code.I don't understand how questioning if itstrulyperformant, then arguing rendering 3D isn'tthathard, is relevant.
> Isn't this obviously true?To an extent sure, but we’re talking about low level micro-optimizations. Games don’t animate individual pixels. I don’t think animating 1000 things per frame gonna saturate a CPU core doing these computations, which means the code doing that is not actually performance critical.> Got a bit lost here: games?I searched the internets for “Bevy Engine” and found this web sitehttps://bevyengine.org/which says “game engine”. I wonder is there another Bevy unrelated to games?> 3.84 GB/secondIn modern games none of that bandwidth is processed on CPU. Games use GPU for that, which don’t run Rust.> there's a weak claim that all performant data structures in Rust must use unsafe codeWeak claim? Look at the source code of data structures implemented by Rust standard library. You will find unsafe code everywhere. When you need custom data structures instead of merely using the standard ones you will have to do the same, because safe Rust is fundamentally limited in that regard.
> Look at the source code of data structures implemented by Rust standard library. You will find unsafe code everywhere.This is survivorship bias: one of the criteria back in the day for “should this go in the standard library” was “is it a data structure that uses a lot of unsafe?” because it was understood that the folks in the project would understand unsafe Rust better than your average Rust programmer. These days, that isn’t as true anymore, but back then, things were different.
> I don’t think animating 1000 things per frame gonna saturate a CPU core doing these computationsOh, my sweet summer child. :)> In modern games none of that bandwidth is processed on CPU. Games use GPU for that, which don’t run Rust.So is your claim that OP is making up stuff about running code on the CPU because its a 3D engine?Also, why mention megapixels if you think it's irrelevant?  :)> Weak claim?"_all_ performant data structures in Rust _must_ use unsafe code" is a long tail reading of the original comment. If that was the intent, it is a weak claim, because we can observemanymemory-safe languages and runtimes and have performant data structures. (minecraft was written in Java, years and years ago!)> Look at the source code of data structures implemented by Rust standard library.This is the bailey, which was directly covered in the previous comment.The motte was "all performant data structures in Rust must use unsafe code"Here, the bailey, steelmanning as strongly as possible, is "data structures with unsafe code are more performant than ones without", which was directly said in the comment you are replying to.In addition to the swapping, this is a picture-perfect replication of the bomber with holes on it meme, as the other reply notes.
> OP is making up stuff about running code on the CPU because its a 3D engine?I’m not sure CPU-evaluated animations are often critical performance bottlenecks of game engines.> why mention megapixels if you think it's irrelevant?Count of screen-space pixels is a hard upper limit of count of simultaneously visible things on the screen. Animating occluded meshes is pointless.> many memory-safe languages and runtimes and have performant data structuresIndeed, because people who designed these memory-safe languages wanted to support arbitrarily complicated data structures implemented using safe subset of these languages.Safe Rust supports arbitrarily complicated code, but requires unsafe to implement most non-trivial data structures.It’s possible to hide unsafe code deep inside standard library, possible to implement safe APIs over unsafe implementations, but still, for people who actually need to create custom data structures (as opposed to consuming libraries implemented by someone else) none of that is relevant.
Non-trivial data structures are often just a bunch of arrays/maps with additional semantics. You may consider implementing/using unchecked versions of basic operations for a little bit of additional performance. If you implement (de)serialization yourself, you may need unsafe code. Sometimes the safety of deserialization may be a convenient lie, if checking the invariants fully would be too expensive. And sometimes you may want to expose internal helper functions for various purposes, which may have to be marked unsafe if they can break the invariants.Beyond that, you only need unsafe code for specific kinds of data structures. At least in my experience.
> Non-trivial data structures are often just a bunch of arrays/maps with additional semanticsThis might be fine for code which consumes data structures implemented by other people. The approach is not good when you actually need to implement data structures in your program.In modern world this is especially bad for a low-level language (marketed as high performance, BTW) because the gap between memory latency and compute performance is now huge. You do need efficient data structures, which often implies developing custom ones for specific use cases. This is required to saturate CPU cores as opposed to stalling on RAM latency while chasing pointers, or on cache coherency protocol while incrementing/decrementing reference counters from multiple CPU cores.Interestingly, neither C++ nor C# has that boundary, for different reasons: C++ is completely unsafe, and safe C# supports almost all data structures (except really weird ones like XOR linked lists) because GC.
> You do need efficient data structures, which often implies developing custom ones for specific use cases.You are assuming you can't do this with those vecs/maps. But you can! That's what the "additional semantics" are.They will be slightly slower due to often using indexes instead of raw pointer, which requires a bound check and an addition to get the pointer, and sometimes a reallocation, but they won't bethatslow. Surely they will be faster than C#, which you claim can implement those same data structures efficiently. You also often get the benefit of better cache locality due to packing everything together, meaning it could even be faster.
> They will be slightly slower due to often using indexes instead of raw pointer, which requires a bound check and an addition to get the pointer, and sometimes a reallocation, but they won't be that slow.This is not a fundamental requirement, though. Assuming arena-like behavior, the index will be constructed/provided by the arena itself, so the bounds check can be safely ellided by-construction. Reallocation cost of the entire arena could be expensive, but if that is a cost you'd want to ammortize down to a new allocation, the arena could be implemented as an extensible list of non-growable arenas: every time an arena is full, you append another. This can be an issue if you don't keep track of deletions/tombstones or can't afford a compaction step to keep memory usage down, but in practice having all of these requirements at once is not as common.
I used to think like that. Then C++11 arrived, and I realized I could get effectively the same performance with containers and move semantics, while spending less effort on writing and debugging the code.If you need an array for your custom data structure, a standard library vector is almost always good enough. Associative arrays are a bit more tricky, but you should be able to find a handful of map implementations that cover most of your needs. And when you need a custom one, you can often implement it on top of the standard library vector.
> I could get effectively the same performance with containers and move semanticsWhen I’m happy with the level of performance delivered by idiomatic C++ and standard collections, I tend to avoid C++ all together because I also proficient with C# which is even faster to write and debug.But sometimes I want more performance. An example from my day job is a multi-step numerical simulation which needs to handle grids of 200M nodes. When processing that amount of data, standard collections are suboptimal. I’m not using std::vector because I don’t need them to grow and I want to allocate these huge buffers bypassing C heap i.e. page-aligned blocks of memory zero initialized by the OS.
I've been using std::vector with arrays that take up to tens of gigabytes for ~15 years without any real issues. Once the size of the allocation exceeds a few megabytes, any reasonable allocator is going to use an anonymous memory map anyway. And if the array doesn't need to grow, it takes effort to make a standard library vector worse than a manually optimized one. It's just a pointer and two integers, after all.
> it takes effort to make a standard library vector worse than a manually optimized oneA simple use case is a 2D array where rows are padded to be multiples of 32 bytes (size of AVX SIMD vectors, saves a lot of implementation complexity because no need to handle remainders) or 64 bytes (saves a tiny bit of performance when parallelizing, guarantees cache lines aren’t shared between rows).When element size is not a power of 2, it’s impossible to implement that RAM layout on top of an std::vector
It's obviously possible to find niche cases where the standard containers are not good enough. But the remaining 9999 cases out of 10000 are more interesting.I also had one of those, in an application that created and deleted a large number of fixed-size arrays across many threads. A naive implementation using glibc malloc ended up with a massive memory leak caused by hundreds/thousands of fragmented arenas. A thread could usually not reuse the memory it had just freed, because it was using a different arena. And because the arena was not empty, it was not possible to unmap the memory.
> proficient with C# which is even faster to write and debug.I don't get it - why are we ignoring the fact that C# necessarily implies distributing CLR? NativeAOT doesn't work for everything.
On AMD64 Windows, .NET 8.0 runtime takes 31.7 MB to download, and 70.7 MB on disk. On ARM64 Linux, the numbers are 28.4 MB and 75.0 MB, respectively.For that amount of data, both internet bandwidth and disk space are rather cheap these days?
As usual the typical argument that if it doesn't cover 100% of everything it isn't good enough.There are plenty of use cases where NativeAOT works perfectly fine, and is getting better with each .NET release.
> As usual the typical argument that if it doesn't cover 100% of everything it isn't good enough.This text> When I’m happy with the level of performance delivered by idiomatic C++ and standard collections, I tend to avoid C++ all together because I also proficient with C# which is even faster to write and debug.very strongly implies that they're completely interchangeable. They're not. It's as simple as that.Sometimes it's hard to keep track of whether I work in software or politics.
> very strongly implies that they're completely interchangeableNot completely but theyareinterchangeable. C# at its inception was as much inspired by C++ as it was by Java. Since then, it only further evolved to accommodate far more low-level scenarios and improve their performance.It provides the kind of capabilities you'd usually expect from C++, so this statement holds true. Calling C exports is one `static extern ...` method away, you can define explicit layout for structs (that satisfy 'unmanaged' constraint), you have fixed arrays in structs, stack buffers, pointers and ability to do raw or abstracted away manual memory management, etc. You can mmap device-shared memory and push data into GPU. You can accept pointers from C or C++ and wrap them into Span<T>s and pass those to most standard library methods.
> Not completely but they are interchangeable ... <whole lotta words telling me things i'm already extremely well aware of>I'll just ask you this extremely simple question: does C# compile/run/whatever-magic-you-think-it-does on targets that aren't in {x32, x86, ARM64}? Does it target RISC-V? Does it target PTX? Does it target AMDGPU? Are you getting the picture?Pre-empting the most low-brow dismissal: these are only niche targets if you've never heard of a company called NVIDIA.
> RISC-VThe work is underway:https://github.com/dotnet/runtime/pulls?q=label%3Aarch-riscv> Nvidia's PTX, AMDhttps://ilgpu.net/and evenhttps://github.com/m4rs-mt/ILGPU/blob/c3af8f368445d8e6443f36...While not PTX, there's also this project:https://github.com/Sergio0694/ComputeSharpwhich partially overlaps with what ILGPU offersArguably, even C++ itself - you are not using "full" C++ but a special subset that works on top of specific abstraction to compile to GPUs, and I was told that CUDA C++ is considered legacy.The original context of discussion is performance and perceived issue of "having runtime", which is what my reply is targeted at. In that context, C# provides you the tools and a solution other languages in the class of Java, Go, TS and anything else interpreted just don't have. So you could reasonably replace a project written in C++ that requires assurances provided by C++ with C#, and possibly re-apply all the freed-up developer productivity into further optimizations, but you wouldn't be able to do so with the same degree of confidence with most other originally high-level languages. Another upcoming contender is Swift.
> you are not using "full" C++ but a special subset that works on top of specific abstraction to compile to GPUsyou're wrong - GPU offloading is just window dressing (#defines and CMake) around the compiler itself, which supports almost all of C++; seehttps://libc.llvm.org/gpu/which builds libc (which is implemented using C++ in llvm) to amdgpu/ptx/etc.> C# provides you the tools and a solution other languages in the class of Java, Go, TSabsolutely no one in their right mind would compare these languages to C++> So you could reasonably replace a project written in C++ that requires assurances provided by C++ with C#i think people that don't write C++ professionally just don't understand where/how/why C++ is used :shrug:
Goverments of the world in their upcoming cybersecurity laws do.
> on targets that aren't in {x32, x86, ARM64}?I have personally shipped embedded Linux software running on 32 bit ARMv7 SoC written mostly in C#. The product is long in production and we’re happy with the outcome.> Does it target RISC-V?Not sure if it’s ready for production, but see that article:https://www.phoronix.com/news/Microsoft-dotNET-RISC-V> Does it target PTX?According to nVidia, the answer is yes:https://developer.nvidia.com/blog/hybridizer-csharp/> Does it target AMDGPU?Not sure, probably not.
> Not sure if it’s ready for production, but see that article:https://www.phoronix.com/news/Microsoft-dotNET-RISC-V> It's coming from a Samsung engineer, Dong-Heon Jung, who is involved with the .NET platform team and works on it as part of his role at Samsung.answer: no> According to nVidia, the answer is yes:https://developer.nvidia.com/blog/hybridizer-csharp/> Dec 13, 2017answer: no> Not sure, probably not.correct, the answer is no.again: this isn't politics, this is software, where the details actually matter.
> Dec 13, 2017OK, here’s a newer project which does about the same thing i.e. compiles C# to PTXhttps://ilgpu.net/BTW, it supports OpenCL backend in addition to CUDA.
>https://github.com/m4rs-mt/ILGPU/releases/tag/v1.5.1> Sept 2023.you guys just don't get it - there's a reason why CUDA is a dialect of C/C++ and not C# and it's not because the engineers at NVIDIA have just never heard of C#.
You are the one that doesn't get it, just like Intel and AMD creating CUDA clones that only focus on C and C++ APIs from CUDA, and not on CUDA the C, C++, Fortran, and PTX ecosystem.
Yes, NVidia has support for .NET on the CUDA ecosystem via partners, the only one that matters on GPGPU.Yes, Linaro is doing work for managed runtimes on RISC-V, although it remains questionable how much RISC-V matters outside nerd circles.
> Yes, NVidia has support for .NET on the CUDA ecosystem via partners, the only one that matters on GPGPU.Ironic because "via partners" is equivalent to "doesn't matter".
No my dear, it matters enough that in a freetards world, there are people willing to pay for such product.
The C++ Standard Library containers are very good and generic, and almost always the right tool to reach for. People are finally giving up on that notion that their own custom linked list is so much better than <list>. My estimate is that out of all the C++ programmers, 1% of them think that the C++ standard containers are not appropriate for their application, and only 1% of that 1% is right, due to their extremely specialized application needs.
>> I just do not see why people seem to use "unsafe" so much>Because it’s impossible to implement any non-trivial data structures in safe Rust. Even Vec has unsafe codeHmm.. wasn't memory safety the main selling point for rust? If not the only. Now mix of two languages looks even worst than one complex. Especially taking into account that it can be paired with safe language from long list. Don't know what rust fans are thinking, but from outside it doesn't look very attractive. Definitely not enough to make a switch. Julia looked better at first, but turned out to be just a graveyard of abandoned academic projects.
> Now mix of two languages looks even worst than one complex.The point is that the vast majority of codedoesn'thave to be unsafe. Empirically, Rust code has far fewer memory safety problems than non-memory-safe languages.
Memory safety without gc is not the only reason people use rust. It's also nicer to use than C++ for multiple reasons (language features, included package manager, easy to integrate tests...)
I use Qt, and I think if you have the Qt libraries then C++ is way better than rust. Most things are there instead of having to go and find a crate and then decide which one to use and hope it will remain maintained.
> Hmm.. wasn't memory safety the main selling point for rust?The vast majority of Rust programmers aren't spending their time re-implementing core data structures like Vec, so memory safety (and the fact that library authors can build safe abstractions on top of unsafe code, which is impossible in C or C++) still benefits them.
You fan wrap unsafe implementations with safe APIs. The point is there's an explicit boundary between unsafe an safe.
Nope it isn't. You just aren't experienced in system programming. Working with hardware is unsafe since it has state that one cannot completely encapsulate in a single program. The entire specific design of a chip isn't available to programmer; only the machine code is. We usually don't know how a processor decides to cache things or switch to kernel permission level. Usually this isn't even the level we're at, OSes have private internals that change behind the programs and they are not accessible from user space. Pressing Ctrl+C to interrupt changes so many things in memory, it would be outright impossible to write programs that handle every single thing.The fundamental / syntactic promise of Rust is providing mechanisms to handle and encapsulate unsafety such that it is possible to construct a set of libraries that handle the unsafety in designated places. Therefore the rest of the program can be mathematically proven to be safe. Only the unsafe parts can be unsafe.Coming from Java or Go or Js or Python angle wouldn't be the same. Those languages don't come with mechanisms to let you to make system calls directly or handle the precise memory structure of the data which is necessary when one is communicating with hardware or the OS or just wants to have an acceptable amount of performance.In C++, the compiler can literally remove your code if you sum or multiply integers wrong or assume the char is signed/unsigned. There is no designated syntax that limits the places possible memory overflow error happen. The design of the language is such that some most trivial oversight can break your program silently and significantly. It is too broad so it is not possible to create a safe and mathematically proven and performant subset with the C and C++ syntax. It is possible with Rust. It is like the difference of chips that didn't have a hardware mechanism to switch between user and kernel mode so everything was simply "all programs should behave well and no writes to other programs' memory pinky promise".Rust doesn't leave this just as a possibility. Its standard library is mostly safe and one can already write completely safe and useful utilities with the standard library. The purpose of the standard library is provide you ways to avoid unsafe as much as possible.Of course more hardware access or extremely efficient implementations would require unsafe. However again, only the unsafe parts can cause safety bugs. They are much easier to find and debug compared to C++. People write libraries for encapsulating unsafe so there are even less places that use unsafe. If people are out of their C++ habit, reaching for the big unsafe stick way too often, then they are using Rust wrong.Whatever you do, there will be always a need for people and software that enables a certain hardware mode, multiply matrices fast, allocates a part of display for rendering a window etc. We can encapsulate the  critical parts of those operations with unsafe and the rest of the business logic can be safe.
> Those languages don't come with mechanisms to let you to make system calls directly or handle the precise memory structure of the dataHere’s a C# library for Linux where I’m doing all these thingshttps://github.com/Const-me/Vrmac/blob/master/VrmacVideo/Rea...As you see from that readme, the performance is pretty good too.
> In C++, the compiler can literally remove your code if you sum or multiply integers wrong or assume the char is signed/unsigned. There is no designated syntax that limits the places possible memory overflow error happen. The design of the language is such that some most trivial oversight can break your program silently and significantly.Here is an interesting case of an optimization-triggered bug in Rust code I've heard of:https://www.youtube.com/watch?v=hBjQ3HqCfxs
> Those languages don't come with mechanisms to let you to make system calls directly or handle the precise memory structure of the dataEh? You can of course do all of that in python.https://docs.python.org/3/library/struct.html
> Because it’s impossible to implement any non-trivial data structures in safe RustThis is why I think rust is great for application programmers.
Honestly high performance web servers, games, anything in that realm it's pretty good for.Low level systems and high performance data structures are better implemented with direct memory management, but the consumers of those libraries shouldn't have that same burden (as much as possible).Granted, I haven't worked with rust enough to run into issues with other people's unsafe code.
> I'm about 50,000 lines of Rust into a metaverse client, and my own code has zero "unsafe". I'm not even calling "mem", or transmuting anything. Yet this has both networking and graphics, and goes fast. I just do not see why people seem to use "unsafe" so much.I agree. I rarely ever use unsafe, and only as a last resort. Unsafe code is really not needed to achieve high performance.> Rust does need a better way to do backlinks. You can do it with Rc, RefCell, and Weak, but it involves run-time borrow checks that should never fail.I think this will basically turn into provably-correct data structures. Which is possible to do, and I've long thought there should be systems built on top of Rust to allow for proving these correct. But we should be clear that something like Idris is what we're signing up for. Whatever it is, it is assuredly going to be far more complex than the borrow check. We should basically only use such systems for the implementations of core data structures.
> I think this will basically turn into provably-correct data structures.That's kind of what I'm thinking. The basic idea is to prove that .upgrade().unwrap() and .borrow() never panic. This isn't all that much harder than what the borrow checker does. If you have the rule that the return value from those functions must stay within the scope where they are created, then what has to be proven is that no two such scopes for the same RefCell overlap. Sometimes this will be easy; sometimes it will be hard. A reasonable first cut would be to check that no such scopes overlap for a specific type, anywhere. That's rather conservative. If you can prove that, you don't need the checking. So it's an optimization.
> My big problem with Rust is too much "unsafe" code.I hear cargo-geiger is useful identifying such crates.> I just do not see why people seem to use "unsafe" so much.Because it's:A) fast (branchless access)B) fast (calling C libs or assembly)C) fast (SIMD)D) people think unsafe Rust is easierWant to write a JSON parser that will gobble up gigabytes per second? Your only way is removing as many branches and use assembly as much as possible. Doubly so on stable! I guess the same goes for making a "blazingly fast"™ graphical stack.People that think unsafe is easier, shouldn't be writing unsafe code. Writing unsafe code correctly is like juggling burning chainsaws. Saying that's easier than using chainsaws  is moronic at best.EDIT: Consider following, if each of your unsafe {} blocks doesn't contain a// SAFETY:
    // Detailed explanation of invariantsOne of the chainsaws just cut off your leg.
>people think unsafe Rust is easierIf that's their line of thought, I don't know why they simply don't use C/++. Or even C# with unsafe blocks. I know you said the same, but I wanted to reiterate that.But yes, I can see a few very specific cases where unsafe access is needed. Emphasis on "few". I think anything past some fundamentals should be at best a late optimizing step after an MVP is established.I also think, if it's not already there, that crates should be able to identify if it's "safe" or "unsafe". Same mentality where I'd probably want to rely on safe crates until I need to optimize a sector and then look into blazing fast but unsafe crates.
> Rust does need a better way to do backlinks. You can do it with Rc, RefCell, and Weak, but it involves run-time borrow checks that should never fail. Those should be checked at compile time.It's not clear to me how rustc could detect a dangling backlink in a tree structure at compile time. Seems impossible short of adding proofs to the type system.
If the language actually supported a full set of memory policies it would be quite possible.Unfortunately it only thinks about are unique, an opinionated form of borrowed ownership, and a little bit about shared (weak I think is punted entirely to the library?), and not all other ownership policies can effectively be implemented on top of them.The usual thing approach would be:given two types, P and C (which may be the same type in case of homogeneous trees, but this), with at least the following fields:

  class P:
    child1: ChildPointer[C]
  class C:
    parent: ParentPointer[P]Then `p.child1 = c` will transparently be transformed into something like:p.child1?.parent = null
  c?.parent?.child1 = null # only needed if splice-to-steal is permitted; may need iteration if multiple children
  p.child1 = c
  p.child1?.parent = pNote that ChildPointer might be come in unique-like or shared-like implementations. ParentPointer[T] is basically Optional[UnopinionatedlyBorrowed[T]].A have a list of several other ownership policies that people actuallywant:https://gist.github.com/o11c/dee52f11428b3d70914c4ed5652d43f...
Is there some research that shows these are actually safe and can be reasonably checked by a compiler?
I don't use Rust and I've bounced off trying to learn it 3 times so far, so take this with a mountain of salt, but...I think that Rust having unsafe is fine as there will be edge cases where the compiler can't quite work out whether some code will work fine or not and where the programmer can vouch for it. That's no problem.The issue I have with it is that the unsafe block then gets kinda swallowed by the supposedly safe wrappers around it. And there's no clear auditable trail back to it. I find that a bit surprising as I'd expect it obvious to have some kind of 'uses unsafe' declaration (annotation? I don't know what Rust calls those statements with a number sign and square brackets in front of a subroutine) which would then propagate upwards. A bit like how in Java (the most elegant and refined of all programming languages) you can use an annotation to state that a function 'throws XYZException' which then needs to be propagated up to a point where it can get handled.Not having such a mechanism feels a bit icky to me. It's like if there's spiders crawling out of your ears it's useful to know that they're coming out of your ears so you don't have to wonder 'are those spiders creeping out of my ears? Or out of my nose? Or out of my eyelids?', which would be a bit inconvenient.
This annotation would be useless, because it would infect ~99% of your codebase. All IO is implemented as unsafe FFI calls or unsafe inline assembly somewhere down the stack. And even "pure" types like Box, Option, Vec have a lot of unsafe in their implementations. At some point these standard implementations just have to talk to an allocator which is implemented unsafely (obviously), or they have to construct a slice [1], etc. Would you make an exception for the standard library and why? I think, this just doesn't make sense. It's all unsafe somewhere down the stack.[1]https://doc.rust-lang.org/std/slice/fn.from_raw_parts.html
> I just do not see why people seem to use "unsafe" so much.SIMD seems to be a big one.
If you're doing graphics then you will have to use `unsafe` to interface with the OS primitives, there's no other way.Backlinks would be "nice" but they break fundamental assumptions that the borrow checker does.> Detecting a double borrow is the same problem as detecting a double lock of a mutex by one thread, which is being worked on.Is it being worked on using heuristics or formal methods?
I’ve been using Rust almost daily since 2015 and I’ve used unsafe twice - both when interoping with C.I don’t know what fancy things you’re doing with unsafe that you’re seeing it on a daily basis… maybe it’s a you problem
It is explicitly mentioned that ubsafe is in their dependencies not their own code.
No. Nobody is going read those (because most people won't even know that some unsafe is buried 5 layers of dependencies below what they work with). The author should make reasonable effort to prove the code is working correctly (and cannot be abused) by other means if possible. It might be a domain issue, so far all my apps are 100% safe (not counting libraries).
You put those safety comments in two places: when you declare an API as being unsafe, and when you use an unsafe API. Not coincidentally, those are the two places in the language that force you to use the “unsafe” keyword. If you declare a safe API that uses unsafe under the hood, it’s on you to ensure that it’s safe to call under any situation, so that callers can call it without worrying that their program is suddenly unsafe. If you can’t guarantee that your API is safe under all circumstances, you need to declare it unsafe and make it the caller’s job to use it safely.
Unsoundness is considered a bug and should be reported and fixed.
Needs (2023)> I predict that tracing garbage collectors will become popular in Rust eventually.The use of Rc is already very widespread in projects when people don't want to deal with the borrow checker and only want to use the ML-like features of Rust (Sum types, Option, Error etc.)> Rust has arrived at the complexity of Haskell and C++, each year requiring more knowledge to keep up with the latest and greatest.I wonder when we will see the rise of Haskell like LanguageExtensions in Rust. AFAIK, pretty much everybody uses things like GADT, PolyKinds, OverloadedStrings etc. The most similar thing I can think of Rust right now for is python-like decorator application of things like builder macros using Bon.> Async is highly problematicAgreed. Tokyo is the only reason, I think, anybody is able to use Rust for this stuff.
Does Rc really resolve the core problem this post is talking about, which is that it's really painful to naturally express tree and graph structures in Rust? It feels like I mostly see people talking about building application-layer pointer systems with integers, which would be surprising if (in a single thread, perhaps) you could just Rc your way around the problem.
> Does Rc really resolve the core problem this post is talking about, which is that it's really painful to naturally express tree and graph structures in RustNo, it doesn't. If you naively express graphs containing cycles with `Rc` you will leak memory, just like you would with `std::shared_ptr` in C++.
> Does Rc really resolve the core problem this post is talking about, which is that it's really painful to naturally express tree and graph structures in Rust?No, but Gc will not resolve the core problem either. The core problem is that rust forbids two mutable pointers into one chunk of memory. If your tree needs backlinks from child nodes to parents, then you are out of luck.
In what way am I "out of luck"? It's trivial to express a tree, including one with backlinks, in Java.
Rust's mutability rules specifically screw you over here (you can't have two mutable references to the same object, ever); most languages (including Java) don't have those rules.I sometimes wish I could have a mode of Rust where I had to satisfy the lifetime rules but not the at-most-one-mutable-reference-to-an-object rule.
Java doesn't enforce the rule "mutable XOR shared". But if you have a link "child" in the parent node, and a link "parent" in the child node, then parent.child.parent == parent, and compiler cannot know it.So Rust as the language makes it impossible to do with &-pointers, while standard library of Rust allows it to do with combination of Option, Rc, RefCell but it is really ugly (people above says it is impossible, but I believe it is just ugly in all ways). Like this:type NodeRef = Rc<RefCell<NodeInner>>;struct Node {
    parent: Option<NodeRef>,
    left: Option<NodeRef>,
    right: Option<NodeRef>
}So the real type of `parent` field is Option<Rc<RefCell<NodeInner>>>. I hate it when it comes to that. But the ugliness is not the only issue. Now any attempt to access parent or child node will go through 2 runtime checks: Option need to check that there is Some reference or just None, and RefCell needs to check that the invariant mut^shared will not be broken. And all this checks must be handled, so your code will probably have a lot of unwraps or ? which worsens the ugliness problem.And yeah, with Rc you need to watch for memory leaks. You need to break all cycles before you allow destructors to run.If I need to write a tree in rust, I'll use raw-pointers and unsafe, and let allergic to unsafe rustaceans say what they like, I just don't care.
I simple standard mark-and-sweep GC will not "leak it".
This has been a solved problem for decades.
Considering that there exists a book about building linked lists in Rust[0], I am going to go ahead and say "Unclear" That does not matter though. It is easier (though verbose and often unidiomatic), and hence Rc has become really popular, especially with beginners.[0]https://rust-unofficial.github.io/too-many-lists/
Rc does solve the problem, but it often introduces interior mutability, which ends up causing usability problems. That's why at the end of the day adjacency representations (i.e. integers) are often preferred.
Sure, Rc/Arc absolutely solves this problem. It's not super idiomatic to go crazy with using it like that, but it's possible/acceptable.Using SlotMap and integer ids, etc. doesn't I think offer any advantage.
I feel pretty comfortable with Rc and Arc, read the "too many lists" book, &c. and feel like it is not actually simple to model trees with Rc? What am I missing? I'd love to be convinced I'm wrong about this (I want to like Rust more than I do).
A tree of Rc/Arc<T> is a tree of references, and is really no different than a Java or Python reference value, except that you'll have to do explicit .clone()sIs it mutability that's tripping you up? Because that's the only gotcha I can think of. Yes, you won't get mutability of the content of those references unless you stick a RefCell or a Mutex inside them.
Yes! Mutability is what's tripping me up! That is not a minor detail!
You can get something like what you're used to a "traditional" language without compiler safeguards by using RefCell and .borrow_mut() on it. That will let you get past the compile-time borrow checks but will do runtime borrow checking and throw panic if more than one borrow happens at runtime.It's verbose, but it's explicit, at least.So:struct Node {
    parent: Rc<RefCell<Node>>,
    left: Option<Rc<RefCell<Node>>>,
    right Option<Rc<RefCell<Node>>>,
  }and just off the top of my head it'd be something like{
    let my_parent = my_node.parent.borrow_mut();
    ... do stuff with my_parent ...
  }
  ... my_parent drops out of scope here, now others can borrow ...etc.Haven't tried this in compiler my memory might not be right here.
I do know that it's possible, but when people complain about this --- as with this tweet, from a PL theorist:https://x.com/LParreaux/status/1839706950688555086... this is what they're talking about.(I know the tweet is about the "idiomatic" answer to this problem, which is to replace references with indices into flat data structures).
Doesn't SlotMap save RAM and pointer dereferences?
What is a slotmap lookup... if not a pointer dereference, or at least a dereference out of a vector likely on heap... so probably a pointer...?
> The use of Rc is already very widespread in projects when people don't want to deal with the borrow checker and only want to use the ML-like features of Rust (Sum types, Option, Error etc.)And the fact that this hasn't caused alarm is kind of an issue.The problem with that is Reference Counting isWAYslower than good Garbage Collectors on modern CPUs.  Reference Counting breaks locality, hammers caches and is every bit as non-deterministic as a garbage collector.
> Agreed. Tokyo is the only reason, I think, anybody is able to use Rust for this stuff.A lot of problems related to Tokyo can be avoided if you think your code as structured concurrency and avoid using Tokio::spawn. However, too often this is not possible.
I haven't, yet, run into building rust apps that require highly complex async implementations with lifetimes etc. however excluding those situations I've found it very straightforward and easy to use. I've built some applications with a lot of moving parts, mpsc has always been a life saver.
I don't have too much experience with async, but I have noticed a similar pattern. Maybe you are right.
"X is as complex as C++" is a preposterous statement for all values of X.A lot of people seem to assume that "C++ is complex" is referring to how the committee adds new language features every 3 years. The conventional wisdom that C++ is wickedly difficult to learn is NOT about "oh man, now I need to learn about the spaceship operator?" C++ is an almost unfathomably bottomless pit. From the arcane template metaprogramming system to the sprawling byzantine rules that govern what members a compiler auto-generates for you, and on to the insane mapping between "what this keyword was originally introduced for" and "what it actually means here in _this_ context, there is no end to it. Keeping up with new language syntax features is an absolute drop in the bucket compared to the inherent complexity required to understand a C++11 codebase, build it (with a completely separate tool that you must choose) and manage its dependencies (with a yet different completely separate tool that you must choose).You don't have to know anything about Rust to know that saying "Rust has become complex as C++" is objectively incorrect.
Depends, how much from unstable Rust ends up in Rust during the next 30 years, to match where C++ is today after 40 years of production deployments across the industry.
Yeah, but in 12 years when reflection is in the language and is widely used, people will probably have to deal with a significantly increased amount of weirdness as a result of that feature. Though all that's to say the complexity gap between rust and C++ is only going to go up.
> Distinguishing mutability has its advantagesI think it's misleading to say that Rust distinguishes mutability. It distinguishes _exclusivity_. If you hold a reference to something, you are guaranteed that nothing else holds an exclusive reference to it (which is spelled &mut). You are _not_ guaranteed that nothing accessible through that reference can change (for example, it might contain a RefCell or other interior-mutable type). Shared references (spelled &) usually imply immutability, but not always. On the other hand, if you hold an exclusive reference to something, you are guaranteed that nothing, anywhere, holds any kind of reference to it.IMO, the fact that exclusive references are spelled "&mut", and often colloquially called "mutable references", was a pedagogical mistake that we're unfortunately now stuck with.
>IMO, the fact that exclusive references are spelled "&mut", and often colloquially called "mutable references", was a pedagogical mistake that we're unfortunately now stuck with.You couldn't just roll out a change like alias &e to &mut and &s to &, and then have a compiler warning for using the old &mut or &?
That’s technically possible, yes, but I really doubt there is any appetite to change basic syntax like that when it’s already so ingrained in everyone’s mind.
> People waste time on trivialities that will never make a difference.This is an aha moment as I read it. The complexity of your tools must be paid back by the value they give to the business you’re in.
This is daft logic. Your business itself has no value in the modern world. Your todo saas app is not needed. Of course this argument is faulty, so going one step back, what is valuable is in the eyes of the hacker. For a lot of people, including mine, the triviality is also part of the value chain.
Really depends on the "difference". If a male a container crate that is Fer from shippable but gives me knowledge to land a Rust gig, was it a triviality?
> People waste time on trivialities that will never make a difference.Depending on the situation, memory layout could be trivial (copying 200 bytes once at startup vs. not in a way that should never be user-perceptible and difficult to even measure) or actually a big deal (chasing down pointers upon pointers in a tight inner loop). It's entirely situational. To dismiss all of that as "trivial" and saying it will "never" make a difference is not helpful. There are a lot of shitty apps that are impossible to get running reasonably without a total rewrite and their shitty use of memory is part of that.
Criticising a systems programming language for needing to manually manage memory is honestly embarrassing.
I mean to be fair so is using a systems programming language for every use case under the sun. If Rust is a great systems programming language that’s one thing. If it’s a general purpose language that’s another.
A lot of git(1) subcommands were originally written in shell or Perl. Now most are written in C.Through many decades people wrote utilities and applications in C. Not hardcore lower-level kernel modules. Just utilities and applications. Because that’s what they wanted to write them in. Over Perl or Java or whatever else the alternatives were.What’s more C than that? Writing everything short of scripts in it?Now people write applications in a modern programming language with modern affordances. They might be working uphill to a degree but they could have chosen much less ergonomic options.The embarrassing part is criticizing people who have put in the work, not on the merits of their work, but on… having put in too much work.
The two are not mutually exclusive. Also, I don't think I have ever needed to actively think about memory management more than .clone() and static for any hobby project I have undertaken. All the ML-like features like sum types, pattern matching etc. add great value. Cargo too. So, it is a great general purpose programming language. But blaming it as too low-level or similar despite choosing it is obtuse at best.
The subtext is that most of the time it won't make a difference, and Rust demands that you consider it every of the time. That squares with my experience. The powerful argument Rust has is that in the hotspots where memory lifecycle and layout make a huge difference to programs, it's much easier to express the fast and predictable memory arrangement than in GC'd languages.
Thinking like that is how we get 12MB of javascript to read a news article, or mobile apps that are jankier than Word 97.I don't get how someone can criticise a systems programming language by saying "I have to think about memory layout"....
There's a response to your comment in the post:> I feel like Rust is self-defined as a “systems” language, but it’s being used to write web apps and command-line tools and all sorts of things.> This is a little disappointing, but also predictable: the more successful your language, the more people will use your language for things it wasn’t intended for.> This post still offends many who have tied Rust to their identity, but that’s their problem, not mine.
I think maybe the GP's point is that weshoulduse systems languages, with their focus on efficiency, for things that the OP defines as out of scope, as an antidote to the creeping software bloat that we all like to complain about from time to time.And let's not forget that Word 97 feltbloatedin its day, however fondly we may look back on it now.
I actually used to agree that Rust generally wasn't good for high-level application code, but working with Bevy has made me change that opinion for certain domains. I simply haven't seen a system that makes automatically parallelizing all application logic (game logic, in this case) feasible, other than Bevy and other Rust-based systems. The trick is that the borrow check gives the scheduler enough information to automatically safely determine which systems can run in parallel, and that's very powerful. It's not that youcouldn'tdo this in C# or whatever--it's that youwon'twithout a system that helps express your intent and enforces that those declarations are up to date.For applications that don't need high performance for the CPU codeandaren't systems code, sure, Rust may not be a good choice. I'm not writing the server-side code for low traffic Web sites in Rust either.
Just so we're clear, your reference points for "good for high-level application code" are systems code and game engines? :)
Games themselves, not game engines. Systems code, game engines, and games.This isn't meant to be an exhaustive list--it's just the domains I have experience with that Rust was a good fit for. Lest it seem like I'm saying Rust is a good fit for everything I've done, I also worked on Firefox where the UI was JavaScript, and I wouldn't hurry to rewrite that code in Rust. Nor would I want the throwaway stuff I write in Python or Ruby to be Rust.
I'm just saying, games areexactlyone of the things I would assume Rust would be a natural fit for. :)
>Rust would be a natural fit forDid you leave out a "not" here?
No, I don't think so? I would have predicted games as a sweet spot for Rust. Most significant game projects are done in C++, and I look at Rust as basically obsoleting C++.
OK. Thanks.My guess was that since almost no one will pay more for a game's having fewer security vulns, there is less benefit to incurring the expense of Rust (takes longer to learn, development speed is slightly less)
Its not just vulnerabilities. In theory you should also get more stability.For example I like to play Civ with a friend, but stopped because about once every 30 minutes one of us would have their game crash. If it was written in Rust, I assume it might be more stable.
Thanks. Another consideration that favors Rust, at least for gameengines, ishttps://news.ycombinator.com/item?id=41793725
When we talk about Rust being a reasonable choice for things like (say) a CRUD app, memory safety is already table stakes; every mainstream high-level language is memory-safe. Why would youeverpick Rust over Java? The answer to that question will be an even better answer to why you'd write a game in Rust.
Java may be memory safe but it is not data race safe (unlike Rust, the compiler does not enforce cross-thread synchronization). So there is still a safety-related reason to use Rust over Java.That said, I don't really think Rust is a good choice for CRUD apps, because development velocity is more important than performance and they probably don't need to be multithreaded anyway.But Rust would have been great for a lot of "systems" stuff that was historically written in Java, like Flink or Hadoop for example.
I feel like I've had this debate many, many times, and it always ends in the same place: I'm willing to concede that there are a subset of correctness/reliability bugs that Rust's error handling and type system mitigate, but not that any of those bugs are material to security, which is what most people are talking about when the discussion turns to memory safety. And, of course, Rust admits concurrency bugs too! We just ran into a huge one.
I didn’t think we were having a debate. You insinuated that Rust isn’t ideal for CRUD apps, and I agreed with you.
"Debate" was too confrontational a word, sorry about that.
Rust's value proposition has nothing to do with security vulnerabilities, except that security vulnerabilities are a type of bug.The point of Rust is to be a language that competes in the same niche as C++ but makes it much more difficult to write large classes of bug, much broader than just "security vulns".
It's funny when people mention Go as the gold standard of not adding features to the language and Rust as ever-changing when Rust hasn't introduced any major changes in at least 3-4 years and Go introduced a major paradigm shift in how people structure their code (generics).Before you start replying with "Rust introduced X" - ask yourself - is X extending an existing feature slightly or does it introduce an entirely new concept?
Generics is hardly a major paradigm shift, and these two languages are worlds apart in amount of features.
That's not the point, though. The author says:> Rust has arrived at the complexity of Haskell and C++, each year requiring more knowledge to keep up with the latest and greatest. Go was designed as the antidote to this kind of endlessly increasing language surface area.Yes, Rust learning curve is much steeper and the "language surface area" is big, but it's not changing much in recent years. Go getting generics is much bigger change than anything that Rust got in a long while.
I think the author rather refers to "tamagotchi tooling" and constant adapting libraries to new trends. It was not that much about language changes per se
I guess it depends on what libraries you're using, but honestly a lot of very popular libraries are at 1.x and hardly change. Honestly I'm not sure where people are getting these experiences from. I feel like either they make it up or they talk about experiences from 2017 or sth. Or maybe they are very unlucky when choosing dependencies?
Ya the article is a bit fluffy and insubstantial. Surprising it's been voted up so highly on HN. Are people just going off the title?
I learned to program around the peak of object oriented fetishization. Shortly after that came functional programming's moment, and now it seems we are slightly past Rust and other safety focused languages' peak period of hype. All three language families have useful things to offer, but were never the panacea their proponents claimed them to be. "No Silver Bullet" continues to be true.
Related:My negative views on Rust-https://news.ycombinator.com/item?id=29659056- Dec 2021 (89 comments)
I think to some extent Rust is a victim of its own unreasonable effectiveness. It is great at its narrow niche of memory safe low level programming, but frankly pretty good at lots of other things. But at these other applications some of its design principles get in the way - like the pedantic borrow checker. Languages not used outside their niches don't tend to collect such criticism.Python is a bit like that. It is a top choice for a few things, and ends up used effectively for other things, simply because it is versatile. But then people run into issues with dynamic typing, zero static safety, start slapping type annotations everywhere... and bemoan Python as a bit of a horror show.My use case for Rust is complementing Python, where frankly I don't care about half the complex features, still it's nicer than C or C++ to code in. The complexities of the borrow checker are more like a tax to me. I understand people who are frustrated with it thought, as otherwise they see it as a bit of a perfect language.
People keep talking about the borrow checker. I have written over 70k lines in Rust so far and it hasn't really been that big of an issue. There are large-ish projects like Zed and Zellij in Rust which seem to be pretty straightforward code as well. I feel it's a bit overblown the whole borrow checker issue.
I think Python is entirely different and a perfect exemple of why popularity trumps quality. I can’t think of any domains where Python would be the better choice. It’s actually pretty bad all things being considered but well the ecosystem is okay and plenty of people know it so why not. JS is another great exemple of that.
I think in general python gets used because of laziness and vitality.  It's just the dumb shit that X person learned first because Y person before then was taught it because it was easy even though it's maybe not even the right choice for example, you can't properly write aworking webserverin python without {venv, uvicorn, celery etc.} and if youve ever worked in another language its like why the hell is this shit here?  Because it's viral, someone didn't know better, and it stuck.Same goes for machine learning.  The ML folks at the start couldn't be bothered to learn something the least bit sophisticated.  Some things are getting better.  You don't need conda anymore, tensorflow wheels are out, and at least instead of shippong around .pt, checkpoint, or pickle files at least we use safetensors, but there's still python shit around, like jinja2 templates for conversations, etc.Anyways if we want good things we need to get better about getting unstuck from these local minima.
I disagree re Python. It is a brilliant, flexible scripting language. It is easy to build expressive libraries such as pytest or argparse, with deep introspection. It is easy to prototype by subtly changing return types, or even keeping them flexible. It is really easy to eg build a custom data type and build custom expression trees, such as what ML often needs.It has a number of features (often stemming from the above) that make it a PITA for other applications, even when it would be fairly well suited to them otherwise. What I would give for proper static typing for production Python! Alas, that's not coming, and Rust's occasionally mind boggling borrow checker is there to stay.
If you feel that way about python, it's really just likely you haven't tried anything else better.And anyways you probably shouldn't be serving a website with a scripting language (php and perl are great examples of why not).   You probably shouldn't be deploying ml with a scripting language (maybetraining is fine,ifyou're not doing distributed training).  You probably shouldn't have too many core os components in a scripting language lookin at you Ubuntu, you probably shouldn't write a cloud (openstack) using a scripting language. What happened to "right tool for the right job".
I don't think you're getting my point. It's a good scripting language - there may better ones, that's besides my point. And your heuristic is terribly wrong, I have used many languages, scripting and otherwise.My point is, it's great at its niche and good but kind of clunky at other things it ends up used for. At its off-niche applications, it attracts a lot of criticism - like you talking about how it's a bad idea to serve a webpage from a scripting language or productionise ML models.No one complains that C++ is clunky at, dunno, serving websites, simply because it is so ill suited for it that no one ever tries. But Rust is less obviously a bad choice. Still that attracts people who find it clunky when they "just" want to serve a webpage and don't want to deal with the vagaries of borrow checker.
I like Rust but at the same time I agree with the points here. These things are indeed problems with Rust.Nevertheless, C++ has even worse problems. When your alternative is using C++, that's the time to consider Rust.
Still a non starter in many industries, other than for those that enjoy building ecosystems from scratch.
Who uses panic instead of `?` and anyhow / Box<dyn Error> (error propagation?)I think there is even a (gross) way to achieve try/catch around a block of code that panics?
Yeah, panic/assert is only for Things That Really Shouldn’t Ever Fail, If They Do Our Base Assumptions Have Broken.whereas Error is for things that are unlikely to fail, like network/filesystem requests and recoverable logic bugs.
Some points resonate with me:> People don't want "to have to play Chess against the compiler"Things that are easy to express in other languages become very hard in Rust due to the languages constraints on ownership, async...> Rust has arrived at the complexity of Haskell and C++, each year requiring more knowledge to keep up with the latest and greatest.It's indeed hard to keep up.> Async is highly problematic.Yes, more complexity, more fragmentation and feel like another language.But one point feels unfair:> the excellent tooling and dev team for Rust [..] pulls the wool over people’s eyes and convinces them that this is a good language that is simple and worth investing in.What? No. The main appeal was the safety. It's still a distinctive feature of Rust.
To almost eliminate a whole class of safety issues. It has been proven by several lengthy reports such ashttps://security.googleblog.com/2024/09/eliminating-memory-s....They are many projects for which the reliability and efficiency are worth the trouble.
i could buy an alphabet soup, add in some cereals, mix it up and throw it on the table, knowing it would end up looking indistinguishable from rust code.
I agree with a couple points here, specifically I agree that choosing a language based on it's community (and not it's ecosystem) is just silly. And we all know that async ended up being a bit of a thorn in rust's side.But yeah, rust is very much a systems language: so it will be forcing you to think about memory layout one way or the other. Idk how valid of a complaint that is when you really consider that, and specifically the other alternatives you have.
A complication of the "Rust is a systems programming language" thing is that people adopt definitions of "systems" of varying expansiveness to suit the situation. There are unquestionable systems programming domains --- the kernel is a great example, and one where it's easy to see why Rust is an exciting proposition; same with browsers, the "second OS" everyone runs --- and then more questionable domains. Is the framework-layer code for a CRUD web application "systems" code? How about a container orchestrator?This isn't a criticism of Rust, but rather of the framing we often use to compare Rust and (say) Python or Java.
Rust makes you think about your memory layout, memory allocation and avoiding thereof, about the specific time you grab and release other resources, about specifics of your inter-thread interactions, etc.If such considerations are natural for your problem domain, you likely do "systems programming" and also happen know C, have an.opinion on Zig, etc.If such considerations are the noise which you wish your language would abstract away, then you likely do "application programming", and you can pick from a wide gamut of languages, from Ruby and Python to Typescript to Elixir and Pony to C#, Java, and Kotlin to OCaml and Haskell. You can be utterly productive with  each.
What does "think about your memory layout" mean? Can you provide an example? I've seen this brought up a few times on this thread and have no idea what people are referring to when they say it.As for the rest of your list - I'm not sure why rust is special in regards to "the specific time you grab and release resources" or "inter-thread interactions". Seriously - I have to think about when I acquire and release resources like sockets and file handles python, c, ocaml, java, c#, and every other language I've used. Its not like you can randomly call file.close() or close(fd) (in python and c respectively) and expect to be able to continue reading or writing the file later. Same for inter-thread interactions... all those languages have mutexes too. Like none of that is rust-specific, its just the consequence of using resources and threads in code.
>What does "think about your memory layout" mean?Here are some of the typical concerns:- How exactly fields of a record sit in memory, how much room do hey take, taking into account things like padding for aligned access?- Are related data sit next to each other, and can stay in the CPU cache together while needed?- Are chaotic memory accesses thrashing the cache?- Do the data structures avoid gratuitous references / pointer chasing (at least mostly)?- Are local variables mostly allocated on the stack?- Does your code avoid heap allocations where possible?- Do fields in your data structure match a binary format, such as of an IP packet, or a memory-mapped register?- Are your sensitive data protected from paging out to disk if free RAM is exhausted?If these questions are not even relevant for your problem domain, you likely are not doing systems programming.
Again, the subtext here is GC versus direct control of memory lifecycles, and it is probablynotreasonable to argue that there isn't a tradeoff here --- that every application is as gracefully expressible in one as the other, so long as you "git gud" at it. Both sides of this debate are guilty of deploying that trope.
I'm not arguing that there isn't a tradeoff, or about "git gud". I'm literally and genuinely baffled about how one can magically elide knowing if a file is open or closed (or the equivalent) when using a resource. Like I can't think of a single language that doesn't make you explicitly obtain resources, and most of the GC languages do the same thing as rust for casual closing - just let the handle go out of scope.Even for memory, a huge amount of the rust I write isn't performance code - I don't understand why it's a mental burden to writelet x = vec![a, b, c];When the equivalent in python is:x = [a, b, c]Nothing about either requires a lick of memory allocation thought, nor about memory layout. Sure in rust I have to think about what I'm going to do with that vec in rust and the mutation story up-front, but after enough lines of python I have also learned to think of that up front there too (ortherwise I know I'm going to be chasing down how I ended up mutating a copy of the list rather than the original list I wanted to mutate - usually because someone did list = $list_comprehension somewhere in the call stack before mutating).I'm not being disingenuous here - I literally don't understand the difference, it feels like an oddly targetted complaint about things that are just what computer languages do. To the best of my ability to determine the biggest differences between the languages aren't about what's simple and complex, but how the problems with the complex things express themselves. I mean it's not like getting a recursion limit error in python on a line that merely does "temp = some_object.foo" is straight-forward to deal with, or the problems with "for _, x := range foo { func() { stuff with x } }" are easy to understand/learn to work with - but I don't see people running around saying you shouldn't learn those languages because there's a bunch of hidden stupid crap to wrap your head around to be effective. (and yes, i did run into both those problems in my first week of using the languages)In all the languages there are wierd idioms and rules - some of them you get used to and  some of them you structure your program around. Sometimes you learn to love it, and sometimes it annoys you to no end. In every case I've ever found it's either learn to work with the language or sign up for a world of pain, but if you choose the former everything gets easier. When a language makes something seem hard, but it seems easy in my favorite language, well, in that case I've discovered the complexity is there in both, but when it's hidden from me it limited my ability to see a vast array of options to explore and shown a whole new set of problem solving tools at my disposal.I still don't know what people mean when they talk about "having to think about memory layout"... like seriously to me it's: Thinking about pointer alignment and how to cast one struct into another in C... something I've only had to think about once in any language across a fairly wide range of tasks. If this is what's being referred to, I'm baffled about how it's coming up so much, but i suspect this isn't what people mean, and I don't know what they actually do mean.
> I still don't know what people mean when they talk about "having to think about memory layout"The best example I'd give is the degree to which you have to ask yourself if you want to use String or if you want to use &str--is this struct, or this function, going to own the string or borrow it from somebody else? If you're borrowing it, who is owning it? Can you actually make that work (this isreallysalient for parser designs)?Essentially in Rust, before you can really start on a large project, you have to sit down and plan out how the memory ownership is going to go, and this design work doesn't really exist in most other languages. Note that it's not inherently a good thing or a bad thing, but it is a potential source of friction (especially for small projects or exploratory tools where memory ownership might want to evolve as you figure out what needs to happen).
> the degree to which you have to ask yourself if you want to use String or if you want to use &strIn practice, there isn’t a ton of thinking to do about this: if it’s a struct, you want String. If it’s a function parameter, you want &str, and if it’s a function’s return type, you want String. Doing that until you have a reason not to is the right call 95% of the time, and 4% of that last 5% is “if the return type is derived from an argument and isn’t changed by the body, return &str.It does take some time when you’re learning, but once you get over the hump, you just don’t actively think about this stuff very much. Google’s research says Rust is roughly as productive as any other language there, so far. That doesn’t mean it’s universally true, but it’s also some evidence it’s not universally false.
> Google’s research says Rust is roughly as productive as any other language there, so far. That doesn’t mean it’s universally true, but it’s also some evidence it’s not universally false.You shouldn't call this evidence but instead marketing. It was thoroughly debunked for the nonsense that it was in many places such as this:https://www.youtube.com/watch?v=vB3ACXSesGo
If you write Rust like this (insisting that structs always fulfill 'static) you will end up unnecessarily cloning memory way more than you would in a GC'ed language.In GCed languages strings get allocated once when you need them, get referred to wherever you want, however many times you want (with no new calls to the allocation subsystem), and are freed once when you don't need them anymore, with minimal thought or intervention on the programmers part. Rust is absolutely not like this at all.I agree with the overall idea that people exaggerate the difficulty of Rust, but come on, this is an exaggeration way too far in the other direction.
That’s why it’s “until proven otherwise.” As you gain experience you can be more subtle about it, and you gain more intuition, but it’s just not that big a deal until you demonstrate it’s a big deal.I rarely type clone(). Even with this advice, you won’t clone super often. And when you do, it’s a signal sometimes that maybe you can do better, but it’s just not a big cognative burden.
Wading in here a little bit, and I know you've thought about this --- I think it's reasonable to say that there are problem domains where it's a very good thing, and problem domains where it isn't.I think a subtextual problem for Rust advocacy is that the places where it's aclearwin are a small subset of all software problems, and that space is shrinking. Rust would, in that view of the world, be a victim of its success: it's the best replacement we have for C/C++ today, but the industry has moved sharply away from solving problems that way, and sharply towards solving them with Javascript.(Deno is doing something smart here.)
The way memory allocation and management becomes part of the paradigm of how we write and structure programs, is actually something I really enjoy about rust.
It's like how you can do the exact same thing in C++, using the same concepts and tools (for the most part) with different names, but it never felt the same, or as natural. It's definitely helped the way I think about programs as a whole.
I feel the same way when I implement reference counting in a C program. It's certainly clarifying and educational. I think it's hard to argue that it's the most expedient way to write a CRUD application, though. Sometimes the most expedient path isn't the most fun one.
Totally reasonable question. The issue isn't how hard it is to get the memory for the a vector, but rather what you have to do to store references to that vector elsewhere in your code, so that the compiler can prove its bounded lifetime and release resources without creating UAF bugs.
"Systems programming language" has almost turned into a weird slur; instead of using it to refer to languages that can actually handle that task, they use it to attempt to pigeonhole a language intoonlythat.As in, people don't realize being a "systems programming language" is extremely difficult to get right, and many languages simply can't handle that (and never will, as per internal design requirements unique to those languages); if a language gets that right, they're going to get everything else right too if people decided to use it for that.
See, depending on your definition of "systems programming language", that is just wildly false. A language that nails all the details and ergonomics of expressing a kernel block device driver is almost necessarily going to be suboptimal for exploratory scientific computing or line-of-business app development.Again: this is about the term, not about the language. I don't think it's controversial to suggest that there is no one ur-language that is optimal for every problem domain!
I don't think the people that use it as a slur actually define it. They use it to mean the language they don't like because they think it has some level of enforced complexity that takes away from the language instead of being an important feature of the language.
Yes: it's about the distinction between global GC and programmer-defined memory management. GC is about as straightforward a tradeoff as you can make: remove a very large class of programmer concerns in exchange for a different performance envelope. It is not reasonable to argue that Rust's memory management doesn't represent a point on a tradeoff space --- that people suggesting GC languages are better fits for some problems just don't grok Rust well enough. That's a common trope, and it's pretty obviously false, just as it would be false to say that kernels should just supply a GC runtime so we can write device drivers in Java.
Meanwhile there are companies doing just that, better let their management know how fool they are selling bare metal real time Java runtimes, Oberon, Go and C# based microkernels.Even more so the fools that given them money for such products./s
Look, I know there are bare metal Java runtimes (I've done assessment projects for some of them), I just don't want to litigate the point. I'm fine with a definition of "kernel programming" that fits Linux and the NT kernel and nothing else.
A quite reducing view of the computing world.
Yeah I use often Rust where Python would be enough. But unless I really need quick/interactive feedback (for exploratory stuff ie.: Jupyter with plots), Rust suits me well.
I enjoy expressing applications in C. Once a week, a story hits the front page here about someone shipping a web app in C. C suits me well. But I don't pretend that's an objectively reasonable engineering decision. It is not.
rust is fine, it's a solid mix of performance and expressiveness, it has good constructs and it's gaining tractionit's hard to learn so we shall see what kind of niche it can carve for itself, but it's fine
> it's hard to learnAnd as long as Rust remains popular, this is why we will witness endless complaining about it. Most devs are lazy, and would rather sweep complexity under the rug and pretend it doesn't exist until it becomes a real problem they can't ignore anymore. That's fine. But no need to be so vocal about it. At this point, people whining about Rust is more of a trope than people proselytizing it.
> Most devs are lazy, and would rather sweep complexity under the rug and pretend it doesn't exist until it becomes a real problem they can't ignore anymoreYou mean pragmatic. Not all of us are memory absolutists. The time ideally invested in memory management really depends on the problem space, the deadlines, etc.
> At this point, people whining about Rust is more of a trope than people proselytizing it.This is common pattern reminds me cross-fit/veganism/i-use-arch/etc. Almost like an echo.
> Most devs are lazy, and would rather sweep complexity under the rug and pretend it doesn't exist until it becomes a real problem they can't ignore anymore.It's the opposite for me.  I would put more effort into Rust, but I'm not going to invest in learning how to write safe rust if my libraries are built on unsafe.
So much to disagree with....> In practice, people just want to be able to write a tree-like type without having to play Chess against the compiler.Sure, Rust's strong encouragement of tree-structured ownership may be annoying when you try and make a spaghetti ownership soup, but it's not like it doesn't have upsides. Many people have written about how the ownership & borrowing rules lead to code structure that has fewer bugs.> I think that if you rewrite anything from scratch with performance in mind, you’ll see a significant performance improvement.Maybe, but I think this is missing the point. The "rewrote it in Rust and it's X times faster" stories are generally when people rewrite from very slow (Python) or medium fast languages (JavaScript or maybe even Go).In those cases you can rewrite in Rustwithoutconsidering performance and get amazing speedups. I recently did a straight 1:1 port of some Python code with zero extra optimisation effort and got a 45x speedup.Sure I maybe could have got the same in C or C++ but there's no way I would have rewritten it in C++ because fuck segfaults and UB. I don't want to spend any more of my life debugging that.> Rust has arrived at the complexity of Haskell and C++, each year requiring more knowledge to keep up with the latest and greatest.I don't really know about Haskell, but I don't think Rust's complexity is anywhere close to as bad as C++'s. Even if it were it doesn't matter because in Rust if you forget some complex rule the compiler will tell you, whereas in C++ it will randomly crash but only in release mode after the program has been running for 2 hours. Totally different.> The “Friendly” CommunityGotta agree with this though. The "we're friendly" thing is bullshit.> Async is highly problematicAlso agree here. Async is a huge wart on Rust's otherwise relatively unblemished face. Big shame. Oh well. You canmostlyavoid it, and there are some cases where it's genuinely good (e.g. Embassy).> I feel like Rust is self-defined as a “systems” language, but it’s being used to write web apps and command-line tools and all sorts of things.
> 
> This is a little disappointing, but also predictable: the more successful your language, the more people will use your language for things it wasn’t intended for.I don't see why he's disappointed about this. Rust is great for command line tools and web backends.> I think that the excellent tooling and dev team for Rust, subsidized by Big Tech, pulls the wool over people’s eyes and convinces them that this is a good language that is simple and worth investing in. There’s danger in that type of thinking.Ok this guy is not worth listening to.
First off, if you edit the "this guy is not worth listening to" out of your comment, you'll probably get better responses from people.Second: I don't think this author disagrees with you that there are huge speedups to get from porting code out of Python. But you'd also get huge speedups porting to Java, and you wouldn't be in the business of managing your own memory lifecycles.
I don't think that was too harsh given that he's saying that everyone who likes Rust (anextremelypopular language) is an idiot who has been tricked into thinking it's good.How can you take opinions like that seriously? It's like saying "nah The Beatles weren't actually that good, everyone just thought they were because of their cool sunglasses".It's patronising and illogical and I don't think it's worth listening to nonsense like that.
He didn't say that at all.
I literally quoted it:> I think that the excellent tooling and dev team for Rust, subsidized by Big Tech, pulls the wool over people’s eyes and convinces them that this is a good language that is simple and worth investing in. There’s danger in that type of thinking.Patronising and wrong.
I think they're squaring "simple" against "millions of dollars of investment." Some other languages are successful without that.
I'm curious what kind of code gets a 45x speedup by going from python to rustand by that I don't mean the rhetorical or bait-style "i'm curious", no, the literal I'm curious, cause I'm trying to find use cases such as that these days and I'm often thwarted by the fact that for anything requiring remotely decent speeds, python most of the time already delegates to C extensions and so any rewrite is not as useful
"I'm often thwarted by the fact that for anything requiring remotely decent speeds, python most of the time already delegates to C extensions and so any rewrite is not as useful"Be sure you verify this is the case for whatever you think it is, though. Pure Python is so much slower than compiled languages (not just Rust) that you don't have to do much percentage-wise in pure Python before you've badly fallen behind in performance versus the pure-compiled alternatives.I think this is asserted a lot more often then it is benchmarked. I am reminded of the way people for a long time asserted that the performance of web languages doesn't matter because you spend all your time waiting for the database, so it never mattered. People would just whip this argument out reflexively. It turns out that if you take a non-trivial codebase written in such a language and actually benchmark it, it is often not true, because as applications grow they tend to rapidly outgrow "all my code is just running a SELECT and slamming the results with minimal processing out to the web stream". I hear this a lot less often than I used to, probably through the slow-but-effective process of a lot of individuals learning the hard way this isn't true.I've seen a lot of Python code. Very little of it that was not "data science" was just a bit of scripting around lots of large C-based objects, such that Python wasn't doing much actual work. And even some of that "data science" was falling back to pure Python without realizing because NumPy actually makes that shockingly easy.
It would be interesting to me to look at something written in Python and rewritten in Rust with a 40x speed-up, and then rewrite it in something like C# or Common Lisp, and see what the speed-up is. My gut tells me the Rust implementation would use significantly less memory than the CL one, but be only minimally faster, if at all. But my gut has been known to be unreliable in the past.
When comparing a networked service that wrote to disk (a-la magic wormhole) written in Java and in Rust, after 3 iterations of improvements on the respective implementations the throughput wasthe samefor both, CPU utilization was comparable, but memory usage wasorders of magnitudelower for Rust. I think that Java will have difficulty closing the gap until project Valhalla (value types in the JVM) is completed, but even then it'll be difficult to bring the ecosystem along to materialize all its benefits.
Is that Rust version of Magic Wormhole released?
I saw some time back that a productionalized attempt came out:https://github.com/magic-wormhole/magic-wormhole.rsThe one I mentioned was much more primitive, meant as a demo (you can look at the branches for different approaches):https://github.com/estebank/rusticwormhole
Anecdotal experience: we rewrote an image processing algorithm from numpy+scipy to pure rust and got a 50x speedup in release builds, without even spending any effort optimizing the rust side.There are further improvements possible around memory allocation and cachelines, but 2 days for 50x improvement was sufficient to not make it worth investing additional effort.Edit: this was from a team who had _never_ touched Rust before.
This is an old example, but - date/time parsing.A coworker of mine years ago was trying to parse out some large logfiles and it was running incredibly slowly (because the log file was huge).Just for fun he profiled the code and found that 90% of the time was spent taking the timestamp ("2019-04-22 15:24:41") into a Python datetime. It was a slow morning, so we went back and forth trying to come up with new methods of optimizing this parsing, including (among other things) creating a dict to map date strings to datetime objects (since there were a lot of repeats).After some even more profiling, I found that most of the slowdown happened because most of Python's strptime() implementation is written in Python so that it can handle timezones correctly; this prevented them from just calling out to the C library's strptime() implementation.Since our timestamps didn't have a timezone specified anyway, I wrote my first ever C module[0] for Python, which simply takes two strings (the format and the timestamp) and runs them through strptime and returns a python datetime of the result.I lost the actual benchmark data before I had a chance to record it somewhere to reproduce, and the Python 3 version in my repo doesn't have as much of a speedup compared to the default Python code, but the initial code that I wrote provided a 47x performance boost to the parsing compared to the built-in Python strptime().Anyone who had a similar Python script and converted it wholesale to Rust (or C or Golang, probably) would have seen a similarly massive increase in performance.[0]https://github.com/danudey/pystrptime/
One could argue that writing a timestamp as a string which then has to be parsed is silly and instead it should be delta-of-delta encoded and packed into variable width integers, but even then double integrating and constructing a datetime for each one would still be expensive in python, only less so.
> I'm curious what kind of code gets a 45x speedup by going from python to rustPretty much any code that is not just tying together external libraries?
If you heavily rely on the Python standard library, then  you’re using a lot of Python code that doesn’t call out to C extensions. Peruse the standard library code, if you want to get a sense of it:https://github.com/python/cpython/tree/main/LibSo you can expect any code that heavily relies on the standard library to be slower than the Rust equivalent.A purely interpreted language implementation (not JIT’d) like CPython is almost always going to have a 10x-100x slowdown compared to equivalent code in C/C++/Rust/Go or most other compiled/JIT’d languages. So unless your program spends the vast majority of time in C extensions, it will be much slower.
My "I'm gonna learn Rust!" initial project was porting a callgraph traversal tool from Python to Rust. For loading in my input file, the speedup was very disappointing: 1x. (As in, no speedup at all.)Then I learned about the `--release` flag and it instantly became a 40x speedup. So that was nice.Waiting 30s vs <1s puts it well within "anything requiring remotely decent speeds". But it was really about parsing a custom data format, nothing fancy. I haven't done comparison timings of the graph traversals, but everything is basically instantaneous in the Rust version and not in the Python.
It is basically reading a massive JSON file containing a few thousand logs and then scanning them with a load of regexes.I was a bit surprised how much faster it was too. Apart from Python being dog slow the only thing I really changed was to use RegexSet which isn't available in Python. I didn't benchmark how much difference that made though; I just used it because it was obviously the right thing to do.That's kind of the point. If you just do the obvious thing in Rust you get very good performance by default.It's the same in C++ but then you're writing C++.
The actual regular expression implementation in Rust is going to be fast, but one of the things that caught a reddit poster out only recently was that the Rust regex crate's parser doesn't magically cache, so if you sit in a tight loop making the same regex over and over, it'll do all that work over and over, whereas the Python code might take ten times longer to do it once, then caches it, it doesn't take long for that to end up faster.Now, if you're going to use RegexSet you're also smart enough to read "For example, it’s a bad idea to compile the same regex repeatedly in a loop" and say "Yeah, makes sense, I will not repeatedly compile the same regex". But some fraction of Python programmers won't read that - and it'll be very slow.
There's plenty of examples like that though. A Python programmer might not know to compile in release mode. They might not use buffering when reading from a file. They might pass around copius copies of Vec<T> instead of &[T]. The list could go on and on.
Sure, and there would probably be some value in a tool which can walk them through the easy stuff before they show a real human code which it turns out just wasn't tested with release optimisations or whatever.Still, as I understand it CTRE means if you just "use" the same expression over and over in your inner loop in C++ (with CTRE) it doesn't matter, because the regular expression compilation happened in compilation as part of the type system, your expression got turned into machine code once for the same reason Rust will emit machine code for name.contains(char::is_lowercase) once not somehow re-calculate that each time it's reached - so there is no runtime step to repeat.This is alongway down my "want to have" list, it's below BalancedI8 and the Pattern Types, it's below compile-time for loops, it's below stabilizing Pattern, for an example closer to heart. But it does remind us what's conceivable.
IDK how we jumped to CTRE. Python doesn't do CTRE. It's doing caching. In Rust, you use std::sync::LazyLock for that. I don't get what the problem is to be honest.I assume by CTRE you're referring to the CTRE C++ project. That's a totally different can of worms and comes with lots of trade-offs. I wish it were easy to add CTRE to rebar, then I could probably add a lot more color to the trade-offs involved, at least with that specific implementation (but maybe not to "compile time regex" in general).
I jumped to CTRE because it's another way that you can get the better results. The programmer need have no idea why this works, just like with caches.I agree that there are trade-offs, but nevertheless compile time regex compilation isonmy want list, even if a long way down it. I would take compile time arithmetic compilation† much sooner, but since that's an unsolved problem I don't get that choice.† What I mean here is, you type in the real arithmetic you want, the compiler analyses what you wrote and it spits out an approximation in machine code which delivers an accuracy and performance trade off you're OK with, without you needing to be an expert in IEEE floating point and how your target CPU works. Herbiehttps://herbie.uwplse.org/but as part of the compiler.
Conway's Game of Life perhaps is a good example: it's a simple program, with a tight loop and cheap calculation in the loop. Python's loops are slow. I wouldn't be surprised if the speedup was much greater than 45x.
So, we should be focused on attacking the author, not the points raised in the article?
The author predicted it.
Surely someone who writes a lot of C code as he mentions has written it for hardware, no?
Take a gander at the rest of that blog, they're a Haskell main.
If you re-read the sentence with s/Chris/The Author/ I expect you'll find the pronoun cromulent. "They" was exclusively plural in Middle English in the 1300s, but, we're not speaking Middle English.
It is common to use "they" for singular unknown people, e.g. "Someone left their coat here."I'm not OP, but since I don't know anyone on the Internet, I have the habit of using "they" for everybody, for example: "WildRookie? No, I don't know their real name, only that username."It could be that OP has such a habit, which just carried over for referring to Chris, even though someone named "Chris Done" is probably a man (although, there are women who go by Chris).
What else would you call them? A collective?
A person?
The author seems very anxious because Rust is getting traction and they don't like Rust. They're afraid that one day Rust will become a "monoculture" and everything will be written in it.I like Rust, but I consider this very, very unlikely.Rust has actually brought more choice to the programming language scenario. If we're talking about monoculture, let's talk about C/C++. For decades this was the only viable option for systems programming. All new languages were focusing on a higher lever. Languages for lower level stuff were rare. There was D, but it never got enough traction.Then Rust appeared and there is finally an alternative. And not only that, I because of that, other language designers decided to create new systems languages, and now we have Zig, and Odin, and Vale, etc.So if anything, Rust is helping in breaking the monoculture, not creating it. C and C++ are not going away, but now we have alternatives.And I think it's important to acknowledge that even if you don't like a language, if you see a bunch of software being written in such language, it's because the language is useful. I don't like C++ but I admit it's damn useful! People are writing interesting software in Rust because they find it useful.
Rust is challenging people because it declares several long-inadequate things about C/C++ to be inadequate (security issues, dependency management), and provides alternatives which show that it doesn't have to be like that.The rewrites will inevitably be long and painful. Rewrites always are. But the onus on anti-Rust people is now to demonstrate a better language to rewrite in first, rather than just sitting in the status quo waiting for the steamroller driven by a crab to very slowly run them over.D is interesting but seems to be a solo project, I'm not sure why it's not had traction. Maybe it's not different _enough_.
This is not meant as a critique of you, but your comment includes a hint of what bothers me with some Rust evangelists. I would call it "slightly entitled over-optimism".I have a C++ service running in production. It's been in production for 10-ish years with minimal updates. It'll probably keep running just fine for the next 10 years.With that in mind, "the onus on anti-Rust people is now to demonstrate a better language to rewrite in first, rather than just sitting in the status quo waiting for the steamroller driven by a crab to very slowly run them over." just doesn't make much sense to me. If the status quo is fine, there's no "onus", there's no difficult decision to be made, there just isn't any rewrite. The anti-Rust people will probably be fine by doing ... nothing.
> I have a C++ service running in productionIs it on a network (or other) security boundary, exposed to attack from the Internet?Is it deployed on millions of machines worldwide?_Those_ are the primary targets for replacement, because the networked environment is a very hostile place, and people are fed up with the consequences of that. Regular announcements of "sorry all your private data has been leaked lol". Constant upgrade treadmill to fix the latest CVEs.(the poster child for this was really Shockwave Flash, later owned by Adobe, which had so many RCE exploits everyone united behind Apple killing it off. Even if this meant obsoleting a whole era of media and games which relied on it. That wasn't rewritten, it was just killed.)
I'd guess most services where performance matters are in the background. And this particular C++ service is only accessible over internal LAN, to be used by other back-end servers.I agree with you that if ha-proxy and nginx didn't exist yet, they would be prime candidates for being implemented in Rust. But now that they already exist and reliably work, I'm not sure there is enough pain for them to get replaced anytime soon. BTW the last ha-proxy CVE was them differing from the HTTP spec and accepting the # character in additional URL components, which is something that probably no compiler could have flagged.
> I'm not sure there is enough pain for them to get replaced anytime soon.https://blog.cloudflare.com/how-we-built-pingora-the-proxy-t...https://blog.cloudflare.com/pingora-open-source
That sounds like a great project :) but1. "Pingora is Not an Nginx Replacement"https://navendu.me/posts/pingora/2. you still put it behind ha-proxyhttps://github.com/cloudflare/pingora/issues/1323.https://github.com/cloudflare/pingorasays "Pingora keeps a rolling MSRV (minimum supported Rust version) policy of 6 months." so for anyone who dislikes the "constant upgrade treadmill", this won't help much.So my summary would be that Pingora is a great Rust library which one day might be used for replacing nginx and/or ha-proxy.But the main advantages of Pingora - which are the reason why CloudFlare is using it now - have nothing to do with Rust. Obviously, a software architecture designed in 2022 can take advantage of modern hardware in a way that an architecture from 2004 cannot. (Yes, nginx is that old). Intel's TBB library brought "work-stealing" to C++ around 10 years ago. The other big improvement in Pingora is moving from multi-process to multi-threading pools. Again, C++ had thread pools for years.So Pingora is probably great and it's written in Rust. But the business benefits that it brings aren't coming from Rust. They are coming from the fact that it's a modern architecture.
> But the business benefits that it brings aren't coming from Rust. They are coming from the fact that it's a modern architecture.This is moving the goalposts. Your original post said>  I'm not sure there is enough pain for them to get replaced anytime soon.Yet, here one of them is, being replaced at a company that powers ~10% of the traffic on the Internet.But beyond that, your links:> 1. "Pingora is Not an Nginx Replacement"https://navendu.me/posts/pingora/Here's what the start of the post actually says:> Think of Pingora as an engine that can power a car while you have to build the car yourself. Nginx is a complete car you can drive. River is a faster, safer, and an easily customizable car.The title is being pedantic for effect. It doesn't say what you say it's saying.> 2. you still put it behind ha-proxyhttps://github.com/cloudflare/pingora/issues/132This is an issue opened by someone on an open source repository. They aren't talking about how Cloudflare itself uses it, but about how they want to use it.> so for anyone who dislikes the "constant upgrade treadmill", this won't help much.Similar to above, this is moving the goalposts. Sure, that might be true, but it's unrelated to the original topic.> But the main advantages of Pingora - which are the reason why CloudFlare is using it now - have nothing to do with Rust.This is not what Cloudflare themselves would say. They chose Rust for very specific reasons when building Pingora: (repeating the link from above)https://blog.cloudflare.com/how-we-built-pingora-the-proxy-t...> We chose Rust as the language of the project because it can do what C can do in a memory safe way without compromising performance.Cloudflare has been a vocal proponent of Rust for years now. Many years ago, they suffered a very serious bug, CloudBleed, that Rust would have prevented. And so they've been using Rust instead of C and C++ for a long time.They of course would also very much agree that the architecture matters, but that doesn't mean that the implementation language doesn't matter either. If they chose to implement Pingora in, say, Ruby, that wouldn't have accomplished their goals.
I don't think anyone believes there will be no C++ codebases in the future - that's crazy talk. What could happen in a decade or two is that there'll be no _new_ C++ codebases. Popular languages are retired to legacy status from time to time, and C++ is completely outclassed by Rust.
People love to think that C++ is only used in systems programming, the thing is C++ is usedeverywhere.FORTRAN is being developed and improved, and new code, most notably in scientific domain, is still being written.What Rust did to C++ is what clang did to GCC. Wake the giant up. Rust will go nowhere, but it's the same for C++.Thinking that C++ will just fade to black is wishful thinking.
Since C++ still evolves and changes, I guess greenfield C++ projects in the future can limit themselves to a subset of the newer improved language thereby C++ will continue living by that way as well.
The C++ community is talking about evolving in the following ways in this space:1. contracts
  2. profiles
  3. successor languages
  4. borrow checkingThe idea of a "subset of the language" is one that's often talked about, but there seems to be an explicit rejection of the idea of a subset, at least by several important committee members. It's not clear to me why this is the case.
I’m not sure why you’re getting downvoted. The committee members have clear interest to keep things as they are. However, from a practical perspective I suspect that “subset lang” will happen. One just needs a linter or compiler flags to do that.
It's all good, I have too much karma anyway.The thing is, there's a difference between a true subset and "some flags that reject certain things." Because that creates a number of different sets that may relate to each other in a variety of ways, some subsets, some overlapping.But beyond the specific definitions here, "profiles" is that sort of approach, so somethinglike itwill happen, probably. It seems to have a lot of support.
"Subset language" is already an option. The developer can choose a safe(r) subset of C++ to constrain themselves to. Many (most?) C++ shops already do this, and go to varying lengths to enforce that only their blessed subset is used. We don't really need a committee to create a new "subset language" to accomplish this.
C++ already passed that line with C++17 and newer iterations. Not only it evolves way faster starting with C++17, the modern code looks sufficiently different that it needs relearning some parts of C++ from start.I've written my biggest project with C++11, and C++14 was just out back then. Now, I plan to reimplement that project (and improve it), again with C++, but I need to look at so-called "modern C++" to do it correctly and in a more future-proof way....and I'm glad I have to do that, because while I love (old school) C++, seeing  it evolve makes me happy. Because systems evolve, software scale evolve, and most importantly hardware and ways to get maximum performance from it evolve.There's no need to write old-school C++ anymore. All these features are developed for a reason, they shall be used.
What new scientific applications are being written in Fortran?
Fluid dynamics codes are still being written in Fortran.Notably, there are still improvements happening in the Fortran space, and there's been a bit of revival of sorts. There are still features in Fortran that make it nicer to write in than C++ (and while I'd hoped rust might be a good Fortran replacement, I feel rust has taken a different path, and remains no better than C++).
New CFD codes?  Links?
I would like to echo this sentiment. I like Rust, but I can't see a Rust monoculture.From my experience, Rust is an absolute improvement in developer experience around so many corners. I'm looking forward to the future where Rust is well established and boring, and all its round edges have been solved, even if that means adopting another new and exciting language :)
IMO there was only a brief period of monoculture, and only if you consider C & C++ to be part of the same culture, which is a stretch.    It started in the mid-80s when people stopped writing programs in Pascal and/or assembly, and stopped in the mid-90s when Java & Perl started to get used extensively.
> if you consider C & C++ to be part of the same culture, which is a stretchThat’s my main gripe with most pro-Rust comments of this kind, to be honest. There are a few ways to write C and a lot of ways to write C++, and most of the C is quite unlike most of the C++. (I’m not counting marginal cases like raw GObject or raw COM as C here, I think those count as basically separate languages.)The problem is, the Rust I’ve read (and read about) is methodologically and stylistically a replacement for most of the C++, but not a lot of the C. I don’t dislike the theory behind Rust—I’ve written Haskell, I’ve written SML, I read the Tofte&Talpin regions paper and some of the subsequent research more than a decade ago. I do dislike when people ask me to switch or even try to, of all things,shameme into switching from C to what presents itself as a better C++, in largely the same way that I dislike attempts to switch to C++ that claim it’s the same thing as C. No it isn’t. And I largely tune out when I read “C/C++”, because it implies the authordoes not get it.(I’m aware there are other people that do get it, some of whom work on other programming languages. They just don’t write posts proposing Rust replace C.)
I was talking about a monoculture specifically in the systems programming area. Java, Perl, PhP, Python, Ruby, JavaScript, C#, Go, these got popular but they use garbage collection and have limitations for systems programming. C and C++ were the only options for a long while.
Systems programming is just a niche.   A large niche, but just a niche.   But between when Pascal & Assembly stopped being used widely and before Java started being used widely C & C++ were used for pretty much everything.
FWIW it was LLVM that catalyzed the modern florescence of programming language innovation.  Rust is just another result of that shift, not its cause.
The author makes the best argument for Rust in the linked post[0]Rust is great for teams because it removes many things that make working on team code dangerous. The items mentioned above are some.

    I work alone, however, because I like to keep my code in my head and working with people means parts of the code are only in their head.

    This also means that the bigger the language is, the less space I have in my head for the code.

    Rust is too big for my small brain, unfortunately.Most code is written in teams and even software with a single author needs a plan for when the maintainer steps down. Besides this I disagree with the author's assertion that Rust is not well suited for them, in fact I think it's strictly better than C because it often obviates the need to keep stuff in your head. Take lifetimes, in C you have to keep track of pointers and their lifetime in your head, and by definition all other maintainers have to do the same, in Rust the compiler does that for you, less to keep in your head. In fact I think the ability offload things from your head to the compiler is one of Rust's great strength. This ties in with compile times too, yes Rust is very slow to compile, but the compiler also does a whole lot more work than the C compiler. Obviously we want rustc to be as fast as possible given the work it's doing, but it will never be as fast as a C or Go compiler.0:https://gavinhoward.com/2023/02/why-i-use-c-when-i-believe-i...
"Most code is written in teams and even software with a single author needs a plan for when the maintainer steps down."I strongly disagree! My experience is this:1. Sole developer builds useful thing2. Team takes over maintenance3. Feature bloat, sluggishness, bugs ignored, Agile initiative, "Product owners"4. Company goes bankrupt or gets acquiredI don't think you can have the clarity of vision that a single person will produce if you're working on it with a big team. That's why so many useful things start with a single person or a very small team, like Linux, Android, curl, ffmpeg, Quake engine, the 2 ppl Firefox "Phoenix" team, the original 3 ppl JetBrains team, the 2 original Photoshop devs.
> That's why so many useful things start with a single person or *a very small team*,You subtly shifted the goal posts here. But even if you start out with a single person you eventually have to have new maintainers, if only because of human mortality. Software is a young field so we haven't had to contend much with this fact yet, but it's inevitable.Personally I think something like Rust is helpful for large solo programs too, keeping everything in your head past 10kCLOC is hard so why not have a language and compiler that helps you?
My personal opinion is that Rust is a bit too lengthy to keep everything in your head. For a solo program, I'd probably go with Python first, just because it tends to produce very short and yet readable source code.And yes, I shifted the goal post a bit by assuming the team to be medium to large in size. If I assume a very small team like the initial Photoshop release with 2 people closely working together every day, then I think their communication will be so good that there aren't "many things that make working on team code dangerous" left. So in that case, I wouldn't expect much benefit from using Rust.
> My personal opinion is that Rust is a bit too lengthy to keep everything in your headI'm curious what you mean by "lengthy" here. The reason I say Rust lets me keep fewer things in my head is because something like this in C:struct Bar {};
    
    struct Foo {
        struct Bar *bar;
    };where it's no clear if Foo owns Bar or merely outlives it, becomesstruct Bar;
    struct Foo<'b> {
        bar: &'b Bar,
    }in Rust and I no longer have to keep this information in my head.
Interesting, it's mostly concepts and architecture in my head, and less lines of code.
Ugh, seen this pattern happen many times at smallish companies. The O.G. codebase was written by a single person. It did one or two things very well, with few bugs, had consistent filenames, variable names, APIs, formatting, and so on, it had a single, pure vision throughout the code, and didn't have all those problems that happen when multiple people reason differently about the same code.Then, eventually, the company gets bigger and the product needs to grow beyond the capability of one person, so a team starts developing on the codebase. That's where the bugs start pouring in, where everything becomes less consistent, where different design patterns are used all over the place, and where the "single clear vision" gets cast aside. A lot of problems that get blamed on "technical debt" and "brittle code" are often just plain coordination and consistency problems that are happening because multiple people can't share a single consciousness.
Rust is certainly not the last word in systems programming languages, but it's an huge leap forward from C and C++. To be honest, it's a sad reflection of our industry that it's taken this long to get basic safety + ML circa 1975 language features into this niche. If things had turned out a little bit different we could all have been using OCaml for the past few decades.
My favorite hypothesis here is that programming language enthusiasts are too different. They are incapable of convincing the average programmer of the merits of their favorite language, because their way of thinking is different. Arguments they find convincing are not convincing to the average programmer.Progress happens incrementally with small steps. Existing languages get new features. New languages get popular, because they look familiar but contain some small meaningful improvements. And familiarity is important. Languages like OCaml never become popular, because they are too different. Even the syntax looks unfamiliar.
> Arguments they find convincing are not convincing to the average programmerI think one problem is believing there exists an "average programmer". It's easy to think in averages (or medians), but the reality is that there is no average person, and exactly one median person.Realizing that every single person is different is important, because you then start to work in more discrete niches. It's going to be much easier to appeal to "programmers who write X in Y with the following constraints" than it will ever be "programmers who write in Y".Or to bring this closer to the topic of discussion, you'll never convince game developers to drop C++ in favor of rust using the same arguments as you'd use to convince a service developer to drop C++ for rust.
I agree, though a big issue is that at some points progress can't happen without breaking backwards-compatibility. If the problem to be solved is that something is allowed which shouldn't be, then backwards-compatibility will prevent progress.C & C++ allow quite a few things they shouldn't need to allow to accomplish their goals. They'll never stop allowing those things, so they'll never improve in certain ways.Rust has a strong backwards-compatibility guarantee, and it has run into this issue with its standard library already. The edition system means the language can break compatibility in some cases, but the standard library can't. I suspect this will eventually prevent necessary incremental change, as it has for C & C++.
> Existing languages get new featuresThat's how you wind up with C++
Or English.A lot of people used to advocate for using their favorite ancient / artificial languages in international contexts and for communicating important matters. But somehow the C++ of natural languages became dominant.
I think you're right. The same way people have strong preference for Systemd, MacOS, KDE, Gnome, I3, Nix, Debian, Gentoo, Arch, etc.So many different solutions. Most are preferred because of subjective reasons (although sometimes just poor reasoning period), because people think so drastically differently.
People reject OCaml for these use cases due to the GC, but I wonder if this actually matters in practice. The optimizations that can be applied to ML languages (see MLTon for example) are very advanced and the ability to do multi core with ease (I know this is more recent to OCaml) can be a big performance unlock that is very hard to get right in C.
The GC does matter.Most applications are completely fine with having a garbage collector, but they are not fine with having multiple garbage collectors!
Mixing multiple garbage collected languages is a recipe for complex bugs. At a minimum, reference cycles across the languages will result in memory leaks.Thus every garbage collected language tends to grow its own ecosystem of libraries, with the whole world having to be re-implemented in that language.
The only exception are the C/C++/Rust libraries, as these can be used (through C FFI interface) by almost every other language. This is precisely because these languages do not introduce their own heavy-weight runtime (especially: no GC), allowing them to be combined with another language's runtime.Thus widely used libraries must be written in one of the non-GC languages, even if 100% of the applications using them are fine with having a garage collector.
I see this same situation playing out with async executors.   tokio is taking over, but it doesn't play well with other async executors.   I just wrote a program that mixed tokio & glib and it wasn't fun.This does feel like a soluble problem, so I hope they do figure it out.   I think the first step might be something like without.boats' proposal to add something likehttps://github.com/zesterer/pollsterto the standard library to establish a minimum common denominator.
GC is perfectly fine for ~99% of applications, which is why all the languages in the last few decades adopted it, and eliminated themselves from being direct C/C++ competitors.Lack of GC isn't a requirement for most programs. However, it is a requirement for a language meant to actually replace C and C++, because these two are mostly used in the remaining fraction of programs and libraries where any GC or any fat runtime is undesirable. Even where some GC could be made to work, it makes it a tough sell for C/C++ users.
> it's a sad reflection of our industry that it's taken this long to get basic safety + ML circa 1975 language features into this niche.That's true.
Could it be that's because we are expert at nitpicking every programming language, every framework and stack which appears to the point it takes time to make steps forward ? Some sort of paralysis, insecurity and confusion ?
Sadly, Rust is only a "huge leap forward from C and C++" for some use-cases.Simple things like returning a const reference to a slot in an immutable array are easily 10x the amount of source code in Rust when compared to C. And all the standard libraries for embedded systems are C, so to get into embedded development, you definitely need to be good at reading C code. Rust is an additional skill, but if you only know Rust and no C, you're of no use in embedded land.I think that's the main reason why we don't move away from C: You still need a firm grasp of C if you want to be a capable higher-level developer.C++ is then the logical upgrade because it's compatible with C and looks very similar. Java also did OK because it looks and feels very similar. And there's good automated C to Java converters. So you get the benefits of Java over C almost for free. Rust, on the other hand, throws away most of the C conventions and that makes it feel foreign and "incompatible".Rust also suffers from a serious "not invented here" problem, in my opinion. It's super easy to re-use C code in C++ or Java. It's significantly more difficult to re-use C in Rust unless you go unsafe and abandon most of the Rust advantages. That means most dependencies need to be re-implemented in Rust if you want to have all the advantages that Rust offers. Go had the same problem, but they had Google's weight behind them to push out tons of libraries. Who is doing that for Rust?In the end, I agree with the article: Rust is great! when it fits. But there are still plenty of situations left where Rust is worse than old-school C.
> Rust also suffers from a serious "not invented here" problem, in my opinion. It's super easy to re-use C code in C++ or Java. It's significantly more difficult to re-use C in Rust ...It feels like a mischaracterization of Rust and I strongly disagree. Both the language and tooling are designed from the beginning for interop with C code. It isn't very hard to do if you have tried it.> ... unless you go unsafe and abandon most of the Rust advantages. That means most dependencies need to be re-implemented in Rust if you want to have all the advantages that Rust offers.This 'Rust is useless if you use unsafe' is a stance that is well debunked, but still gets repeated like this. Ensuring safety using Rust semantics across an FFI with a language like C is impossible - making unsafe necessary. But just because you use unsafe doesn't mean that the language lost most of its advantages. In fact, almost every Rust program uses unsafe code, if you care to look at the code in the standard library. Yet, that never seems to be a problem.What unsafe does is to cordon off a small code area where certain invariants have to be asserted manually, instead of relying on the borrow checker. You still get the safety for the rest of the code. In case you do get safety violations, there is much less code to debug. This is a significant advantage over languages like C++, considering that unsafe blocks are usually less than 5% of the code, even in the worst case. But to take it further, C libraries often have corresponding Rust wrapper libraries that create safe wrappers over C FFI calls. In addition to the small unsafe blocks to verify manually, these wrappers have the additional advantage of being widely used and debugged by a wider community. There are innumerable such wrappers on crates.io and it's uncharitable to accuse the language of NIH syndrome.
"It isn't very hard to do if you have tried it."My attempt at OpenGL rendering with Rust turned out to be a lengthy journey of suffering through way too many layers of rust wrappers around unsafe C shared libraries. I especially hated that I constantly had to use casting helper functions to go from pre-defined OpenGL constants back to their associated integer values.And I do think it's valid to accuse NIH syndrome if there is exactly 1 OpenGL API in C but there are 100+ Rust crates for various OpenGL wrappers.
> My attempt at OpenGL rendering with Rust turned out to be a lengthy journey of suffering through way too many layers of rust wrappers around unsafe C shared libraries. I especially hated that I constantly had to use casting helper functions to go from pre-defined OpenGL constants back to their associated integer values.From this description, I can't figure out if you used FFI or a wrapper library. But it looks like you are complaining about both - which can't happen together. And the problems you mention seems very specific to the choices you made. I have faced similar problems with other code - something often solved by choosing a different library or approach. I don't see that affecting Rust's FFI story.> And I do think it's valid to accuse NIH syndrome if there is exactly 1 OpenGL API in C but there are 100+ Rust crates for various OpenGL wrappers.By definition, they didn't invent anything if the crates were wrappers. They were just using that exactly 1 OpenGL API - the thing that you were accusing them of not doing. And as for 100+ Rust crates, I don't think that should be a problem. Wrapper developers often try different API styles. It's just that crates.io makes them all very visible. In practice, just one crate (or a group of related crates) become popular enough to be the defacto standard in a segment.
> It's significantly more difficult to re-use CIt's not, and you're over indexing on your experience with OpenGL.There are plenty of rust libs that are thing wrappers over C libraries. They're widely used, without a problem. libgit2, written in C, is the most popular Rust library for git bindings.Despite that, people do prefer pure Rust libraries for a very valid reason - it makes building the project, especially cross-compiling very easy. That's why cargo audit shifted from libgit2 to gitoxide.Who is sponsoring the development of these libraries? The Rust Foundation gave the developer of gitoxide grants to develop it, with the eventual goal of replacing libgit2 in cargo.I'm sorry you had a bad experience with OpenGL, but I don't think it's accurate to extrapolate your experience with that onto the entire ecosystem.
> Simple things like returning a const reference to a slot in an immutable array are easily 10x the amount of source code in Rust when compared to C.I’m very interested in what you mean here. Isn’t the syntax identical in both cases?&array[index]
My personal take on this subject is that Rust turns experts back into beginners and some devs react with hatred because of the fear this induces. For me it was the opposite. I was getting bored with my industry and thinking of a move to something else like management. Rust came along 6 yeas ago (for me) and threw me a lifeline. I love getting good at something that is hard, it’s just very satisfying. I do get why some people can’t stand the language. It is ugly to look at with its genetics and lifetime annotations and when a project is so large that it begins to lag rust-analyser then my joy turns to rage too.
Maybe it wouldn't be reasonable to say this about people who dislike programming in Malbolge, and maybe there are aspects of Rust that are more like programming in Malbolge and less like the field advancing.
"despite the GC" and "despite the unsafety" is really putting a lot of weight on that "despite"These are massive problems
I don't think it's so cut and dry. For lots of usecases, using Rust involves writing everything from scratch, because the only libraries available pull in an opinionated async runtime and feel entitled to call the global allocator and various syscalls at times the user cannot control, and these components cannot be swapped out because of fundamental issues that prevent Rust libraries from being composable (unless they go out of their way to adopt a feature that launched late last year?). IME there are relatively few usecases where long stalls due to GC are bad but long stalls due to page faults or open(2) taking a couple seconds to return are fine.
You're replying to me as if the comment was in a vacuumIt's responding to:> complexity just for the sake of it,> lots of pain for minimal gain> If you need async/await you'll do better in modern .NET despite the GC> if you need the highest CPU performance you'll do better in C++ despite the unsafetyTo this I respond, GC is such a massive problem (I guess you can fill in "for some categories of problems" but I think it's obvious) that some people need to avoid it. And those people often turn to C++, where the "unsafety" is a very big problem.
I don't think so? My reply is that if you can't afford to stall for a really long time, like dozens of frames at 60hz at least, then your choices are often to deal with unsafety in C++, to deal with the GC in .NET, or to write everything from scratch in Rust (including many things for which you would typically use libraries) because idiomatic Rust and the associated ecosystem won't solve your tail latency issues. The last option is not obviously more attractive than the approach of working really hard to not make garbage that Unity devs are usually forced into after years of development when they start testing on Switch.
You can deal with that in .NET the "C++" way too, given that you can write abstractions with structs and generics instead of objects, use malloc and stackalloc, and more. You are not married to GC heap, despite some suggesting otherwise.Generally speaking 60hz is not a problem but it starts to matter more with the popularity of high refresh rates. There are much more extreme cases like 1000hz game loop in OSU!, which pretty much has to use the same techniques as realtime systems that utilize GC-based language:https://github.com/dotnet/runtime/issues/96213#issuecomment-...
That depends a lot on the domain of the code.. just saying they are massive problems is plain wrong. There is a huge percentage of applications that need not care about GC at all.
>the syntax. It’s ugly. [...] I would prefer something that is less sigil-heavy.That's also one of my gripes with Rust. Very sigil heavy makes it hard to google syntax elements. What's the name of the `|` glyph? Especially challenging if you know the name of the glyphs in your language but not in necessarily in english. Double challenging for glyphs with several accepted namesBut in the end, I'm big enough to realize that this is not a very important aspect of the languageIf it's ugly so be it. I'll still learn itAlso for once Bing Copilot pretty much solved this for me since unlike google search, it's semantic + it doesn't ignore special characters
FYI Wikipedia has pages for every ascii character I think, if you just search for `|` in wikipedia it would redirect you tohttps://en.wikipedia.org/wiki/Vertical_barWhich lists all the common names used for this symbolHere is also a table with all symbols with direct links to the wikipedia pageshttps://en.wikipedia.org/wiki/ASCII#Character_set
This might be usefulhttps://doc.rust-lang.org/reference/tokens.html#punctuation
That doesn't seem to explain 'lifetimes or turbo::<Fish>, though.
The page linked for :: explains the turbofish.That said, you're right that it could use a row for the lifetime syntax.
If you know where to look, you will find it. If you don't, you don't.For someone new to Rust, I don't see why you'd expect them to expect to see a "path separator" between the function name and it's call in x.collect::<Vec<_>>(). A more likely path to discovery is via the Generics link (discovered from "<" being so prominent there), which shows the ::<> syntax in context of const values, and that isn't actually very helpful for understanding.
So the thing is, the link provided is not really intended to be "teach me what syntax means." It is meant to provide a reference for various tokens. And it does that, because the turbofish isn't a single thing, it's a combination of two things.If the goal of this page was "comprehensively explain Rust syntax to someone who doesn't know Rust," I would agree with you. But it's "produce a spec-like document for experts who want fine-grained details about the language."
I just cloned the Starship repo and cargo --release built it and it took six minutes and 30 seconds (which did feel interminable). The author says it takes him 15 minutes "for building just the main.rs", 10 minutes for "lib.rs" and an unspecified time for "everything else".My CPU is from2012. What on earth is he doing this on, a TI-83? Or am I missing some intricacy of whatever Gentoo is doing that would inherently inflate build times by an order of magnitude?
> The author says it takes him 15 minutes "for building just the main.rs", 10 minutes for "lib.rs" and an unspecified time for "everything else".That's weird, cargo displays the current crates under compilation, not files as that's not the compilation unit in Rust, the author seems to be fibbing.
$ emerge -v starship
    <...>
    Running `rustc --crate-name starship --edition=2021 src/lib.rs --error-format=json --json=diagnostic-rendered-ansi,artifacts,future-incompat --crate-type lib <etc>
    Running `rustc --crate-name starship --edition=2021 src/main.rs --error-format=json --json=diagnostic-rendered-ansi,artifacts,future-incompat --crate-type bin <etc>This person is using gentoo, gentoo does print it like that.
Just another data point. I cloned and ran `cargo build --release`. It took 2 mins and 2 seconds (M1 Pro, 2021).Just want to say, creating a release build is really unusual! You'd do that relatively rarely. Most of the time you'd create a debug build, which took 29.56 seconds on my machine for a clean build and 1.45 seconds for an incremental build with one line changed.I sympathise with the author's running on underpowered hardware, but it might not reflect the experience of the average Rust developer.
Rust doesn't playquiteas nicely with Gentoo's packaging system as C/C++, but yes, that seems excessively long.Then again, I'm fairly sure I have starship installed via `cargo install`, not via portage (Gentoo's packaging system).I'm a Rust and Gentoo lover :D
5m 39s here on a 2017 CPU: Intel(R) Pentium(R) CPU G4560T @ 2.90GHz
People complaining about Rust... As Bjarne Stroustrup says: "There are only two kinds of languages: the ones people complain about and the ones nobody uses"This is actually the kind signal I wanted to see. A language everyone likes isn't right. In production, programmers have to follow customer requirements, not the other way around, and customers don't care about your pretty code, they want their things to work, and at some point it is going to get ugly, and people will complain. As time goes on, there will be more and more of that ugly legacy code, and you have to keep it, because people are using it, and people will complain more, and they will blame everything that relates to it: the language, customers, management, previous devs, etc... It is actually a good thing, it means the language is used to do real work, you will never get these complains when all people do with it are toy projects or a few precise, programmer driven programs.
Worse is better in programming languages.  You decide "I'll use python because everyone else uses it" and then you waste a week of your life debugging when some asshole on your team has mutated a dict that you passed into a critical function and you didn't notice.
> First, the syntax. It’s ugly. TO MY EYES!Beauty is in the eye of the beholder, you can't please everyone and you should not exceed your weirdness budget[1].
The decision to please the C++ crowd so much (mainly manifested in later syntax related decisions) would not have been my preference, but it makes sense and there could have been worse decisions.> Second, Third, Fourth, FifthI feel a lot of this async criticism has more to do with how async is used than with Rust itself. Maybe it would be good to have more crates that don't used async or even depend on tokio, but in the end this is on us as a community.> Sixth, Rust doesn’t go far enough in static analysis. Rust had a chance to go much further, and the team blew it.I am not qualified to judge that, but I am curious of other opinions.> Seventh, Rust compile times are a jokeTrue, but this is actively tackled on multiple fronts. One is cranelift, which I find highly fascinating.[1]https://steveklabnik.com/writing/the-language-strangeness-bu...
> I feel a lot of this async criticism has more to do with how async is used than with Rust itself. Maybe it would be good to have more crates that don't used async or even depend on tokio, but in the end this is on us as a community.No, this is a language design issue. In Lua or Zig the easy way to write a library that speaks websockets produces a library that works with synchronous or asynchronous i/o and with the user's choice of read and write primitives. In Rust, after many years of unnecessary suffering, we finally have the ability to ship one library that can use either kind of i/o.... unless the user wants to use both in the same workspace, in which case they are screwed. You may enjoy this tale of a user trying to get Rust to do what Lua and Zig do by default, for a single library:https://nullderef.com/blog/rust-async-sync/
This is being worked on:https://blog.rust-lang.org/inside-rust/2022/07/27/keyword-ge...
This looks great! The example in the linked post directly addresses the obvious follow-up of "well, what about for functions that use traits that are currently divided into two or more flavors?". I hope it progresses to an RFC and code sometime!
The post is a bit of a rant and all over the place. Async infecting everything, ugly syntax (who cares?), slow compile times etc.What stood out to me:> In other words, if compilation is fast, the tooling is easy.Andrew Kelley said something similar in a recent talk. Compiler performance seems to be the number one priority at the moment for Zig.The rationale seems to be: fast compilation leads to more productivity, which leads to more bugfixes.This claim seems almost bruteish, but it makes sense.Tight feedback loops (think things like devops, REPL, TDD, light processes etc.) can help us to iterate more and stay in the zone.To be fair a sophisticated type checker like Rust‘s also helps with that.But of course any added friction and sluggishness can be an indirect hindrance to the overall correctness and even performance of a program.
Fast compilation is nice and I believe stuff like incremental compilation are essential.But at the end of the day I'll prefer slower compilation every time if it means advanced checking.And speaking of the zone I prefer writing Scala code for like 1h while fixing compiler errors and then you run and it just works TM vs Java where you'll waste your time tracking NPE ...
> But at the end of the day I'll prefer slower compilation every time if it means advanced checking.I don't think that's a large issue in Rust. Type checking is quite fast in comparison to code generation.Generics, traits, macros etc. seem to be the culprit. Turning complex language features into code and not runtime safety lead to these slow compile times.
>  ugly syntax (who cares?)I'm a nobody of course, but I do. Ugly is subjective, and by "ugly" a lot of people probably think "alien", as not what they are used to. Less syntax cruft is good for cognitive load and more common syntax is good for adoption.But I'm sure the problem fades away with practice.
> The rationale seems to be: fast compilation leads to more productivity, which leads to more bugfixes.Sure, but add LLVM to the mix and you get a slow ass compilation time even in Zig (See Zig filing divorce from LLVMhttps://github.com/ziglang/zig/issues/16270). Granted, LLVM isn't the only thing to blame. Rust has its own share of problems stemming from monomorphisation, and macros, type check seems to be not as big of a culprit. Although, that depends on the project.Being fast to compile, versus being efficient to optimize seems to be the trade-off here.
> ugly syntax (who cares?)Code is meant to be read, so a lot of people care actually.Sure it's not the only thing that contributes to the usefulness and appeal of a language, but reading code is still one of the two main things we do with it so it's quite important to nail the syntax right.
Yes, but readable and beautiful are two very different qualities.Rust is a wolf in sheep’s clothing. It looks like C syntax but largely expression based like functional languages. It also has a lot of syntax.It is readable with little effort for most because of it. But the trade off is ugliness.
The post doesn't seem to mention certain parts of the community, which is basically my main issue with Rust.You can't even mention that bootstrapping the compiler is a process that's way too convoluted, because you get buried to oblivion ("why would you need that"). Thankfully there are some already, though incomplete because (I'm guessing) Rust being mostly defined as "whatever rustc outputs" doesn't help reduce the pain of checking if your implementation is correct. I appreciate the efforts that are going on to write informal non-spec documentation about the language though, better than nothing.Also can't mention that alternative compilers would be nice (e.g. to make bootstraping easier, see previous point), because you also get buried to oblivion ("don't fragment the ecosystem", "the Rust council/teams/etc will always be composed of trustworthy people now and forever").Like, yes, but chill a bit and try to consider other use cases instead of reading those topics as attacks to the language just because you think you don't need them. A small minority being very loud in rejecting any attempt at healthy discussion is not good optics for the ecosystem.This stuff also happens with other languages' communities, but somehow I seem to find them happening a lot more frequently with Rust.(P.S.: Changing the topic a bit, I'll invoke Cunningham's Law and say there's no easy way to read Rust documentation offline that doesn't require a web browser of some kind or parsing HTML output. Some equivalent to `go doc` or Python's `help()` function.)
> The post doesn't seem to mention certain parts of the community, which is basically my main issue with Rust.Mine too, but my post implied it, and it was already too ranty.
I'll bite: What specific parts of rust syntax do people find so ugly?I keep hearing this from decent chunks of people who don't write rust, but the language doesn't seem that far off C to me. It's certainly no haskell.
From what I've asked people, the complaints fall mainly into two categories:* familiarity and aesthetics. Rust uses fewer round () parens, and more <> and {}. This makes it look alien, and people say it's unreadable when they don't immediately recognize the language constructs they know.* misattributing difficulty of learning Rust concepts like lifetimes and generics to their syntax. People say they wantlesssyntax, but they mean they don't want to explicitly specify  things like ownership and trait bounds.
The more interesting follow up question is: "How would you express the same semantics with a different syntax?" Too often discussions about Rust's ugly syntax lack this crucial component.
> How would you express the same semantics with a different syntax?This isn't the problem, the problem is "... and keep the syntax C++-like?".
Is it? I don't know if keeping Rust's syntax C++-like is a stated goal of the project, but okay sure we can add that caveat to my question.The big problem I see is that people will say "Lifetime annotations are ugly and noisy" and when pressed on the issue will eventually concede that they just want GC(which is not about syntax, but semantics)
It was a goal, though lower priority than other goals. You can see this in the way Rust is largely “curly braces and semicolons” but at times when there’s good reasons it diverged from that, like the ML style let syntax.
> I don't know if keeping Rust's syntax C++-like is a stated goal of the projectThey won't change the syntax, the whole discussion is hypothetically anyway. 
What I wanted to express is that most people want a C++-style syntax (of generics), even if they complain about Rust's syntax.
I say this as a Rust enjoyer, but I think what most people mean when they say this is that there's a lot going on, especially in the function definition syntax. When you start adding in lifetimes and generics with bounds, async, &muts, where clauses... it really does become unreadable. I don't really see a way to fix this without making the syntax even more verbose, or aggressively simplifying the type system to the point that function argument inference becomes viable, but then you might end up in a situation like Swift's where type checking a simple expression takes an excessively long time.That and the colon-colons (::), probably. Those can add a lot of noise.
I suspect the colon-colons were a mistake. Java uses periods for both modules and classes, and it doesn't seem to be a problem there.Lifetimes are really ugly. You usually don't need to write them explicitly, but that's not a real excuse.
https://web.archive.org/web/20230713231438/http://bash.org/?...< Andys> oh dear
  < Andys> in ruby, symbols are represented with a prepended colon
  < Andys> eg.   :flag
  < Andys> so some guy tshirt that said ":sex"
  < Andys> which everyone at railscamp knew meant "Sex symbol"
  < Andys> he wore it until someone pointed out that to non-rubyists it said "Colon sex"
Paamayim Nekudotayim anyone (https://en.wikipedia.org/wiki/Scope_resolution_operator#PHP) ?
I think it's not that much the specific parts as it is the combination of (sometimes obscure) symbols forming dense blocks of sigils that you have to carefully pick apart to understand what the code is doing. It's easier to reason about code if it uses words instead of symbols, and Rust seems to desperately want to avoid using actual words (I don't count "fn" as a word, and "pub"isa word, but for me it's somewhere where you go to have a drink after work). Ok, I know there is a long tradition of doing this in C-family languages, but Rust has driven it to new heights, and it hasa lotmore concepts (with their attached symbols) that you have to keep in your head.
I hate the unpronounceable sigils of languages like Haskell, but C-style abbreviations don't really bother me somehow. The abbreviations help you remember what the words are, at least, and for me this seems to be enough.
>I keep hearing this from decent chunks of people who don't write rustThat's exactly the people you want to hear from if you're trying to improve adoption.
Here's my litmus test: read the source aloud. Over the phone to a person who doesn't see your screen, if needed. Did you have an obvious, understandable, and simple pronunciation for everything, that wasn't just reading ASCII characters one by one?Now pretend the other person is a smart and experienced programmer, but has never heard of Rust. How would they write down what you just told them, without any idea of Rust's syntax? That's the non-ugly version of Rust.
function max with type parameter T
    with arguments
    a of type T and b of type T
    and returns a value of type T
    where T implements trait PartialEqVsfn max<T>(a: T, b: T) -> T where T: PartialEq
Limiting examples to a subset of Rust syntax will produce more readable answers, sure. You have no lifetimes and no borrows, and very limited generics.
The information density of the "human syntax" Rust syntax both remain linear in size, but with a significant different N.function max
    with
        a lifetime a,
        a lifetime b,
        and type parameter T
    with
        argument a of a reference to type T that lives as long as lifetime a
        argument b of a reference to type T that lives as long as lifetime b
    and returns a value of type parameter T
    where T implements trait PartialEqVsfn max<'a, 'b, T: PartialEq>(a: &'a T, b: &'b T) -> TIf you want a real life example:#[stable(feature = "rust1", since = "1.0.0")]
    impl<'a, T, A: Allocator> IntoIterator for &'a Vec<T, A> {
        type Item = &'a T;
        type IntoIter = slice::Iter<'a, T>;

        fn into_iter(self) -> Self::IntoIter {
            self.iter()
        }
    }


    An implementation of trait IntoIterator
    (that has been stable since Rust 1.0.0)
    with a lifetime a
        a type parameter T
        a type parameter A which implements the trait Allocator
    for a borrow for the duration of lifetime a of type Vec with type parameters T and A
    
        it has an associated type Item, which is a borrow for the duration of lifetime a of type T
        it has an associated type IntoIter, which is type Iter from module slice with parameters lifetime a and type T

        it has a method into_iter
            that consumes the receiver
            and returns associated type IntoIter
            
            the methods body
            calls method iter on the receiver
            and returns its resulting value
I'm not arguing that complex things will somehow become non-complex.However, none of the human syntax of Rust includes things like :: or '. To a first approximation[1], those are the parts that peoplecanexperience as "ugly", and they are not present in the human syntax. This is what people mean when they say "sigil heavy" or "punctuation based" syntax -- things that are generally are not read out as such. This is the space where you can make arguments about beauty.[1]: Only roughly so because your chosen human syntax still encodes some Rust syntax decisions like predeclaring generic lifetimes and types, and using "where" instead of an inline clause. Those parts of syntax can also be shuffled around for subjective values of "not ugly".
Lifetime bounds on a trait object argument can be confusing.I have to look up how to write the where part properly every single time.
Fishtail, lifetime and closure syntaxes are rather ugly. Just specifically when combined in practice, not alone in isolated examples.
For what is worth, the turbo fish falls from the decision to use <> for generics (for familiarity for  C++ and Java developers) and a desire to make the syntax non-ambiguous (side stepping the C++ problem of having to delay determining if something is a type path or a comparison, mixing parsing and name resolution).
This argument is always so divided into very thoroughly mine-protected trenches it’s insane.The anti-rust crowd treat the language like it has more boilerplate than JavaScript and that it’s the most complex language out there while offering no benefits, which just isn’t true. It’s a great language with a lot of features that are huge advantages over C/C++.The rust evangelists treat it like it’s the second coming and that you’re literally killing babies if you aren’t letting the language enforce its paradigms on you. The forced safety the language offers is a great feature in 2024, but it is not a be all end all thing - there are plenty places where it just isn’t necessary and creates more work for the programmer. The argument is also usually “everything should be rust” but the moment you point out a use case where its advantages don’t matter, they say “well the rewrites only need to happen for <x critical direct networked service>” - that then means everything doesn’t need to be rust, no?Like most things, the correct path is somewhere in the middle. I personally don’t like Rust’s syntax, generics, not being object oriented, etc - but that’s just my opinion and is no more valid or invalid than the next. At the end of the day, use the language you like most and are comfortable with, as long as you understand the benefits and drawbacks of each.- Signed, a Kotlin evangelist
Within Rust is a smaller, simpler, safer language struggling to get out
Without a GC? No there is not. You are welcome to try of course, but unless you have a PhD in type theory I doubt your chances.
Author here.Yao is already fully designed. And while I haven't updated its example file [1] to include everything, it would only be a max of two or three times bigger.This includes generics, an equivalent to Zig comptime, something like traits but more powerful, a solution to the expression problem, etc.The solution is structured concurrency.The only reason I am not working more on Yao is because I worked on it for three years at full tilt (because I constantly refactor to eliminate tech debt), and I am burned out.But adding a new feature takes only about two hours max; I just add a new client-defined keyword.[1]:https://git.yzena.com/Yzena/Yc/src/branch/master/src/yao/exa...
There's a smaller, simpler, safer language lying in Rust called "Rust without async", which would be good enough for the 99% of use-cases that don't need absolute-lowest-possible-latency async.
No one is forcing anyone to use async though. It is an entirely optional part of the language.But it is naive to think that not using it is an easier path towards a solution.
YMMV, but Austral-lang (https://austral-lang.org/) comes quite close to what I want out of a smaller, simpler, safer Rust.Its syntax is inspired by Ada, and as far as I know the designer has no PhD in type theory, so it matches the requirements put forth by the other commenters too.
Readable would be a nice benefit.
Not sure about smaller or simpler, but Ada is definitely more readable in my opinion.
Two things:- It was made to be approachable for C++ experts- The idea was that language could be effortlessly greppable.
Coming from C++, and I would have loved Rust tonotpick up C++-y things to make it look like it...
So legacy baggage from the get go. This is what I'm lamenting, it's objectively a syntax soup.
This is my current mental model for picking a language, considering just the language itself:- Backends: Gleam or other BEAM- Web frontend: Gleam- Mobile apps: Dart + Flutter- Specialized mobile apps: Swift and Kotlin- Blazing fast: Zig- Blazing fast and safest: Rust- Fast performance and iteration: GoWould love to hear additions and corrections.My only problem with this is I'm not a fan of Go's syntax and I wonder what's a good alternative. Heared good things about OCaml but didn't check it out yet.
OCaml could almost replace all of those. I don’t think there is a BEAM compiler backend yet.I’m not very experienced with BEAM, but could its features be delivered with a framework on top of a different stack? I know Akka is popular.
The OCaml backend for the BEAM was called Caramel but has been abandoned after his author went on working on hiw own build system, warp.
Build systems come for our best and brightest. :-(Talk to your friends and family.
Actor model is a small component of the BEAM. Even then, itguaranteesyields to the scheduler.This is practically impossible to retrofit on to an existing language, esp. in the presence of loops.
GC precludes OCaml from replacing a chunk of those.
>>> don’t think there is a BEAM compiler backend yetI think there's something close -https://caramel.run/manual/
The project has been abandonned :https://github.com/leostera/caramel/discussions/102
I’m super into elixir now and don’t see myself going anywhere else. Is gleam really that good? What are the advantages? Can I use liveview with it?
As far as I know Gleam is the only strongly typed language on BEAM, which is important to me since I don't like dynamically typed languages.
But of course Elixir gets optional types now.
There is also:Purerl - Erlang backend for PureScript, a few folks are using this in production -https://github.com/purerl/purerlCaramel - Ocaml for Beam, seems dead -https://github.com/leostera/carameland more probably dead projects athttps://github.com/llaisdy/beam_languages
Is that the only difference?
It can also compile to JavaScript (instead of the BEAM) so you can use the same language for backend and frontend work.
- Backends: Kotlin (on JVM)- Web frontend: TypeScript (maybe Gleam in the future!?)- Fast performance and iteration if I want a binary: Kotlin (native compiled)- Blazingly fast and good for WASM: Rust- languages that I keep an eye on: Gleam, Zig, Odin- languages that I will never touch: C, C++- languages that I think are quaint: OCamel, Lisp, Haskel- languages that I have used in the past and that are fine: Dart- languages that I have used in the past and that are ok: Java (if it had nullability, it'd be fine)
I love Kotlin, but don't want to use IntelliJ, and they obviously have strong financial incentives against supporting other IDEs. Has anything changed in this regard?I appreciate their work on native/wasm, and I think it's great if they could be financially rewarded/sponsored for that work. It's just unfortunate that it has to be in the shape of an IDE dependency.
Nim fits a lot of Go's use cases. It is way more niche though.
I have seen a lot of criticism of async Rust.In C# most APIs expose both sync and async versions of the same methods. Why is that not more common in Rust?Sure some 3rd party C# libraries probably do some ugly sync to async conversion internally but most don't and use the .NET standard libraries sync/async versions of the same APIs.
Rust's async is in some places more difficult to use, because Rust is obsessed with avoiding allocations and dynamic dispatch.Languages like C# and JS allocate a new object for every Promise and every listener. Rust bends backwards to avoid that, and make inlined strongly typed state machines instead. It creates limitations where you wouldn't expect, e.g. recursive calls need special handling, and abstract interfaces don't fully support async.As for supporting both, it's just inconvenient to do, because many small syntactic and semantic differences mean it's hard to automate and cumbersome to maintain.
Not every await and new task produces an allocation in C#: ValueTask only allocates a state machine box if it yields asynchronously, plain task objects are pooled for common values and state machine box itself can also be pooled for frequently called methods (is opt-in), for example socket.SendAsync does not allocate thanks to this.This will change further as "Runtime Handled Tasks" implementation comes along which will replace Roslyn-generated explicit state-machine code with runtime-provided suspension mechanism which will only yield/suspend the execution at true yield points, with further improvements to how the captured state that needs to persist across them is stored.
Maybe that will sound banal to some but C would be so much more enjoyable to me if it had a "cargo" system and no implicit imports.
That's the problem with C. It cannot have a sane cargo like system. The language is not built for writing libraries. There is a reason why everyone keeps reinventing the wheel when it comes to datastructures in C. Where is STL for C?
The closest is GLib and it's absolutely not fun to work with.
you could use the Zig build system as your C build system. Seehttps://zig.news/kristoff/make-zig-your-c-c-build-system-28g...
Cargo is just half the story. The other half is rust itself. It is an excellent language for writing abstractions.
That's why i like zig it has at least the very basic with build.zig for build script. You have build.zig.zon for build.zig dependencies.
I mostly agree. Compile times are the worst in the industry, and async is a mess.
Rust is a systems programming language. It forces you to think about computer architecture as you are writing code. The language is a tool expressing how logic should execute safely and performantly on actual hardware. That is both its strength and weakness.I agree with the article in so far as the hope that people will not start pushing Rust as the cool language for pretty much everything.For many development endeavors, the language is a tool purely for expressing logic, and for that Rust is a poor choice IMO.
What does Yao look like?
edit ah I found some exampleshttps://rigbuild.dev/yao-tutorial/
You can also look at the example file.[1]:https://git.yzena.com/Yzena/Yc/src/branch/master/src/yao/exa...
"I like small programs with few dependencies. I will write my own I/O to avoid dependencies. And tokio is to dependencies what god objects are to object-oriented programming."This is what is preventing me from using Rust.  It is so tightly integrated with a package manager for libraries that trying to avoid crates.io and dependencies is like paddling against the current.
@gavinhoward Just FYI, a couple of links in the article are broken:* The "incomplete list" of C UB currently points to the Rust spec vision* The link labelled "unreasonable programming language" currently points to the Gentoo Wikipedia page* The "Starship" link points to the House Wiki page on Vicodin
Ack! That is what I get for writing a post quickly while drunk on sleep fatigue late at night.And the rantiness comes as a side effect of that.Fixed, Thank you!
The compile times are the only real issue mentioned here.I still think it's better than C++ but for large projects the compile times and crate splitting, etc. become a real pain.
Not to author: The URL for the "incomplete list" hyperlink is incorrect.
Ack! Thank you, fixed.
A lot of this author's complaints about Rust remind me of similar historical complaints about C++, but amplified.Hijacking and overtaking new projects? C++ and Rust both do that. C++'s compile times were a joke, Rust is even worse. Complex semantics and syntax? Both have those. Rust is trying to be everything to everyone? C++ has always been criticised as design by committee.And yet C still exists and is widely used. Once the smoke cleared, people simply hated C++ and what it brought. After all was said and done, C became regarded as much more tolerable and usable for lack of those headaches. C++ still exists and there is certainly not a C++ monoculture. I hope and expect that the same story will play out for Rust.
Do you mean that once the Rust smoke clears, people will see C++ as much more tolerable and usable? :')
What are some examples of the complex semantics? The things I can think of(lifetimes, generics, traits) exist and are modelled in C too, but just with less(or no) support from the language and compiler.
At least, compiling is always straightforward. With C, there's a good chance the build will fail for whatever reason (e.g. your OS missing some header files).
Yep, IME rust makes contribution easier because I generally don’t need to hunt for setup instructions which may or may not existandmay or may not work for my system.And the compiler at least attempts to tell me what’s wrong when it fails to compile (and give suggestion though that is very hit or miss for non trivial case).The one case where the compiler is singularly unhelpful is when trying to hunt down why a future is !Send tho.
I feel like you could stand to qualify "fun" more here. I don't share your experience - I'll take a Rust project any day - but I'm curious to know what you feel is missing.(Outside of compile times, which are a well known point)
There’s no reason you couldn’t have a rust jit for development then compile the code for production (or stick with a jit for prod too).
There's no reason? Are you sure about this?I think you mean there could theoretically be an interpreted Rust, but I don't think anyone has ever made a prototype of a Rust interpreter.The closest is probably rust-analyzer (the official language server), that maintains internal state and reacts to changes you make, but it doesn't create an executable artifact.The other is probably the Cranelift Backend (https://github.com/rust-lang/rustc_codegen_cranelift), which can produce debug builds quickly.
I meant no reason from a technical point of view. People might say most of the compilation time is spent in the type/borrow checker, but that's orthogonal. You can JIT potentially incorrect code and postpone static checks for a later time (or run them in parallel).
The cranelift backend itself has a JIT mode.
Honestly it would probably be even faster than unoptimized aot compolation
Some developers need/are used to a fast edit-compile-run loop. The JIT doesn't even need to be optimized, just good enough to improve the developer experience.
What were you waiting on? You shouldn't have run cargo build every change. And cargo check shouldn't take that long.
This is a sort of odd phenomenon, but I've noticed that the Rust software I'm developing professionally is never actually getting run before it's pushed to production. We have some unit tests and run those, and if that's fine then into prod it goes. It's honestly a bit insane when I think about it, but it works...
cargo check will take long once you use macros. 
And now the advice changes to 
"well you shouldnt use that many macros", and a new criticism will be made, followed by "well you shouldnt....." and a new...I dont think this wont even work for most kind of programming. I always do an edit-compile-run cycle when im programming, or I break everything to .so and dynamically reload as much as possible. Very easy with C++ and C.I am waiting on zig and its in place binary patching.
But just saying that you should cargo check instead of running and seeing with your eyes if your change made sense or not or is affecting perf or not is....ridiculous.I think this kind of development flow works better when you are writing already solved solutions or rewriting code. How on earth are you gonna cargo check a perf issue, or a game or memory leaks???
The fact that i got downvoted says it all, people are in delusional modeZig devs are tackling the issue early, Rust devs are living with it, it's just sad
adding to this,  People that say cargo check is the answer dont even understand the problem at hand.Just because the language is compiled does not mean it needs to take 30 business days to compile something.You can have fast compile times and good performance too. SBCL the common lisp implementation is extremely famous in these circles for its performance. IT IS A BATCH COMPILED LANGUAGE WITH A REPL!!You cannot use cargo check for perf issues, for memory leaks, for trying to solve a problem that does not have a solution...etc etc.Even then cargo check will make you bleed if you use macros.
I wrote a lot of rust, but after some years it still feels unproductive. I do a lot of zig now and I am like 10 times more productive with it. I can just concentrate on what I want to code and I never have to wonder what tool or what library to use.I know rust gives memory safety and how important that is, but the ergonomic is really bad. Every time I write some rust I feel limited. I always have to search libraries and how to do things. I cannot just "type the code".Also the type system can get out of control, it can be very hard to actually know what method you can call on a struct.I still think rust is a great tool, and that it solves tons of problem. But I do not think it is a good general purpose language.
> but the ergonomic is really bad. Every time I write some rust I feel limited.> But I do not think it is a good general purpose language.Remember that this is not a sentiment that's shared by everyone. I use Rust for tasks that need anything more complicated than a shell script. Even my window manager is controlled from a Rust program. I say this as someone who has been programming in Python for nearly two decades now. At this point, I'm about as fast in Rust as I am in Python.
I tried to get into rust for many years, I'm now in a C/CPP job (after Java/Python/Ruby and other gigs). What I've come to understand is that Rust's lifetime model is very difficult to work with whenever you have a cyclic reference. In C/CPP the same holds, but you deal with it through clever coding - or ignoring the problem and cleaning up memory later. Java, and other GC'd languages just work for these structures.While the Rust devs believe such cyclic references are rare - I think this speaks mostly to the problem domain they are focused on. Relational models are everywhere in Apps, they are often common in complex systems software like databases, and they are fairly rare in firmware/drivers/system code code.There are a few patterns for dealing with cyclic references, but they all end up requiring either unsafe or a main "owner" object which you clean up occassionally (effectively arena allocation). Having now worked in C/CPP - the idea of having unsafe blocks sprinkled around the code doesn't bother me, and many C/CPP components have some form of arena allocation built-in. I just wish Rust learning resources would be more upfront about this.
> Relational models are everywhere in Apps, they are often common in complex systems software like databases, and they are fairly rare in firmware/drivers/system code code.It's not like that you can't write relational models in the safe Rust. The only forbidden thing is a reference pointing arbitrary memory, which is typically worked around via indices and often more performant in that way. It is much rarer to find applications that need an absolutely random pointer that can't be hidden in abstractions in my opinion.
> I just wish Rust learning resources would be more upfront about this.While beginner resources don't dwell too much upon cyclic references, they don't consider unsafe blocks as unusual. All the material I've seen say that there are certain domains where Rust's compile-time safety model simply won't work. What Rust allows you to do instead, is to limit the scope of unsafe blocks. However, the beginner material often won't give you too much details on how to analyze and decide on these compromises.Anyway, compile-time safety checks (using borrow checker) and manual safety checks (using unsafe) aren't the only way to deal with safety. Cyclic references can be dealt with runtime safety checks too - like Rc and Weak.
> Cyclic references can be dealt with runtime safety checks too - like Rc and Weak.Indeed. Starting out with code sprinkled with Rc, Weak, RefCell, etc is perfectly fine and performance will probably not be worse than in any other safe languages. And if you do this, Rust is pretty close to those languages in ease of use for what are otherwise complex topics in Rust.A good reference for different approaches is Learn Rust With Entirely Too Many Linked Listshttps://rust-unofficial.github.io/too-many-lists/
Also, take a look at GhostCell (https://plv.mpi-sws.org/rustbelt/ghostcell/andhttps://www.youtube.com/watch?v=jIbubw86p0M). If anyone's used this in a project or production environment, I'd love to hear your firsthand experiences and insights.
Except in those other languages the compiler types .clone() for me.
Sometimes the compiler types clone for you even you don’t actually want it to.
It is easier to tell it, "don't do it this time" than all the time.It is no accident that while Val/Hylo, Chapel and Swift have taken inspiration from Rust, they have decided to not inflict the affine types directly into the language users, rather let the compiler do part of the work itself.
You still need a main owner in those patterns, that owner must be part of a DAG of owners - you cannot have cyclic ownership.
Oh I just put up a blog post about this on Monday :)https://jacko.io/object_soup.htmlAgreed that I wish more beginner Rust books had a section about this. The pattern is quite simple, but it's hard for beginners who get stuck to realize that they need it.
I would have needed this when I started learning Rust! All my early programs were object soups.
> While the Rust devs believe such cyclic references are rare -They are.I have not had to use cyclic references ever, except once doing experiments with fully connected graphs, that was very unusualIf you're doing a lot cyclic references Rust is not the right choice. Horses for coursesBut are you sure you're using the best algorithm?
Maybe for you it's unusual - in my previous work all the apps contained graphs, and I just joined a company where almost all the apps also contain graphs
I don't write Rust, but I never understood why graphs meant you need circular references.Doesn't it just come down to the question of who owns the node?If it's a tree, and parents are never removed before children, just make the child owned by the parent and keep a weak reference to the parent.If it's a general graph, and vertices can exist or not exist regardless of edges, keep a list of them independent of the edges, and keep weak references in the edges.If it's a graph where a one or a few roots exist, and nodes exist as long as there's a path from a root node to them, that sounds like a classic use case for Rc<>.Is there a common use case I'm missing?
Things get tricky when you have a valid triangular relationship amongst equal objects. This comes up far more often than you’d expect.
Can you give an example?
What's a frequently encountered case for such cyclic loops?  Without details I'm drawn to trying to break the cycle, either by promoting the shared state to a container object for the set, or by breaking it out into it's own object that multiple things can point at.
I think a game is a good example, or anything that's kind of like a game in that it's modeling a world that's changing over time. Objects come and go, and they "target" each other or "require" each other or whatever sort of relationships the program wants to express. Those relationships end up forming a graph that might contain cycles.Ijustput up a blog post about this actually :)https://jacko.io/object_soup.html> promoting the shared state to a container object for the setYeah I think that's a good way to describe these "ECS-ish" patterns.
a parent field.a doubly linked list
Your parent said "frequently encountered" and while it's probably true that doubly linked lists may be "frequently encountered" in some people's code they're usually a bad idea and "don't use a list here" is often the right fix, not "conjure a way to make that safe in Rust".It's very noticeable how often people who "need" a linked list actually only wanted a queue (thus Rust's VecDeque) or even a growable array (ie Vec).Aria has a long list of excuses people offer for their linked lists, as well as her discussion of the time before Rust 1.0 when she sent lots of Rust's standard library collections to that farm up-state but wasn't able to send LinkedList.https://rust-unofficial.github.io/too-many-lists/
Doubly-linked list is something you have almost no reason to ever write.Parent field is something where you have a clear hierarchy (it's not really “cyclic”, so it's the perfect use-case for weak references).When coming from a managed-memory language, this obviously requires some conceptual effort to understand why this is a problem at all and how to deal with it, but when compared to C or C++, the situation is much better in Rust.
That's assuming you traverse the tree down from the root each time. Often you do, but there are cases where you don't -- e.g., if your goal is to determine the lowest common ancestor of two given nodes.
ASTs
An abstract syntaxtreecan't have cycles by definition.
Technically true, but sometimes you want parent pointers. You then have a more general graph in the underlying representation, but it still represents a tree structure.
Same shows up in Postgres Query* struct for SQL. Copying memory between parser, planner, execution would be too expensive in large queries - so instead you have an arena allocated representation.
ASTs are one of "nicely behaving" data structures. It is like a archetype of abstract data types pervasive in functional programming languages.
An Abstract Syntax Tree / or Double-Linked List both qualify, but they're also a lower level implementation detail than I'd expect to frequently interact with in a reference safety focused language.I've still been meaning to write something in / learn Rust's ways of thinking; is there not an intended replacement for these data structures?  Or do they expect it all to go under Unsafe?
> is there not an intended replacement for these data structures? Or do they expect it all to go under Unsafe?For linked-lists, there's one in std and the majority of people should never have to write their own as it's error prone and requires unsafe.For graph use-case then you can either use ECS, arena, ref counting or unsafe, but you're probably better off using/developing a dedicated crate that optimizes it and abstract it away behind an easy to use (and safe) interface.
The one in std uses unsafe. My main concern with learning rust is that you can spend ages trying to learn “the right way” of doing things in rust, when the right way really is to use unsafe.
No, the right way is to use unsafe primitives that have been tested, audited or even formally proven (like the ones in std).Sometimes such a primitive doesn't exist and you should use unsafe yourself, but then you're the one supposed to make sure that your code is in fact sound. If you keep unsafe for small portions of the code you can reason about and extensively test so Miri gives you a good level of confidence, then it's fine to use unsafe. But it's the more expensive option, not the default.
You usually solve this by using a traversal helper that keeps the stack and next/prev for you without storing them inside the AST explicitly.
Surprisingly, I am faster in Rust than any other language. Something about my prior experiences just made it click just the right way.I don't want to program in anything else anymore. I don't want to deal with obscure C++ error messages, C footguns and lack of ergonomics, I don't want to deal with abstraction hell of Java, or the poor person's typing that python has.I have been programming in Python for the past 6 years, I know all sorts of obscure details, and with rust, I just don't need to think about all of those issues.
> Surprisingly, I am faster in Rust than any other language.Not really surprising, given that you have C and C++ background. That's what I was trying to highlight.Rust isn't a confusing or unproductive languageas many project it to be - if you have the conceptual understanding of what happens on the hardware. Especially about stack frames and RAII. If you know those, the borrow checker complaints will immediately make sense and you will know how to resolve them.Add rust-analyzer (Rust's language server) to it, you get real-time type annotations and a way to match types correctly in the first attempt. In my experience Rust also helps structure your program correctly and saves a ton of time in debugging. All in all, Rust is a fast way to write correct programs.
> Rust isn't a confusing or unproductive language as many project it to be - if you have the conceptual understanding of what happens on the hardware. Especially about stack frames and RAII. If you know those, the borrow checker complaints will immediately make sense and you will know how to resolve them.I have reasonable understanding of "what happens on the hardware" (been writing kernel code for years), know modern C++ (with RAII and stuff) and Rust is confusing and unproductive language for me.
I get the feeling that learning rust can be a "bang your head against it until you get an 'aha' moment" sort of affair, much like learning git.Some people pick up rust quickly because it clicks into their brain early, some take longer or end up bouncing off.
I had university courses on computer architecture and assembly, even before I took up Python as a hobby. I did have a little C experience before that. My entire perspective on Rust type system from day 1 (back in 2013, before Rust 1.0) was based on the hardware (primarily stack frames) and problems I had with assembly and C. There was never a point where the borrow checker didn't make sense. This is why I insist that Rust isn't hard to understand if you learn the hardware on which it runs.Back then, people were debating the design decisions that led to the borrow checker, in public for everyone to see (on Reddit and IRC). They were trying to avoid memory safety issues in Firefox and Servo. They were even a bit surprised to discover that the borrow checker solved many concurrency bugs as well.
I took a different route to Goku (other commenter), I used to write a lot of C and C++ in university, did everything there, up until 2018-ish, I got a bit into rust and things just clicked, my understanding of memory was just not that good enough, and then my C skills skyrocketed as a consequence of learning proper memory management.Then I got into Haskell, and functional programming, that made thinking about traits, immutability, and all functional aspects a breeze.Then finally, I got into rust again, use it at work and personal projects. Somehow I managed to rewrite a project that took me 4 months in Python in about 4 days. It was faster, more robust, cleaner, and I could sleep at night.
I'd add that if you have some understanding of how memory ownership should be such that you don't end up with memory leaks, you are fine. The borrow checker just verifies that your mental model is correct, and removes some of the cognitive load from you.
>if you have some understanding of how memory ownershipWhat reading materials will help me level up my understanding of this?
My background is PHP, Python, and Go, and I have the same experience as GP
> At this point, I'm about as fast in Rust as I am in Python.This is factually impossible.For anything larger than (very) small programs, Rust requires an upfront design stage, due to ownership, that it's not required when developing in GC'ed languages.This is not even considering more local complexities, like data structures with cyclical references.
> This is factually impossible.How do you outright deny something as subjective as my personal experience? Besides, I'm not the only one in this discussion that made the same opinion.> For anything larger than (very) small programs, Rust requires an upfront design stage, due to ownership, that it's not required when developing in GC'ed languages.While GC'ed languages allow you to skip a proper initial design stage, it's a stretch to claim that it's not required at all. In my experience using Python, while the initial stages are smooth, such design oversights come back and bite at a later stage - leading to a lot of debugging and refactoring. This is one aspect where Rust saves you time.> This is not even considering more local complexities, like data structures with cyclical references.I'm not going to dwell on cyclical references, since there's another thread that addresses it. They point out a way to make it as easy in Rust as it is in GC'ed languages.Meanwhile, the upfront architecture and data structure design isn't as complicated as you project it. Rust is mostly transparent about those - even compared Python. How well do you understand how Python manages Lists, dictionaries or even objects in general? I often find myself thinking about it a lot when programming in Python. While you need to think upfront about these in Rust, there's actually less cognitive overhead as to what is happening behind the scenes.
Or maybe they mean "fast to 1.0" rather than "fast to 0.1"?They didn't specify.
That is also not shared by everyone. If you have written enough Rust to have internalized designing for the borrow checker, you don't have to spend much time in a design phase.The only time I find I have to "fight the compiler" is when I write concurrent code, and you can sidestep a lot of issues by starting with immutable data and message passing through channels as a primitive. It's a style you have to get used to, but once you build up a mental library of patterns you can reasonably be as fast in Rust as you are in Python.
> For anything larger than (very) small programs, Rust requires an upfront design stage, due to ownership, that it's not required when developing in GC'ed languages.It's nearly the opposite. For larger programs in Python, you need an upfront design stage because the lack of static typing will allow you to organically accrete classes whose job overlap but interfaces differ.Meanwhile, Rust will smack you over the head until your interfaces (traits) are well-organized,beforethe program grows enough for this to become a problem (or until you give up and start over).How do I know? I'm stuck with some larger Python programs that became a mess of similar-but-not-interchangeable classes. RiiR, if I ever have the time.
> For larger programs in Python, you need an upfront design stage because the lack of static typing will allow you to organically accrete classes whose job overlap but interfaces differ.You can also install pre-commit and mypy, and have static typing.
That's the entire point we're making. Rust's type system forces you to deal with the problem early on and saves time towards the end. It's not like that's impossible with Python with addons like mypy. But Rust's type system goes beyond just data types - lifetimes are also a part of the type system. I don't know how you can tack that on to Python.
> Rust's type system forces you to deal with the problem early on and saves time towards the end. It's not like that's impossible with Python with addons like mypy.Definitely not - mypy's pretty good these days, and lots of people use it.> But Rust's type system goes beyond just data types - lifetimes are also a part of the type system. I don't know how you can tack that on to Python.Well, Python's objects are generally garbage collected rather than explicitly destroyed, so I don't think it'd make sense to have lifetimes? They don't seem a correctness thing in the same way that types do.
Lifetime analysis matters a lot for way more than just garbage collection.File handles, iterators, mutex guards, database transaction handles, session types, scoped threads, anything where ordering or mutual exclusivity matters.
I don't know about all of those, but Python's context managers and built in constructs handle most of those, I think?
Only in the most basic cases. If your handle has to be passed into another function or outlive the current scope of your function, the guardrails end.
Lifetimes and borrowing are very much a correctness thing and aren't just for tracking when memory is freed. While you won't have use-after-free issues in a GCed language, you will still have all the other problems of concurrent modification (data races) that they prevent. This is true even in single-threaded code, with problems like iterator invalidation.
Mutability is a big one for correctness.  In Python, any function you pass any (non-primitive) object to might be mutated right out from under you and you have no idea it's happening.  In Rust, you have to explicitly provide mutable references, or you need to hand over ownership, in which case you don't care if the callee mutates its argument, because you no longer have access to it.
RiiR: Rewrite it in Rust
> This is factually impossible.Factually it's not. Itmaybe true that in a very very idealized thought-experiment, when someone has a perfect knowledge, never makes mistakes, doesn't have preferences, can type arbitrary fast etc, python needs fewer keystrokes, fewer keywords or such, thus is faster. Who knows. But in reality none of the assumptions above hold, also literally everything plays a much bigger role in development speed anyway.
You know what slows me down in Python? The fact that you need to actually go down a code path to make sure you’ve spelled everything right.But nothing that Rust does slows me down because I’m used to it.
Of course it's possible. You just need to write Python very slowly :)
Everyone has their breaking point. I start to write Python very slowly around after 10k lines or so. Can't remember where I put stuff...
> For anything larger than (very) small programs, Rust requires an upfront design stage, due to ownership, that it's not required when developing in GC'ed languages.Every language requires this (if you want robust code), most just let you skip it upfront ... but you pay dearly for doing so later.
I disagree. I have similar observation. With modern editors and Language Server that are giving immediate feedback writing strongly typed languages doesn't differ than writing python.
I would flip this around.If you are only writing small programs where perf doesn't matter, crashing doesn't matter, design doesn't matter - Python will be faster than Rust, because the only thing that matters is how you can write the code from 0 to "done". You can jump right in, the design stage is superfluous & unnecessary. There is nothing to optimize, the default is good enough.If you are doing slightly more than that, Python and Rust become about even, and the more you need those things, the better Rust becomes.
> This is factually impossible.No it isn’t Both languages comprise much more than their memory management handling. Even if your premise is true, the conclusion does not follow.
I mean, it’s easily the same for me. I am way more productive in Rust because I know it very well, and with Python I’m debugging all kind of gotchas.
I have to second the OP: ownership isn’t that hard. I just get used to structuring a program in certain ways. Having written a lot of C++ helps because the things Rust won’t let you do are often unsafe or a source of leaks and bugs in C++.Having an editor with rust-analyzer running is massively helpful too since ownership issues get highlighted very quickly. I can’t imagine dealing with any language larger than C without a smart editor. It can be done but why?I still find async annoying though.My biggest source of friction with Rust (other than async) is figuring out how to write code that is both very high performance and modular. I end up using a lot of generics and it gets verbose.
I think this is a very valuable comment, and the replies don't do it justice.I strongly agree from my own and my peers experience with the sentiment that latency from zero to running code is just higher in Rust than Python or Go. Obviously there are smart people around and they can compensate a lot with experience.
Honestly I found myself coding very much the same way in Rust as I did in Python and Go, which were my go-to hobby languages before. But instead of "this lock guards these fields" comments, the type system handles it. Ownership as a concept is something you need to follow in any language, otherwise you get problems like iterator invalidation, so it really shouldn't require an up-front architectural planning phase. Even for cyclic graphs, the biggest choice is whether you allow yourself to use a bit of unsafe for ergonomics or not.Having a robust type system actually makes refactors a lot easier, so I have less up-front planning with Rust. My personal projects tend to creep up in scope over time, especially since I'm almost always doing something new in a domain I've not worked in. Whenever I've decided to change or redo a core design decision in Python or Go, it has always been a massive pain and usually "ends" with me finding edge cases in runtime crashes days or weeks later. When I've changed my mind in Rust it has, generally, ended once I get it building, and a few times I've had simple crashes from not dropping RefCell Refs.
Couldn't one use Arc and similar boxed types to avoid thinking about memory until later?
Why not just something like nim and that point, and straight up ditch 90% of the complexity?
I was answering to this other user:> This is factually impossible.> For anything larger than (very) small programs, Rust requires an upfront design stage, due to ownership, that it's not required when developing in GC'ed languages.It seems that is not factually impossible.Now, answering your question: It could be useful to use boxed types and later optimize it, so you get the benefits of rust (memory safety, zero cost abstractions) later, without getting the problems upfront when prototyping.
I've finally set my mind to properly learning a new language after Python, Haskell, and typescript. I'm looking into Rust especially because of how I've heard it interoperates with Python (and also because it's maybe being used in the Linux kernel? Is that correct?).
Rust is an excellent follow up to those languages. It's got many influences from Haskell, but is designed to solve for a very different task that's not yet in your repertoire so you'll learn a ton.And yes the Python interop is excellent.
I'm sold, thank you. Yes, it felt like a great "missing quadrant" to my generalist skillset.
Linux kernel has support for rust userland drivers, and rust interops with python with pyo3.
Not sure what you mean by "userland" drivers here, but support for kernel modules written in rust is actively being developed. It's already being used for kernel drivers like the Asahi Linux GPU driver for M1 Macs.
I am referring to userspace / userland drivers.https://www.kernel.org/doc/html/v4.18/driver-api/uio-howto.h...
But you can write userspace drivers in any language, as long as that language has basic file I/O and mmap() support. There's nothing special about using Rust for userspace drivers.
Isn't this false? Don't certain languages basically need, say, a libc that isn't nessesarily available in kernel space?
What window manager is that, may I ask out of curiousity?
Sway. And river, sooner or later. A single Rust program is used for setting up services (using s6-rc on Gentoo), shutdown, reboot, idle inhibit, etc.
I agree. I feel far more productive in C and C++ than in Rust at that point.Rust feels like totally missing the sweet spot for me. It's way too pedantic about low level stuff for writing higher level applications, but way too complicated for embedded or writing an OS. In the former case I would rather take a C++, Java, Haskell, OCaml or even Go, and maybe sprinkle some C, and in the latter case C in macroassembly mode is far more suitable.I still have a feeling that original vision of Graydon Hoare (i.e. OCaml/SML with linear types, GC, stack allocations, green threads and CPS) would be a much better language.
The problem with C and to C++ is that it’s 2023 and the CVE list is still loaded with basic memory errors. These come from everywhere too: small companies and open source all the way up to Apple, Microsoft, and Google.We as a profession have proven that we can’t write unsafe code at scale and avoid these problems. You might be able to in hand whittled code you write but what happens when other people work on it, it gets refactored, someone pulls in a merge without looking too closely, etc., or even maybe you come back two years later to fix something and have forgotten the details.Having the compiler detect almost all memory errors is necessary. Either that or the language has to avoid this entirely. Rust is the former class unless you use unsafe, and the fact that it’s called “unsafe” makes it trivial to search for. You can automatically flag commits with unsafe in them for extra review or even prohibit it.
I think nobody is arguing the need for static memory safety, just that the poor Rust ergonomics aren't a good tradeoff, especially for scenarios where C is useful. We need many more Rust alternatives that explore into different directions, Rust is already too big and "established" for any radical changes in direction.
On that regard, by packaging Modula-2 into a C friendly syntax, I do agree Zig is relatively interesting option, however not having a story for binary library distribution is an hindrance in many C dominated industries.
> I think nobody is arguing the need for static memory safety, just that the poor Rust ergonomics aren't a good tradeoffUnless the "poor ergonomics" and lack of shortcuts are explicitly what provides the static memory safety.
IMHO Rust's ergonomics problems aren't caused by the borrow checker itself, but have the same cause as similar problems in C++ (mainly a "design by committee" approach to language design and implementing features that should be language syntax sugar in the stdlib instead, which then directly results in the stdlib being too entangled with the language and "too noisy" hard to read code).Apart from the static memory safety USP, Rust is repeating too many problems of C++ for my taste, and at a much faster pace.
I agree with this. The borrow checker itself isn't the problem. That's necessary to make you write correct and safe code anyway.The problem is that there is too much syntax, too many symbols, and too many keywords. I just keep forgetting how to use impl and lifetimes and single quotes and whatnot. It makes it really tough to use as an occasional language. And if I can't do that, then how can I get confident enough to use it in my job?
> The problem is that there is too much syntax, too many symbols, and too many keywords. I just keep forgetting how to use impl and lifetimes and single quotes and whatnot.This is exactly how I feel about Rust.There are some good ideas in there, hiding behind a horrible language design. I am waiting for someone to provide a more developer friendly alternative with the simplicity of C or Go.
Maybe Lobster could be an option.https://strlen.com/lobster/https://aardappel.github.io/lobster/memory_management.htmlIt uses compile-time reference counting / lifetime analysis / borrow checking. Which is mostly inlined to the point that there is none of the sort in the compiled output and objects can even live on the stack. It basically looks like Python but is nothing like it underneath, and of course with no GIL. You can run it on JIT or compile it to C++.There's also Koka with the Perceus algorithm on compile time and looks like a much cleaner language than Rust. It also tracks side effects of every function in a type where pure and effectful computations are distinguished.https://github.com/koka-lang/koka
In that regard, strangely enough, I find with constexpr code, templates, and concepts, is easier to achieve most compile time code stuff, while staying in C++, than dealing with Rust macros.
When the pendulum swings it often swings far before normalizing somewhere in the middle. I agree that Rust isn't the answer.FWIW there is interest in adding bounds checking to C [1]. That discussion includes feedback from at least one member of the C standards committee.[1]https://discourse.llvm.org/t/rfc-enforcing-bounds-safety-in-...
It is, however those same companies aren't dialing full safe ahead knob either, hence why Microsoft just recently published a set of secure coding guidelines for C and C++.https://devblogs.microsoft.com/cppblog/build-reliable-and-se...
Does it have tooling to enforce those guidelines? If not, how is it better than someone saying "write correct code" and calling it a guideline?
Following a guideline that checks correctness for you is easier than following "write correct code".
Partially, in Visual Studio and GitHub.
These are two issues, which a theoretically orthogonal but in practice not so much. These are known as soundness and completeness. A good talk on topic [1]Rust will reject a lot of sound programs, and that's a huge performance hit. You are hitting the incompleteness wall with multiple mutable borrowing, closures in structures are a huge source of pain as well. And usually the answer from the community is "use handlers instead of pointers", but this gives you, surprise surprise, manual resource management alike that in C, and the compiler won't help much.Of course this is all subjective but for me the ergonomics of Rust is far too bad. It's a good step in right direction along with ATS, but I really hope we could do better than this.[1]https://www.youtube.com/watch?v=iSmkqocn0oQ
Can you give us examples, please? I use Rust since version 1.0, and I like it a lot.
Cyclic data structures are impossible to represent in safe Rust because there is no clear "owner" in a cyclic data structure.
Cyclic structures can be flattened into a vector or an arena, or unsafe Rust can be used.
What are some examples of sound programs you want to write in Rust but are unable to write?
I maintain very large C and C++ application and very rarely have any memory issues. Tools like Valgrind and Helgrind are excellent for finding and fixing problems. So switching to Rust is a very bad ROI.
I gave Rust a few chances, and always came out hating its complexity. I needed a systems programming language to develop a hobby OS[1], and Nim hit the sweet spot of being very ergonomic, optional GC, and great interop with C. I can drop down to assembly any time I want, or write a piece of C code to do something exotic, but the rest of the system is pure Nim. It's also quite fast.[1]https://github.com/khaledh/axiom
Opposite experience for me. Writing Rust on embedded systems greatly improved my confidence and speed. When using C a small mistake often leads to undefined behaviour and headaches. Rust theres none of that - its been a game changer for me.
I was using rust on embedded, I moved to zig. Very happy with it as you can pass allocators around to use fixed buffer.
When you are developing hardware on an FPGA, a lot of hardware bugs look like they have locked up the CPU and strangely enough, a lot of undefined behavior looks exactly like a hardware lockup...
I am curious what kind of code you are writing? Is it very low level or very high?>I know rust gives memory safety and how important that is, but the ergonomic is really bad. Every time I write some rust I feel limited. I always have to search libraries and how to do things. I cannot just "type the code".You don't have to search libraries and figure out how to do things in Zig?
It's hard to describe, but in some languages, you spend a lot less time looking at reference docs and more time just naturally writing the solution. Lisp is a great example of that, if you get through the learning curve.
I suspect Zig libraries feel easier because they're doing easier things. I bet if you try to draw a triangle with the Vulkan API in Zig, you'll find yourself looking at the reference docs a lot.
Most of the time I can use my "general computer science baggage" to write the solution. At present, I do embedded and web business logic (wasm) where the UI is rendered by preact. For those two projects zig is working very well.
I agree with this general feeling, and it is hard to articulateRust forces you to figure out ahead of time where each bit or byte is going to go and on which thread and using which mutation scheme. I’m happy to play the game, but it feels tedious for anything short of a parser or a microcontroller.It messes with my process because I like to get something working before I determine the best API structure for itI can get 90% of the performance with Swift and it flows much more easily, even though Rust’s type system is more powerful.
I’ve written plenty of Rust code in my life (easily more than 100kLOC, and I’ve really never worried about putting which bit where.You can just clone and be on your merry way; you don’t need to worry about perf-related things if you don’t want to.
Those two sentences feel in contradiction of one another. You don’t need worry to about where the bits go, you just need to know to call a method to move the bits?Swift makes every type implicitly copyable on the stack, including object pointers (through ARC), so you don’t have to clone. You can even pass functions as variables without any hoops.I love lots of things about Rust, though, and will continue to use it for lots of things. Cross-platform things, for one!
I rather use compiled managed languages like Swift, D and C# instead, they provide enough low level coding knobs for C and C++ style coding, while being high level productive.Would add Go to the list, but only when I really have to.Nim and Crystal could be alternatives, but don't seem to have big enough communities, at least for what I do.However I do agree with the conclusion, Rust is a great language for scenarios where no form of automatic memory management is allowed, kernels, specific kinds of drivers, GPGPU programming, as general purpose, there are more productive alternatives, equally safe.
C# is underrated by the HN crowd, I find. I quite like how mid sized firms (100-1000 employees) use it.
I used to be .NET dev and don't agree. Couple of reaons:1) Modern Java is almost as good as C# with some things I can't give up in Java (static imports => succint code, Groovy Spock => succint tests)2) Kotlin is better than C#3) JVM hasmuch muchbigger ecosystem (almost all the apache projects are JVM oriented) and default web framework is much less code to type (SpringBoot) is much more productiv4) JVM has wider variety of langsFor those reasons IMHO if you are small-mid company (or startup) it's wiser to choose JVM.
Kind of, maybe you need to do some low level coding and don't want to wait for Valhala, or make use of JNI and native libraries, GraalVM/OpenJ9 still aren't as integrated as .NET Native or Native AOT, e.g. writing native shared libraries.Also Java lost the attention span of the gaming industry, besides Android casual games and Minecraft, there are hardly anyone else paying attention to it.
To be fair, C# is ok for game dev, but not great. C# libraries are lagging heavily behind Java.Want a fastest possible library? It's in C++, and not portable to Win/Mac. So good luck with wrap + porting it.Want a decent implementation of an algo? It usually exists for Java but not for C#. Hope you like writing it from scratch.Want a C# implementation of an algo that doesn't allocate to the Nth degree. Again, write it yourself.But ok, maybe Unity has a good ecosystem... And they fucked it over a barrel.
It is widely better recieved in the AAA gaming developer community than Java, and that is what matters.I also like Java, but c'mon no decent algorithms being implemented in C#? That is already approaching zealotry.
I didn't say no decent algorithm in C#, but for each performance sensitive algorithm/data structure there is a C and Java implementation at the least ( in my case Roaring Bitmaps).In C# the solution is half baked or archived or abuses allocation.I think Unity has way more with C# adoption in game dev than innate C# qualities.
This is a classic case of goalpost moving. The reason why so many algorithms are written in Java especially closer to academic side is because most curriculums in comp-sci often straight up not allow using anything else except Java, Python or sometimes C++. Having C# as an alternative in these is a luxury. There are also more people using Java in general. However, this does not make it a better language at solving these tasks, nor it is any suitable for writing high performance implementations for advanced vectorized algorithms which would push hardware, which is actually what you want when you start caring about such scenarios, which C# excels at.
I'm not moving the goalpost. I explained my examples in another reply. Want to write an engine mostly from scratch in C# and you need libraries that are low on allocation and for niche data/algorithms that games need? You're going to have a bad time(TM).Sure you could use YAML parser, but it allocates everyone and their mother. 
Can you find a Fluent localization in C#? Sure, but its outdated and archived.
Ok, but basic RoaringBitmap implementation? The repo is archived and not fully complete.Why C# is used in game dev is incidental. It has more to do with Unity and XNA/FNA than any concrete quality of language modulo value types (but then again, most C# libraries don't focus on avoiding allocation and are just as happy as Java to construct a complicated hierarchy of classes).
I think Java is only good for long-running servers.Java doesn’t support C interop. For many desktop and embedded projects this is a showstopper, here’s an examplehttps://github.com/Const-me/Vrmac/tree/master/VrmacVideoThat C# code directly consumes V4L2 and ASIO Linux kernel APIs, and calls unmanaged user-mode DLLs like libfdk-aac.so and liba52-0.7.4.so.Native stack and value types in C# reduce load on GC, and the number of complicated tricks required from JIT compiler. This in turn helps with startup performance. This is critical for command-line apps, and very desirable for desktop apps.Another thing missing in Java is intrinsics support, both scalar like popcnt, bitscan, BMI, etc., and SIMD like SSE and AVX.
Projects Panama & Valhalla seems to solve all your complaints:> Java doesn’t support C interop. For many desktop and embedded projects this is a showstopper, here’s an examplehttps://github.com/Const-me/Vrmac/tree/master/VrmacVideoThat C# code directly consumes V4L2 and ASIO Linux kernel APIs, and calls unmanaged user-mode DLLs like libfdk-aac.so and liba52-0.7.4.so.Part of Panama: check out the "Foreign Function & Memory API" [0]. The official docs [1] say it is a preview in 21 but it got stabilized in Java 22 (isn't out yet).> Another thing missing in Java is intrinsics support, both scalar like popcnt, bitscan, BMI, etc., and SIMD like SSE and AVX.Also part of Panama: see the "Vector API" JEP [2].> Native stack and value types in C# reduce load on GC, and the number of complicated tricks required from JIT compiler. This in turn helps with startup performance. This is critical for command-line apps, and very desirable for desktop apps.This is part of Project Valhalla [3], they're adding value types and actual generics, among other things.That said, most of these are not done / not in a stable LTS Java release yet. We'll see how much better it'll be compared to C# (if at all) once they land.[0]https://openjdk.org/jeps/454[1]https://docs.oracle.com/en/java/javase/21/core/foreign-funct...[2]https://openjdk.org/jeps/460[3]https://openjdk.org/projects/valhalla/
> Part of PanamaMost real-live C APIs are using function pointers and/or complicated data structures. Here’s couple real-life examples defined by Linux kernel developers who made V4L2 API: [0], [1] The first of them contains a union in C version, i.e. different structures are at the same memory addresses. Note C# delivers the level of usability similar to C or C++: we simply define structures, and access these fields. Not sure this is gonna be easy in Java even after all these proposals arrive.For a managed runtime, unmanaged interop is a huge feature which affects all levels of the stack: type system in the language for value types, GC to be able to temporarily pin objects passed to native code (making copies is prohibitively slow for use cases like video processing), code generator to convert managed delegates to C function pointers and vice versa, error handling to automatically convert between exceptions and integer status codes at the API boundary, and more. Gonna be very hard to add into the existing language like Java.> "Vector API" JEPThat API is not good. They don’t expose hardware instructions, instead they have invented some platform-agnostic API and implemented graceful degradation.This means the applicability is likely to be limited to pure vertical operations processing FP32 or FP64 numbers. The rest of the SIMD instructions are too different between architectures. A simple example in C++ is [2], see [3] for the context. That example is trivial to port to modern C#, but impossible to port to Java even after the proposed changes. The key part of the implementation is psadbw instruction, which is very specific to SSE2/AVX2 and these vector APIs don’t have an equivalent. Apart from reduction, other problematic operations are shuffles, saturating integer math, and some memory access patterns (gathers in AVX2, transposed loads/stores on NEON).> most of these are not done / not in a stable LTS Java release yetBTW, SIMD intrinsics arrived to C# in 2019 (.NET Core 3.0 released in 2019), and unmanaged interop support is available since the very first 1.0 version.[0]https://github.com/Const-me/Vrmac/blob/master/VrmacVideo/Lin...[1]https://github.com/Const-me/Vrmac/blob/master/VrmacVideo/Lin...[2]https://gist.github.com/Const-me/3ade77faad47f0fbb0538965ae7...[3]https://news.ycombinator.com/item?id=36618344
Well maybe you should use C++ or Rust instead of Java or C# in that case?My point is if you are doing business (especially web) apps. Use one of JVM langs insted of C# because ecosystem is much bigger (and it has fresher langs as well like Kotlin - if that's what you care about)
> use C++ or Rust instead of Java or C# in that case?Despite having to spend extra time translating C API headers into C#, the productivity gains of the higher-level memory safe language were enormous.Another example, I have shipped commercial embedded software running on ARM Linux, and based on .NET Core runtime. The major parts of the implementation were written in idiomatic memory-safe C#.> doing business (especially web) appsWell, these business web apps are precisely the long-running servers I have mentioned. Still, the software ecosystem is not limited to that class of problems, and due to different tradeoffs Java is not great for anything else.
Also with JDK 21 - you can use virtual threads. No need for async/await which IMHO is a design mistake. Java copied Go here instead of C#.
Which makes C interop worse, just like Go
Java is surely keeping up but I can't name single Java feature that I miss in C# or is implemented better in Java. I haven't used Java in a long time though, just occasionally I read about new Java features and I've never said to myself "cool, I wish I had it in C#".Static import are also available in C# for quite some time now (c# 6, released in 2015, and in C# 10 you can even make this import global for for project).I haven't used Kotlin, is there any killer feature compared to C#? (except more succinct code in certain cases?)
Kotlin is younger and made better choices by default, like immutable "val" as default option.Also since it's Jetbrains - IDE integration is superior compared to anything C# can have (including Rider...)
Depending on how you look at it, better extension everything support on Kotlin's case, and a way to do DU, while it keeps being discussed for C#, people should just add F# to their codebase, but alas.
#1 => agree#2 => don't know enough about Kotlin to comment#3 => agreebutquality > quantity#4 => not terribly important to me (Clojure is cool but it's not "switch to the JVM" level cool)
I've always found those sort of firms with C#, in my experience, have the best architected code. Proper domain-driven design, onion architectures, clean testable code... Some have legacy issues where they might not have the most cutting edge CI/CD pipeline or high automated test coverage, but the code itself can be very nice. I've never really experienced that level of consistency with a different language/company size.
C# is a lovely language to work with.The only issue I have is with the .NET ... that is, building self-contained binaries to distribute.For comparison:* Hello World win-x64 binary self-contained in .NET 7 is around 70 MB* The same for Go results in 1.2 MBEdit: Missed 'trimming' in .NET, which would result in a binary of size around 11 MB in  win-x64
Usually that means you aren't using trimming, .NET speak for dead code removal during linking.Also remember that standard .NET runtime does a little bit more than Go's runtime, so it might happen that even with trimming, for basic applications Go ends up having an upper hand on file size.On the other hand, I have had Go static binaries grow up to 200 MB and being require to use UPX to make it manageable, e.g. trivy.
You're right. But even with trimming I get around 10x the size of the Go binary
dotnet publish -c release -p:PublishAot=true
Since I edited my comment, see my additional remarks regarding runtime capabilities, and the counterpoint of big Go binaries.Also note that triming only works properly if the libraries have taken the effort to be trimmable, as the linker errs on the safe side and won't trim unless certain that it is really dead code, and not called via reflection.
I was making Windows 98 apps with Delphi 4, and they were 350 KB largeAnd I was upset that they were so big. Sometimes I used UPX. Or I kicked out all Delphi GUI libraries, and created the GUI with the Win32 API calls directly. I got 50 KB Hello Worlds.
50kB hello worlds? Uhm.. thats still big.15k May  3  2019 quickrun.exe*Win32 GUI Application that spawns Window and ask for alias to run.
Pure Win32 API, written in C (Mingw).I literaly looled at 11MB hello world of .net or 1.2MB Go..
Well, it is what I rememberedI do not have Windows 98 anymore. But I still have Delphi 4 installed under Wine, so I just tried it out.Just showing a messagebox from windows gives 16kUsing the sysutils unit though, puts it at over 40k. And with classes, it becomes 57k. 
Not sure what they pull in. sysutils contains number/datetime parsing and formatting, and exception handling.  classes has basic containers and object oriented file handling.
Ahh, Delphi. Then I suppose its all right for it. Still, much better compared to Go or Java :D
If only Borland's management didn't decide to focus mostly on enterprise customers.
Let me give a real world example from my own experience.I have built a Win32 desktop app with its core logic in Go; and then re-built from scratch using .NET (v7). The core logic involved a fairly complicated keyboard input processing based on bunch of config files.- Final binary of .NET ~ 14 MB- Final binary of Go ~ 2 MB
This is an unfair comparison of apples to oranges by building the binary with the wrong flags. .NET produces smaller binaries than Go with NativeAOT (despite including more features).
Yea, I missed trimming. But still NativeAOT results in 10x the size of the Go binary in Windows (win-x64)
Two aspects:- There is no point in chasing smallest possible binary size if it trades off performance and features one wants to use in production scenario, or comes with other tradeoffs that sacrifice developer productivity. I don't see anyone complaining about the size of GraalVM native images. As long as binaries are reasonably sized, it's not an issue.- dotnet publish -c release -p:PublishAot=true definitely produces smaller binaries than Go as of .NET 8 (and no, you cannot use the argument that it's not released yet - it's in RC.2 which is intended for evaluation for adopting .NET 8 scheduled for release next month)
That's awesome, honestly. Can't wait.
Idk the last time you tried but a hello world in C# using .Net 8 is smaller than a Go hello world, for what it’s worth.
Is it? Every time I see C# being mentioned here people agree how awesome it is. Not that I'm complaining, I love C#
Agreed. I feel C# is appropriately rated on HN and other programming forums. It has perfomant memory options that other GC languages lack, and great builtin packages to use. Overall, it is a good language.My biggest issue with C# though is how badly exceptions are handled given that it is a statically typed langauge. I wish functions explicitly defined the exceptions it can throw since a minor package bump could add an exception without your compiler warning you that it isn't handled. I much prefer Rust, Go and Zig's error handling to C#'s since those kind of issues don't happen.
> It has perfomant memory options that other GC languages lack, and great builtin packages to use.As clarification for the audience, it isn't the only GC enabled language with C and C++ like capabilities, in fact there are several examples since the early 1980's.The adoption push for Java and scripting languages distorced the understanding of what was already available out there.
Well, I see it as lack of fanboyism which is interesting and almost unique to the Java/C# ecosystem. A lot C# experts(and I mean REAL, low level experts) seem to also have very high Java expertise..And those that have Java expertise but not C# seem to demur to those that do; image!But it's still niche(around here and in the startup world) and gets lumped in with Java and together they are not "hip" or "agile" or whatever.
Slightly... The difference in type erasure is pretty huge IMHO.But what libraries are you lacking?
Type reification is planned and so is value types.And type erasure isn't as negative as you seem to make it.Bunch of really obscure use cases - fluent localization, roaring bitmaps and so on.
> compiled managed languages like [...] C#I've been out of the windows development game for a long time, so I haven't used C# since it strictly required a VM... what's pre-compiled C# development like nowadays? Are there major caveats? If you can emit plain old binaries in C# with no runtime dependencies, that would make it a truly compelling language IMO.And as another question, what's the cross-platform (mainly Linux) support like in AOT-compiled C#? If it's just as good as in Windows and emits plain executables, I would probably consider it the best place to start for any new project. (Something tells me it's not...)
C# supports AOT since forever, NGEN was present in .NET 1.0. Not many people used it, because it requires signing binaries and only supports dynamic linking, with a performance profile towards fast startup.On Microsoft side the Singularity and Midori experiments used AOT.They influenced the AOT toolchains for Windows 8 store apps with MDIL (Singularity/Bartok), and Windows 10 store apps with .NET Native (Midori/Project N).Now there is Native AOT, which supports CLI and native libraries,.NET 8 extends that to EF and ASP.NET frameworks. For GUI applications, maybe only fully on .NET 9.Mono AOT has had support for ages, being used on iOS, Android, and Blazor.Finally there is IL2CPP and Burst compiler from Unity.
In 8, NativeAOT also supports iOS (and even Android reportedly?) for, I assume, MAUI target to do away with Mono. Documentation on this definitely needs work, and there are projects that made it working with WPF, Windows Forms and Avalonia back in .NET 7. Arguably, none of those were particularly user-friendly but generated COM interop project for 8 was done specifically to improve this on Windows as well.
This. I have exactly the same experience, I can't believe how much I was able to ship with Zig and the code mostly feels like "done".You can always improve it, but there's no need to. With Rust, I was never happy, even after 5 years, I was still thinking about better abstractions and implementing more traits, making it more generic, etc.
Why is there no need to improve Zig code but there is for Rust code? You'd need the same abstractions in Zig as well, no?
No, usually you don't. Rust has closures, iterators, generics, different traits for operator overloading, smart pointers, etc.Zig doesn't have any of that. It's very interesting combination of low-level, predictable code, with meta-programming, where you get some of that abstraction back.i.e. Zig does not have generics, but your function can return type, so generic list is just a function which returns a newly created struct.
Could you expand on the generics point, please? That sounds interesting but I can't quite get my head around it.
Functions in Zig can be called both in runtime and in compile-time. You can force some expression to be called during comptime using a keyword, and sometimes the comptime is implied (like when you define top-level const)If a function is called in comptime, it can also return types. So for example:// this is a function which accepts a type
    // if you accept type, you also have to restrict the arg to be comptime
    // if the arg is comptime it still does not mean that the function cannot be called in runtime,
    // but in this case, it returns type, so it is comptime-only function
    // there are also cases where this is not true, like std.mem.eql(u8, a, b) which accepts type,
    // but can be called in runtime because it does not return type
    fn Wrapper(comptime T: type) type {
        return struct { value: T };
    }

    const F32Wrapper = Wrapper(f32);

    // @TypeOf(x.value) == f32
    var x: F32Wrapper = .{ value: 1.0 }
Zig has `comptime` where you effectively generate Zig code at compile time by writing Zig code, no special generics syntax/semantics needed. It is very nice and powerful concept that covers lots of ground that in Rust would belong to the land of procedural macros.
Can't speak for why Zig doesn't have a problem but Rust is cursed by its success: it lowers the barrier for improvement enough to entice you to always improve it.
No. Rust forces you to spend endless hours doing mental gymnastics which shouldn't be needed in the first place (linked data-structures, owned arenas, or even just boxed slices are impossible in safe rust).And you just keep refactoring/improving/desperately trying different ideas, because it never feels right.It's ok if you don't agree but pls don't try to make my responses look like I like Rust, I don't and I'd happily get those years back if it was possible.
> it can be very hard to actually know what method you can call on a structThe rust-analyzer language server can autocomplete the available methods for a value.
depending on the autocompleter feels like asking to code to Chatgpt to me.
I disagree, there's a big difference: rust-analyzer is deterministic and 100% accurate while ChatGPT is non-deterministic and hallucinates.
Yep. I can't remember method names for the life of me, which is why my best experiences have been with Go and Java: The IDE (always Jetbrains) knows, via the type system, what methods I can call.
Furthermore you can use `cargo doc` to generate a documentation website that had everything you can do or you can use docs.rs for this. Whoever wrote this didn't embrace the tooling and just gave up.
Wait, I am a bit confused.  Does Zig have more/better libraries than Rust? I thought it's a pretty new language. The most limiting thing for me with Rust was the lack of libraries (vs. say Python or Node/JavaScript).
It doesn't. The ecosystem is very immature and even the official tooling is very unstable. It has a bunch of interesting design ideas but at this point it's more of an experimental language than a production ready one by most metrics. (And unless it finds some kind of corporate backing, this is unlikely to ever change).
We shipped a few web apps backed by zig. It is absolutely in production.
It interops seamlessly with C libraries.
Depending on what seamlessly means, Rust can also interop with C libraries. I wrapped a bunch of them.
Truly seamless because the zig compiler is also a C compiler, so the type information and calling convention works across languages at a level above any other I've encountered.
It's also an unfinished language. I agree Zig is promising, but it's not confidence inspiring when the creator is still making videos debugging the compiler.
True, but I think that the person you're responding argued that rust/C integration is also seamless. (In the general discussion I'd say they're right as C to Rust integration isn't much of an problem and you can use C libraries relatively easily in Rust as well, but at the same time when talking about Zig I don't think it's fair to put it on the same ground).
It is impossible to do C interop without a C compiler, by the way.
Seamlessly as in @cInclude("raylib.h")
Given that Zig is memory unsafe it isn't either a good general purpose language.IMO a good GPR is memory safe (no C, C++, Zig), is easy to use(no Rust), has strong static typing (no Perl, Python, Ruby) and is "stable" (no Scala). Lots of choices remain: Java, Kotlin, Ada, D, OCaml..
From these, my favourite is D
c#
It somehow seems that Zig has most of the qualities that people like about C: clear, crisp, no huge Stdlib, good old straightforward imperative semantics, and readonably fast. But without lots of the cruft.
Unfortunely lacks support for binary libraries, and not yet a story for UAF other than the tooling we are already using in C derived languages to track them down.
You should try diving into num for like a month and see how you like it. It's different enough that you need to go past a certain kind of ledge to start liking it. Or at least that was my experience.For me, it shares the most important benefits of Rust but with quite a lot more ergonomic coding model.
Nim on paper is great; it has many advantages over Rust in the general purpose "niche". Tragically, it's kind of stillborn. It's older than Rust, has orders of magnitude less mindshare, and has no companies with serious technical reputations backing it.
Yeah, you're not wrong about the mindshare problem. But it somehow at least in my mind differs from other "stillborn" older languages in that it keeps improving. The end result is that it still feels modern in the year 2023.
So any language that isn't sponsored by Google/MS/Amazon/Mozilla from day 1 should just die?
Woopsie. I meant s/num/nim/ of course.
Since you have previously said that you are using Zig to do embedded programming for medical devices, I assume that it is your main pain point. I largely agree that the current Rust embedded story is not exactly for existing embedded programmers (and I guess you are one of them). Rather it looks more like a solution for existingapplicationprogrammers. I don't think it's an intrinsic limitation of Rust the programming language, rather a specific community at this point happens to prefer this way. Still it is a weakness in some sense and Zig will be a good alternative.
Yes, I think rust is very good for higher level programmers wanting to code embedded like a regular OS. There are many great projects around using rust on embedded.But me, I prefer to manipulate registers directly. Especially with "exotic" MCU where you have to execute write/read in specific number of CPU cycles. Rust makes that very hard.
By "wrote" you are meaning just coding or coding+debugging? Because other languages are easier to code, but hard to make error free, while Rust is hard to write but much easier to make bug free.
nim could be another option which defaults to c backend with python syntax
I use Rust a lot, and have been really keen on getting into Zig.Not sure if much has changed (it was a while back), but my biggest problem was with finding and using 3rd party libraries (mostly for the boring stuff like DB connectivity, JSON/YAML parsing, logging, etc.).E.g. even now if I search for "zig mysql library", the tops hits are all about people discussing it on reddit, than any actual library.
You cImport the C library most of the time.
Give Copilot a try, it completely shift coding experience in Rust.
Especially this:> I always have to search libraries and how to do things.Once you pass the initial curve with crutch like Copilot, then you can be almost as productive (if not more, considering refactoring and testing) with your native first coding language
How much of your negative Rust experience is due to async?Having used Rust for a long time it’s definitely the biggest source of confusion and headaches.
It is not that complicated but it is very "time consuming" for reasons I cannot really explain.
Perhaps my biggest critique is that crates.io has no namespacing. Anyone can just claim a global and generic package name and we mostly have to deal with it (unless you avoid using the crates.io repository, but then you'll probably have more problems...). Some of these globally-claimed generic packages are not really the best package to use.Maybe it was a reaction against the Java-style reverse DNS notation, which is verbose and annoying, but a more GitHub-style user/group namespace prefixing package names would have been the nice middle ground.
I did some analysis on crates.io to find the top name squatters.  Then I did some calculations and found that the top name squatter created their crates at a rate of about one ever 30 seconds for a period of a week straight.I send the analysis to the crates.io team and pointed that they have a no-automation policy.They told me that it was not sufficient proof that someone was squatting those names. That's my problem with crates.io is that they have a clear policy and they don't enforce it so all the short/easy to remember names for crates are already taken and there is nothing you can do to get it.
There's a HUGE gap between>Using an automated tool to claim ownership of a large number of package names is not permitted.And-Hey, I found that someone created crates at a rate of about one every 30 seconds for a period of a week straight.-That's not sufficient proof of squatting.Whoever answered that, was either supporting the squatter or explicitly in favor of the practice. I cannot conceive that someone would get that evidence in their hands, and in their right mind think that the claim is bogus. Hell, I'd even be willing to suppress the squatter with evidence of one new crate created every 30 secondsfor one hour!The only reasonable conclusion to make is that they didn't really care. But then don't save face and claim that you do. That's hypocrisy.
In July 2023 the crates.io team started asking for feedback around changing their policy around name squatting -https://rust-lang.zulipchat.com/#narrow/stream/318791-t-crat...
There's a secret effort in the Rust community to supplant Crates.io and create an entirely new package ecosystem with proper namespacing, security, and much better community.Not naming names, but I know several people working to put Crates.io out to pasture.There's a level of playing nice with them for the time being (eg. build reproducibility), but it's only KTLO.Crates.ioneedsto die for Rust to thrive. They're a bungled, mismanaged liability. New code, new leadership.
Crates.io doesn't need to die necessarily. It needs some competition as a wake-up call.Once a better alternative is out there, crates.io will either wither and die or improve. If it matches its competition in terms of quality and reliability, everyone is better off. If not, the alternative solution will take over.I'm eager for this crates.io alternative to land, assuming they don't break too many projects in their improvements.
Why does something like that need to be secret...? Isn't it in the community's best interest?
Drama avoidance and avoiding bikeshedding seem obvious. Much easier to present a working system than a design that will get nitpicked into irrelevancy.
Yeah, that makes sense.
If one tyranny has namespaces and the other doesn't, I'll prefer the former.
pub use std::sic::semper;
const step_on_snek = false;
I find this interersting as most namespacing solutions would need the cargo team involved and I've heard nothing about this.
This was my first thought too. And there are a lot of questions that will get asked, like, will all crate library names start being prefixed as well? So you end up withuse::bar; // changing touse::foo::bar;I assume the library names that can be overridden in cargo would still be accepted, and then it all gets a little messy. The transition would be very messy.
My preferred syntax route is a new separator in package names and the lib name gets populated by everything after it.Still doesn't solve all of the policy problems with namespacing.
How secret is it now that you've posted on HN about it?
Wait I thought only I could read the secret
yes, HN hides secrets automatically******* is my password, but you can't see it. Type your password back, and I won't be able to see it. Try it!
I'm not sure it's working the way you described:hunter2
It’s working. I really can’t see it. All I see is ****
Maybe you are getting tricked to give out your password...
https://knowyourmeme.com/memes/hunter2
tr!pt0ph@n3
It's an open secret.
crates.io is fine.
> they have a no-automation policyWhat's that? 
I have scripts that automate publishing of new release of my crates. And I think many projects have.
Of course that's permitted.What they stated was only regarding claiming new ownership over crate names:> Using an automated tool to claim ownership of a large number of package names is not permitted.
Write some automated analysis that looks up popular packages on npm, pub.dev, rubygems, nuget. "Rustify" the package names. Add to it frequently used words, maybe popular names, etc. Then, write a script that creates an empty package, registers a name on crates.io every thirty seconds, and then you have about 20k package names after a week that nobody can use.
> Maybe it was a reaction against the Java-style reverse DNS notationI suspect it was less a reaction against anything and more just following the norms established by most other package managers. NPM, PyPI, RubyGems, Elixir's Hex, Haskell's Cabal... I'm having a hard time thinking of a non-Java package manager that was around at the time Rust came out thatdidn'thave a single, global namespace. Some have tried to fix that since then, but it was just the way package managers worked in 2014/2015.
>I'm having a hard time thinking of a non-Java package manager that was around at the time Rust came out that didn't have a single, global namespaceThe implication here is that namespaces in package managers weren't a known concept. Outside Java, NPM - probably the biggest at the time - not only supported them but was actively encouraging them due to collective regret around going single-global in the beginning. Composer is another popular example that actually enforced them.Not only was namespacing a known widespread option, with well documented benefits, it was one that was enthusiastically argued for within the Rust community, and rejected.
NPM added namespaces in version 2, which was released in Sep 2014, just 2 months before cargo was announced. I don't remember anyone making a big deal about using scopes in NPM for several years after that, it was just there as an option. The announcement blog post of v2 only gives two paragraphs to scoped packages and explicitly frames the feature as being for enterprises and private modules [0]:> The most prominent feature driving the release of npm 2 didn’t actually need to be in a new major version at all: scoped packages. npm Enterprise is built around them, and they’ll also play a major role when private modules come to the public npm registry.My memory is that the industry as a whole didn't really start paying attention to the risks posed by dependencies in package managers until the left pad incident.To be clear, I'm not saying that it was a good idea to not have a better namespace system or that they were completely ignorant of better options, just that they were very much following the norms at the time.[0]https://blog.npmjs.org/post/98131109725/npm-2-0-0.html
The left pad issue was kind of wild coming from the enterprise Java space. Supply chain attacks against open source software were already being taken pretty seriously, my last company had it's own Maven repository manager running that was used to stage and vet packages before they could be used in production.
I don't think the left-pad problem wasn't about package namespacing it was about the ability to unpublish packages as well the prevalence of micropackages caused by lack of a decent standard library.Also npm's bad policy/decision to transfer control of package in the name of predictability(this should probably be avoided for packages that aren't malicious. You could argue for seizing broken/trivial and unmaintained packages that have a good name but even then it might be best to leave well enough alone).I suppose you're talking about the original dispute which led the developer to unpublish his libraries (which npm stupidly allowed, and cargo didn't). There's a smaller chance of a company wanting a random package namespace then a package name but its not impossible (think Mike Rowe Soft vs Microsoft)
> I don't think the left-pad problem wasn't about package namespacing it was about the ability to unpublish packages as well the prevalence of micropackages caused by lack of a decent standard library.It was "about" cavalier approach to the dependency supply chain.  A dependency disappearing outright is just one of many failure modes it has.
>The left pad issue was kind of wild coming from the enterprise Java space.This may be a little off topic for this comment thread but this is a little misrepresentative. Hosted private repos for enterprise weren't exclusive to Java at the time of left pad - anyone doing enterprise node likely had one for npm too & were probably well prepared for the attack. Such enterprise setups are expensive though (or at least take a level of internal resources many companies don't invest in) leaving the vast majority exposed to both js & java supply chain attacks even today.
At the time Nexus was free to self host, and that is what many smaller teams did just that to archive known good packages for the CI pipeline, I'm not in the Java space anymore so I don't know if that's still the case.
Yeah it's all a bit of revisionist history here, or I guess a bit ignorant. I had a friend who worked at Sonatype from pretty early days and they were, as I understand it, specifically working in this area of infrastructure for vetting, signing, license checking, etc. for corporate environments that needed to be extra careful about this stuff.That crates.io launched without explicitly acknowledging this whole problem is either naivety or worse: already by then Java wasn't "cool" and the "cool kids" were not paying attention to what happened over there.It's not that the industry wasn't paying attention until the 'left pad incident' -- that only holds if one's definition of "the industry" is "full stack developers" under the age of 30; I remember when that happened and I was working in a shop full of Java devs and we all laughed at it...Maven's biggest problem was being caked in XML. In other respects it was very well thought out. That and it arrived at the tail-end of the period in which Java was "cool" to work in.
It's not revisionist history, the wording I chose was meant to acknowledge that there were segments of the industry thatdidtake dependencies seriously. I'm very much aware that the Java world had a much more robust approach to dependencies before this, but "the industry as a whole"includesall the Node shops that were hit by leftpad as well as all the Python and Ruby shops that were using equally lousy dependency management techniques.Rust chose to follow the majority of languages at the time. Again, as I noted in my previous comment, I'm not defending that decision, just pointing out thatmostof the widely-used languages in 2014 had a similar setup with similar weaknesses.
What are the benefits?
mainly, you can trust that anything under the foo/ namespace is controlled by only a smaller group of people, as opposed to the current situation on cargo where people pseudo-namespace by making a bunch of packages called foo-bar, foo-baz, and you can't trust that foo-bin wasn't just inserted by someone else attempting to appear to be part of the foo project. It also helps substantially with naming collisions, especially squatting.
If you want to check your dependency tree for the number of maintainers you're dealing with instead of the number of dependencies, this can be done with cargo tree + checking the Cargo.toml/crates.io ownership info for each of the found packages. I don't know if there's a command written to do that already, but I've done that with a small script in the past.
That's helpful, but doesn't address the bigger problem of people squatting on deceptive names.
Perl’s CPAN was around in the 90’s and all modules were namespaced.
Fair enough. As I noted to another commenter, I'm not trying to say there was no prior art (if nothing else there was Maven), just that they were following the overwhelming majority of mainstream languages at the time.
> just that they were following the overwhelming majority of mainstream languages at the time.They were trying to do better than mainstream languages in other areas and succeeded. IIRC on this front they just decided Ruby's bundler was the bee's knees.
The same developer who worked on bundler also worked on the initial version of cargo. That’s why they’re similar.And at that time, it was a good idea. Ruby was popular and bundler + gem ecosystem was a big reason for its popularity. No one was worried that Rust might become so popular that it might outgrow the bundler model. That was only a remote possibility to begin with.
A mistake that many programmers make, as if baking one more feature on top would have made any difference that wouldn't be amortized in just a few weeks... Sigh.
Yes, and all of those have had major security issues caused by their lack of foresight."We're pretending security is not an issue." has been the feedback every time this is raised with the Cargo team.To be honest, it's turned me off Rust a little bit.The attitude of "Rust is memory-safe, so we don't need any other form of security." is not a good one.
> "We're pretending security is not an issue." has been the feedback every time this is raised with the Cargo team.Literally nobody has said this.> The attitude of "Rust is memory-safe, so we don't need any other form of security." is not a good one.Fortunately it's an attitude that nobody in the Rust project has!
> Literally nobody has said this.I know of a few people, personally, who have said this.
Ok, but like, were any of them people of note, actively working on the project?Because it seems like the people whoareworking on the project aren’t saying that.
The people that are working on the project haven't implemented namespaces, or any other security feature really, so what they say is immaterial. What they do is the only thing that matters.
How do namespaces measurably increase security?
They reduce the risk of supply chain attacks like typo squatting or Dependency confusion.
Funnily enough, they in factincreaseit.
Namespaces can't be typosquatted?
I don't believe I said that.The point is that it's much easier to make a mistake typing "requests" than "
org.kennethreitz:requests" (as a pure hypothetical.)It also means that more than one project can have a module called "utils" or "common", which once again reduces the risk of people accidentally downloading the wrong thing.
> The point is that it's much easier to make a mistake typing "requests" than " org.kennethreitz:requests" (as a pure hypothetical.)Sorry what? It's strictly the opposite: more character to type equals more risks to make a mistake.In fact, in the general case, namespaceincreasethe risk of supply chain attacks, because it makes packages names even less discernable.
> I know of a few people, personally, who have said thisjiggawatts
> "We're pretending security is not an issue." has been the feedback every time this is raised with the Cargo team.Do you have a specific link where I can read this response, because this is not at all the responses I have read.
Just some random Cargo security-related issues I noticed:- No strong link between the repo and the published code.- Many crates were spammed that were just a wrapper around a popular C/C++ library. There's no indication of this, so... "surprise!"... your compiled app is now more unsafe C/C++ code than Rust.- Extensive name squatting, to the point that virtual no library uses the obvious name, because someone else got to it first. The aformentioned C/C++ libraries were easy to spit out, so they often grabbed the name before a Rust rewrite could be completed and published. So you now go to Cargo to find a Rust library for 'X' and you instead have to use 'X-rs' because... ha-ha, it's actually a C/C++ package manager with some Rust crates in there also.- Transitive dependencies aren't shown in the web page.- No enforcement or indication of safe/unsafe libs, nostd, etc...- No requirement for MFA, which was a successful attack vector on multiple package managers in the past.DISCLAIMER: Some of the above may have been resolved since I last looked. Other package managers also do these things (but that's not a good thing).In my opinion, any package manager that just lets any random person upload "whatever" is outright dangerous and useless to the larger ecosystem of developers in a hurry who don't have the time to vet every single transitive dependency every month.Package managers need togrow upand start requiring a direct reference to a specific Git commit -- that they store themselves -- and compile from scratch with an instrumented compiler that spits out metadata such as "connects to the Internet, did you know?" or "is actually 99% C++ code, by the way".
> > "We're pretending security is not an issue." has been the feedback every time this is raised with the Cargo team.> Do you have a specific link where I can read this response, because this is not at all the responses I have read.Those aren't people saying security isn't an issue but examples of concerns you have which is different.For some of those, there are reasonable improvements that can be made but will take someone having the time to do so. While the crates.io team might not be working on those specific features, I do know they are prioritizing some security related work. For instance, they recently added scoped tokens.For some, there are trade offs to be discussed and figured out.
Sure, but all the drawbacks you enumerate are also advantages for gaining critical mass. A free-for-all package repository is attractive to early adopters because they can become the ones to plug the obvious holes in the standard library. Having N developers each trying to make THE datetime/logging/webframework/parsing library for Rust is good for gaining traction. You end up with a lot of bad packages with good names though.
> Extensive name squatting, to the point that virtual no library uses the obvious name, because someone else got to it first.Maybe the obvious names should have been pre banned. But I don't see the issue with non-obvious names either way you're going to have to get community recommendation/popularity to determine ifbrandonq/xml is better or worse then parsers/xml
In ASP.NET land, I regularly work on projects where there is an informal rule that only Microsoft-published packages can be used, unless there's good reason.You don't want to be using Ivan Vladimir's OAUTH package to sign in to Microsoft Entra ID. That probably has an FSB backdoor ready to activate. Why use that, when there's an equivalent Microsoft package?When any random Chinese, Russian, or Israeli national can publish "microsoftauth", you justknowthat some idiot will use it. That idiot may be me. Or a coworker. Or a transitive dependency. Or a transitive dependency introducedafter a critical update to the immediate dependency. Or an external EXE tool deployed as a part of a third-party ISV binary product. Or...Make the only path lead to the pit of success, because the alternative is to let people wander around and fall into the pit of failure.
Crates.io has publisher information-- namespacing is not required for that. For example, here are all the crates owned by the `azure` GitHub organization and published by the `azure-sdk-publish-rust` team:https://crates.io/teams/github:azure:azure-sdk-publish-rust
fwiw but when I saw a 3rd party library pretty much exactly like "microsoftauth" on nuget, I reported it and it was swiftly removed.I think we need to encourage a culture that package managers are our shared garden and we must all help in the weeding.
> I'm having a hard time thinking of a non-Java package manager that was around at the time Rust came out that didn't have a single, global namespace.Technically not in the same category, but Docker Hub (2014) had namespaces.
php's composer[0] in 2012 had package namespaces[0]https://getcomposer.org/
Sorta—it looks like they were mostly just using that system by convention until May 2015, when they finally become enforced [0]. Still, that's a good one that I hadn't thought of, and they at least had the convention in place.[0]https://github.com/composer/packagist/issues/163#issuecommen...
I'm honestly astounded at how badly many languages have implemented dependency management, particularly when Java basically got this right almost 20 years ago (Maven) and others have made the mistakes that Java fixed. With Maven you get:1. Flexible version (of requirements) specification;2. Yes, source code had domain names in packages but that came from Java and you can technically separate that in the dependency declaration;3. You can run local repos, which is useful for corporate environments so you can deploy your own internal packages; and4. Source could be included or not, as desired.Yes, it was XML and verbose. Gradle basically fixed that if you really cared (personally, I didn't).Later comes along Go. No dependency management at the start. There ended up being two ways of specifying dependencies. At least one included putting github.io/username/package into your code. That username changes and all your code has to change. Awful design.At least domains forced basically agreed upon namespacing.
> Later comes along Go. No dependency management at the start. There ended up being two ways of specifying dependencies. At least one included putting github.io/username/package into your code. That username changes and all your code has to change. Awful design."github.io/username/package" is using a domain name, just like Java. Changing the username part is like changing the domain name--I don't see how this is any worse in Go than in Java.If you don't like that there's a username in there, then don't put one in there to begin with. Requiring a username has nothing to do with Go vs. Java, but rather is because the package's canonical location is hosted on Github (which requires a username).I don't know why so many programmer's use a domain they don't control as the official home of their projects--it seems silly to me (especially for bigger, more serious projects).
Slight difference is that it wouldn't break existing builds if you changed namespaces in Java. The maven central repo does not allow packages to be rescinded once they are published.So that old version of package xyz will still resolve in your tagged build years from now even if the project rebrands/changes namespaces.
Note that in Java it is merely a convention to use domain names as packages. There is no technical requirement to do so. So moving to a different domain has no impact whatsoever on dependency resolution. Many people use non-existent domain names.To be honest I really like how Java  advocated for verbose namespaces. Library authors have this awful idea that their library is a special little snowflake that deserves the shortest name possible, like "http" or "math" (or "_"...).
Java did a lot of things right beyond the language and VM runtime, both of which were "sturdy" by the standards of the early 1990s. Using domain names for namespaces was one nice touch. Having built-in collections with complete built-in documentation was another excellent feature that contributed to productivity.
It may be a convention but in practice if you want to publish your package to Maven Central you need to prove ownership of your group ID domain. (Or ownership of your SCM account, which is in essence another domain).
Interesting, I contribute to a project that releases on Maven Central but the package name has never been registered as a domain.
> I don't know why so many programmer's use a domain they don't control as the official home of their projectsNot only that, but a commercial, for-profit domain that actively reads all the code stored on it to train an AI. Owned and run by one of the worst opponents of the OS community in the history of computing.At least move to Gitlab if you must store your project on someone else's domain.
If youre project is open source, won't everyone who wants it just scrape in anyway?
Yes, #3 in particular is important for many large corps where one team develops a library that may be pulled in by literally thousands of other developers.
The dependency management side of Maven is great. OTOH, I was astounded to learn today that Maven recompileseverythingif you touchanysource file:https://stackoverflow.com/a/49700942This was solved for C programs since whenever makedepend came out! (I'm guessing the 80s.)(Bonus grief: Maven's useIncrementalCompilation boolean setting does the opposite of what it says in the tin.)
Build and test caching is one of the few compelling advantages that Gradle has over Maven. It's a shame that this is still an issue.
Maven and Java really don’t get enough credit for how well it’s dependency management works.So many inferior dependency management systems for other languages have come along later, and learned nothing from those that came before it.
100% agree. It's unbelievable what a PITA it is dealing with pip or npm compared to Maven even 10 years ago. The descriptors could get convoluted but you could also edit them in an IDE that knew the expected tokens to make things happen.
What’s so hard about “npm install” and “package.json”. It’s dead simple
No you see Java devs have stockholm-syndromed themselves into believe that a giant stack of XML, or some unhinged mini-language are actually good, and much better than something the humans involved can actually read and parse easily and now to compensate with other ecosystems providing 85% of the functionality, with 5% of the pain, they’ve got to find some reason to complain about them.
what's wrong with XML? Maven XML is a configuration not a programming language.
"XML is more verbose" is a lazy criticism in the same veign as "Python is better than Java because you can do 'Hello World' in one line".Maven files have a simple conventional structure and a defined schema. Once you learn it, it's a breeze to work with. It's not like you need to write hundreds of lines of SOAP or XLST — which is actually why people started to dislike XML, and not because XML inherently bad.Edit: I'd also take XML over TOML any day, especially when it comes to nested objects and arrays.
For a descriptor verbose is superior. It's way clearer what you're looking at. Matching a named end tag is much easier than matching a }. Also, XSD means you can strictly type and enumerate valid values and you will instantly see if you've written something invalid.
Maven stores every version of every library you've ever needed in a central location. It doesn't pollute your working directory and it caches between projects. And this is more of a Java thing than a Maven, thing, but backwards compatibility between versions is way easier to manage. There's no incompatible binaries because you changed the node runtime between npm install and running your project.
And NuGET, which was inspired on them.
Not even remotely a joke.The inverse-style domain name thing does a really good job of removing the whole issue of squatting from the ecosystem.  You have to demonstrate some level of commitment and identity through control of a domain name in order to publish.I would also say that this putsjust enoughfriction so that people don't publish dogshit.crates.io demonstrates quite clearly that you either have to go all the way and take responsibility for curation or you have to get completely out of the way.  There is no inbetween.
Having tried Java and other languages, no, it's not a joke. Other than XML Maven got a lot of things right.
and i dont particularly think that using xml is that bad. The schema is well defined, and gives you good autocompletion in any competent IDE (such as intellij).It took some iterations before maven 3 became "good", so people forget that it wasn't as nice before now! Unfortunately, it seems that the lessons learned there is never really disseminated to other ecosystems - perhaps due to prejudice against "enterprisey" java. Yet, these package managers are now facing the sorts of problems solved in java.
What the hell is that XML hateWhats the diff between changing lib version in xml and json?
I have no problem with XML in general and even think it's still the better format for many things. But it's not really appropriate for a build config. Thankfully Maven now offers polyglot but I've seen no use of it in the wild.
And you don't even need to use XML with Polyglot Mavenhttps://github.com/takari/polyglot-maven
I think the correct approach is to do full-real-name_good-package-name it might not be practical but it would be legendary.
URLs for packages makes a lot of sense.  It works well in the land of Go.  It also conveniently eliminates the need for the language to have a global packages database.  Upload your package to example.com/your-thing and it's released!  (You can, of course, still offer a cache and search engine if you want to.)
No, URL's don't make sense because your application shouldn't care where on the internet your dependency happened to be hosted when you integrated it. It's location has nothing to do with what it is.By the time you're going to production, your vetted and locked dependency should be living in your own cache/mirror/vendored-repo/whatever so that you knowexactlywhat code you built your project around and knowexactlywhat the availability will be when you build/instantiate your project.Your project shouldn't need to care whether GitHub fell out of fashion and the project moved to GitLab, anddefinitelyshouldn't be relying on GitHub being available when you need to build, test, deploy, or scale. That's a completely unnecessary failure point for you to introduce.Systems that use URL-identified packagescanwork around some of this, but just reinforce terrible habits.
URLs are well structured and unique, with a sensible default - sourcing the file from the internet - and ubiquitous processes for easily mapping the URL to an alternative location.I.e., when you're going to run the production build, the URLs are mapped to fetch from the vetted cache and not the internet.I don't see any downsides to allowing them as a source, or making them the default approach
> and ubiquitous processes for easily mapping the URL to an alternative location.This seems strange to me because the whole point of a Uniform Resource Locator is to specifywherea resource can be located.It's a bit like saying "My project depends on the binder on shelf 7 in Room 42, sixth binder from the left. Except when I go into production, then use...." Don't tell me what binder it's in, tell me what it is.I can see a case made for URIs, which is basically what Java did.
This was a big annoyance for me back in the day when I was dealing with XML namespaces. URLs never made sense for that use case and too many tools tried to pull XSDs from the literal URL which was always generally out of date, some projects switch to URIs like tag uris or URNs and it was much better, imo.
From my experience, URNs really should be used more often for these sorts of things. One thing that AWS got right almost from the get go
Isn’t that why GOPROXY exists though? Not sure why you would need an internet connection. URLs don’t necessarily equate to the internet. Our internal and external packages are all locally hosted and work regardless of the internet being available.
> By the time you're going to production, your vetted and locked dependency should be living in your own cache/mirror/vendored-repo/whatever so that you know exactly what code you built your project around and know exactly what the availability will be when you build/instantiate your project.In the Go world this would be "vendored" dependencies, that is, the dependencies are within your source tree, and your CICD can build to its hearts content with no care in the world about the internet because it has the deps.The URL is useful for determining which version of a specific project is being used - "Oh we switched to the one hosted on gitlab because the github one went stale"The advantage of using gitlab, or github, or whatever public code repository is that you get to piggy back off their naming policies which ensure uniqueness.But, at the same time, there's no reason that the repo being referred to cannot be in house (bob.local) or private.Having said all of that, the Go module system is a massive improvement on what they did have originally (nothing) and the 3rd party attempts to solve the problem (dep, glide, and the prototype for modules, vgo), but it's not without its edge cases.
Isn't that just delegating the problem? URL dependencies do not replace what crates.io does, and a modern language will still want something like it. You'd just end up with most every dependency being declared as crates.io/foo.
URLs form a nice global namespacing system. But yes, I agree that it should be possible to actually get the source from anywhere.Basically the URL of a package name should be primarily the ID, not the locator (even if it is used for location by default).
You can use the `replace` option in the Go mod file to redirect your dependency references elsewhere if you need to.
It worked for the rest of the Internet.
There is something to be said for separating {unique piece of content} and {hosted location}.E.g. doi'shttps://en.m.wikipedia.org/wiki/Digital_object_identifier
You can, though. From a random Cargo package I have downloaded to my computer:[dependencies]
    uniffi = { git = "https://github.com/mozilla/uniffi-rs" }You can also specify revision/branch/etc.Alternatively, you can do:[registries]
    maven = { index = "https://rust.maven.org/git/index" }
    [dependencies]
    some-package = { index = "maven", version = "1.1" }Obviously Maven doesn't host any Rust crates (yet?), this is just a theoretical example. Very few projects bother to host their own registry, partially because crates.io doesn't allow packages that load dependencies from other indices (for obvious security reasons). The registry definition can also be done globally through environment variables: CARGO_REGISTRIES_MAVEN="https://rust.maven.org/git/index". Furthermore, the default registry can be set in a global config file.In theory, all you need to do is publish a crate is to `git push upstream master`, and your package will become available onhttps://github.com/username/crate-name(or example.com/your-package if you choose to host your git repo on there).Personally, I don't like using other people's URL packages, because your website can disappear any moment for any reason. Maybe you decide to call it quits, maybe you get hit by a car, whatever the reason, my build is broken all of the sudden. The probability of crates.io going down is a lot lower than the probability of packages-of-some-random-guy-in-nebraska.ddns.net disappearing
It doesn't help with the failure mode of dependencies disappearing, which forces people that care about it to vendor, which in turn brings its own set of issues.
I don’t work with rust on the regular, but this is so annoying with package repositories in general. No don’t use http-server, it’s bad, instead you have to use MuffinTop, it’s better. And then you just have to know that. The concept of sanctioned package names would be interesting, but probably chaotic in practice as the underlying code behind this sort of alias changes over time. This will remain a part of being a domain expert in any given ecosystem forever I think, hooray!
(You probably agree with me but I'm going to just write one big comment instead of replying to every slightly incorrect comment in the thread)Naming things really is one of the hardest problems. This crates thing is a special case of Zooko's Triangle:https://en.wikipedia.org/wiki/Zooko%27s_triangleCrates.io names are human-meaningful and everyone sees the same names, but it's vulnerable to squatting, spamming, and Sybil attacks.You could tie a name to a public key, like onion addresses do, but it's unwieldy for humans. (NB, nothing stops you from doing this inside of crates.io if you really wanted)You could use pet names where "http-server" and "http-client" locally map to "hyper" and "reqwest", but nobody likes those, because they don't solve the bootstrap problem.It's a problem with all repos because when you say "http-server should simply be the best server that everyone likes right now", you have to decide who is the authority of "best", and "everyone", and "now". Don't forget how much useless crap is left in the Python stdlib marked as "don't use this as of 2018, use the 3rd-party lib that does it way better."So yeah... probably will be a problem forever. As a bit of fun here are some un-intuitive names, and my proposed improvements:- Rename Apache to "http-server"- Rename Nginx to "http-server-2"- Rename Caddy to "http-server-2-golang"- Rename libcurl to "http-client"- Rename GTK+ to "linux-gui"- Rename Qt to "linux-gui-2"- Rename xfce4 to "linux-desktop-3"Then you only need to remember which numbers are good and which numbers are bad! Like how IPv4 is the best, IPv6 is okay, but IPV5 isn't real, and HTTP 1.1 and 3 are great but 2 kinda sucked.Very simple. If a company as big as Apple can have simple names like "WebKit", "CoreGraphics", and "CoreAudio" then surely a million hackers competing in a free marketplace can do the same thing.
I think if you get three to five developers who are enthusiastic about X language, their collective knowledge will select good packages.
> Perhaps my biggest critique is that crates.io has no namespacing. Anyone can just claim a global and generic package name and we mostly have to deal with it (unless you avoid using the crates.io repository, but then you'll probably have more problems...). Some of these globally-claimed generic packages are not really the best package to use.This is true that with no namespace anyone can end up squatting a cool name, but with namespace you end up in an even worse place: no-one end up with the cool names, and it makes discoverability miserable, because instead of having people come up with unique names likeserde, everybody just name their json serialization/parsing libraryjsonand user now needs to remember if they should use "dtolnay/json" or "google/json" (and remember not to use "json/json" because indeed namespace squatting is now a thing), and of course this makes it completely ungoogleable.We've had the namespace discussion for hundreds of time in the various Rust town squares, and the main reason why we still don't have namespace is because it doesn't actually answer the problem it's supposed to address and if you dig a little bit you realize that it even makes them worse.Having a centralized public and permissionless repository opens tons of tricky questions, but namespaces are a solution to none of them.
> and of course this makes it completely ungoogleableDo you really think nobody has ever been able to google a Go import path? Some of these arguments are ridiculous.
If you have a namespace, can't people just globally-claim namespaces instead? like serde/serde or something similar. I feel if you really don't want people claim whatever they want, you have to do the Java package style where namespaces are tied to domain names.
While Java made that notation famous, it was already used in NeXTSTEP and Objective-C, hence why you will see this all over the place in macOS and derived platforms, on configuration files and services.
CPAN has the best model IMHO. Hierarchy that starts with categories. You build on top of the base stuff and extend it, rather than reinvent/fork something with a random name. Result is a lot more improvement and reuse, and more functionality with less duplication. Plus it's easy to find stuff.Perl's whole ecosystem is amazing compared to other languages. It's a shame nobody knows it.
Go made a great decision to namespace packages via this Github style.
And the horrible decision to not make library-level ("module") and code-unit-level ("package") namespacing orthogonal.  The former was an afterthought tacked on since the package system was designed to be used only within Google's monorepo and little care was paid to how it would work when it was released to the public and used more generally.
I want to understand what you just said, but I fear watering your language down a bit might be a tall ask with some people. Would you be willing to eli5 what you believe Go did that was a horrible decision with regards to module/package namespacing?
I think what they mean is: if you see a line like `import git.example.com/foo/bar/baz`, that could be package `baz` inside module `git.example.com/foo/bar`, or it could be package `bar/baz` inside module `git.example.com/foo`.Also, even if you know it's the latter, package namespacing isn't strictly related to directory structure, so `bar/baz` has no specific meaning outside of the context of a go import. They could have used any other separator for package components - `git.example.com/foo:bar:baz` - but instead they chose the slash, making the scheme both technically ambiguous and easy to confuse for an HTTP URL.
Ah that makes sense. I think Go did somewhat stumble a bit in the early days due to this, especially with repositories in GitLab, where GitLab allows essentially a directory tree where your repository can be nested indefinitely in directories like `https://gitlab.com/mygroup/subgroup1/subgroup2/repository`.I still don't think this is a huge issue, to be honest. Not one big enough for me to complain about, for sure. But it's definitely not ideal.
I think he wants them to be treated differently for some reason.
Go packages is yet another design item that I dislike on the language, exposing SCM URLs directly on the source code, and no story for binary caching.
> exposing SCM URLs directly on the source codeIncorrect. You're able to use any URL you control, regardless of where your SCM is located.
Thanks for pointing out you didn't got what the whole point of the wrong design is about.
I am quite open about my opinion regarding most of Go's design decisions.
What is the better decision to avoid name colliding?
This needs to be resolved by every damned language.
Just make signed dependencies a universal default, point to an https page for the package vendor and use the signing key from there.Neither node nor maven ever bothered to solve this, so we end up wandering the Wild West wondering when it will be that HR, or legal, or architecture comes knocking on the door to ask what we were thinking having a dependency on a dynamic version of Left Pad.I'd kinda like to see what Cloudflare and Let's Encrypt could come up with if they worked together on at very least a white paper and an MVP POC.
I don't think that's the real solution.Pay somebody either internally or externally to maintain a repo of all your dependencies and point your code at that. You won't get a left-pad incident. You won't get a malicious .so incident (unless you mirror binaries instead of source code).Like if you ran out of screws to make your product with do you walk around the street and scrounge up some? No, you go to a trusted vendor and buy the screws.
I'm not suggesting scrounging.I'm suggesting that the guys who've repeatedly proven themselves technically competent around security at scale might have a couple of useful ideas regarding how the industry might go about crawling its way out of this little security clusterfuck.And perhaps even stop treating something as simple as a BOM as an enterprise feature, given that the overhead on such things is damned near zilch and the security implications are staggering.https://www.cisa.gov/sbom
There's reasons why Google projects don't go out on the internet to get their 3rd party deps.They're all checked into Google3 (or chromium, etc.). One version only. With internal maintainers responsible for bringing it in and multiple people vetting it, and clear ownership over its management. E.g. you don't just get to willy nilly depend on a new version -- if you want to upgrade what's there, you gotta put a ring on it. If you upgrade it, you're likely going to be upgrading it foreveryone, and the build system will run through the dependent tests for them all, etc.And the consequence is more responsible use of third party deps and less sprawling dependency trees and less complexity.And additional less security concerns as the code is checked in, its license vetted, and build systems are hunting around on the Internet for artifacts.
I actually really like this idea. The community just needs to align on a good, simple, standard approach to mirroring repos...
Maven has signing and you can check the signatures on your dependencies if you care to. Most don't, sadly.
To be fair, all the dependencies in the maven central repository require a signature to publish them.
Agreed. The other thing I don’t really like is that you can’t split up things in the rust namespace hierarchy between crates (something that’s natural with jars in JVM). I would have liked to have defined things so that I could have the unicode handlers for finl live in finl::unicode, the parser in finl::parser, etc. but because they’re in separate crates rust gets upset about finl being defined twice and there’s no workaround for it. There are likely pitfalls I don’t see in what I want, so I live with it.
We have an RFC for this that has fairly broad support that I just need to bug some people some more so we can approve it.https://github.com/rust-lang/rfcs/pull/3243
Would re-exporting partially solve your problem?
As I recall, I could do something where I could have a common root crate  that would import and re-export the other crates with the namespaces modified on the exports and then control which crates are exported through feature gates, but it just seemed more hassle than it was worth.
I don't think a lack of namespace is that much problem. Sure, it is often annoying, but people are creative enough to create a short enough and still available crate name for most cases. Namespacing only makes sense for a large group of related crates---and it wouldn't give much benefit over a flat namespace.As other mentioned though, a typosquatting is a much bigger problem and namespacing offers only a partial solution. (You can still create a lookalike organization name, both in npm and in Github.)
> Some of these globally-claimed generic packages are not really the best package to use.Or it is just a placeholder from a squatter.
I love this lack of namespacing personally, because it means that whatever crate you see in a project is going to be the same as the crate your see in another one. Never need to alias crate names. It happens in Golang all the time and I really think namespacing packages was a mistake there.
Golang's problems aren't due to using namespaces, they're due to delaying too many decisions until too late.Go has namespacing mostly because for a long time it didn't have a package manager at all, so people just used a bunch of ad hoc URL-based solutions mostly revolving around GitHub, which happens to have namespaces andalsohappened to lend itself to aliasing (because a whole GitHub URL is too long).If you want to look at an actual example of namespacing done well, Maven/Java is the place to look. There is no aliasing—the same imports always work across projects.
I don't see the problem. Even with namespaces you'll havebrandonq/xml vs parsers/xml with no clue if one is better then another.Also possibly with some confusion over whether things with the same name are forks or not. May make it a little more difficult to Google. Why not just have brandon_xml vs xml-parser and have a community list of best and most popular libraries?I guess the only issue is that some generic/obvious package names are bad packages. That can have been avoided if they banned/self-squated most of the names. I suppose if you use dns namespaces and actually tie it to ownership of the domain name it might make sense but that would also cause issues(what if you forgot to renew the domain?).
The advantage is one of trust. If the `abc` developers build well known library `abc.pqr` are well trusted then I know I can use `abc.xyz` and everything else under the same namespace without (much) vetting.We could even have `rust.xyz` for crates that are decoupled from `std` but still maintained by rust core devs such as `regex`.
>brandonq/xml vs parsers/xml with no clue if one is better then another.You will have this problem only once. After an initial research you settle on one and move on with life.I don't get how having to vet a dependency is going to be more difficult than before. The process is 99% the same, you still have to do the research work initially in both cases.
Yet to see any proof that namespacing has made things better in other ecosystems, are go style links or other types of namespaced imports any less prone to supply chain risks?It's definitely a good thing that people choose new unique names for crates rather thandijan/base64vsdljan/base64Do understand the desire of having a crate for audio manipulation called "audio" but at the same time how often do we end up with "audio2" anyway? It's an imperfect solution for an imperfect world and I personally think the crates team got it right on this one.
> Yet to see any proof that namespacing has made things better in other ecosystemsIt's really as simple as this: many libraries are generic enough implementing something that already exists. Let's say you want a library to manage the SMTP protocol. On crates.io, of course someone has already taken the "smtp" crate (ironically, this one is abandoned, but has the highest download counts, because it's the most obvious name). Let's say you disagree with the direction this smtp crate has gone, and you make your own. What do you call it?Namespaces solve this problem. You'd instead of have user1/smtp and user2/smtp competing in feature sets. You can even be user3/smtp if you don't like the first two.This is precisely what Java enables too. The standard library is in com.java.*; if you don't like how the standard library does something, you can make com.grimburger.smtp and do it yourself. If you choose to publish to the world, all the more power to you. It doesn't conflict with the standard library's smtp implementation.
This is a common critique, and although I don't have insight into why the original decision to not have namespaces was made, the current outlook is that until issues related to continuity are resolved, it's a no go:https://samsieber.tech/posts/2020/09/registry-structure-infl...
That article starts with the premise that “it’s a feature, not a bug” then goes on to describe a whole bunch of things I consider to be anti-features of a packaging system that has a flat namespace.The first section says it discourages forking. I consider this to be bad. Nobody’s code should be more important purely because it squatted a better name.The Identity section actually makes the case that flat registries make naming harder.The section on Continuity is “we’ve tried nothing and we’re all out of ideas”. Make up an org name and grandfather all packages in the flat namespace into that special org. Also this is already a problem because packages in the flat namespace do get abandoned, then forked, and then we have the associated issues.The section on Stability seems to take it as a given that crates.io should be the only registry. I don’t. It also seems to conflate cargo with rustc for the benefit of the argument.The squatting section describes only anti-features and I don’t consider the author’s legitimate use cases to be legitimate reasons to squat.I think the only legitimate problems that need addressing are the ergonomics of accessing namespaced packages throughout transient dependencies and backwards compatibility with non-namespaced code. But the fact that these are real problems does not, to me, make a flat namespace a “feature”. It’s just easier to implement.It’s okay for it to be a mistake that takes effort and time to fix.
Another option would be to grandfather all packages into their own org. So serde becomes serde/serde. This way you don't need to manage permission rules in the legacy "all" namespace.You get some oddities such as serde-derive/serde-derive but the package owners can choose if they want to move to serde/derive or leave it in a separate namespace.
I like that there are no namespaces, it forces people to come up with unique names rather than naming their calendar crate to be `calendar`.
> It also looks like (soon) you’ll finally be able to configure global lints for a project. Until now, you had to hack your solution to keep lints consistent for projects.> I questioned my sanity every time I circled back around to the Clippy issue above. Surely, I was wrong. There must be a configuration I missed. I couldn’t believe it. I still can’t. Surely there must be a way to configure lints globally. I quadruple-checked when I wrote this to make sure I wasn’t delusional.You create a .cargo/config.toml in the workspace root so it covers all your crates.inside the file:[build]
  rustflags = ["-Wclippy::lint_name_to_warn", "-Dclippy::lint_name_to_deny"]The only limitation is that rustflags are not additive, so if you have other sources of rustflags like the RUSTFLAGS environment variable it will overwrite this setting.
We just have a script that adds the lints to any lib.rs or main.rs files that runs on commit. ezpz
I'm learning Rust because it seems clear that it's going to be important professionally. I wish I loved it, I really do. I see the benefits. But, at least so far, it's one of the most unpleasant languages I've used. I keep hoping that as I gain proficiency, I'll stop disliking it, but as I climb higher on the learning curve, I'm not really warming to it.It's fine. It won't be the only language I'll be proficient in while being averse to it at the same time. But I heard so many people proclaiming their love for it that I expected to enjoy it, too.
As a counter example, I love programming in Rust. Fighting the borrow checker ended a long time ago. Even the errors are rare these days, except in cases I trigger them in order to examine the types. Rust compiler also seems to have improved in accepting broader cases that are valid.For me, the key to understanding the borrow checker was understanding the underlying memory model. Rust memory model is the same as that of C, with some extensions for abstractions like generics. The borrow checker rules seem arbitrary at first. But it's deeply correlated to this memory model. The real value of the borrow checker is when I trigger it unintentionally. Those are bugs that I made due to lapse in attention. What scares me is that another language like C or C++ might simply accept it and proceed.Yet another pleasant side effect of Rust's strict type system and borrow checker is that they gently nudge you to properly structure your code. I can say for certain that Rust has improved my code design in all the languages that I use.
How do you do anything dynamic/cyclic? Like, graphs that need to be updated in runtime?
My experience is that most programs dealing with ordinary problems don't need such complicated data structures. In cases you do, Rust has a few options:1. Use Rust's runtime safety checks, using Rc, Weak, RefCell, etc. It will be as ergonomic as GC'ed languages (no productivity loss). While this has a runtime performance penalty, it will still be mostly comparable to other languages. This works for most use cases.2. If you need the last ounce of performance, just drop all automated safety checks and do it manually using unsafe. Even if you make a mistake, your debugging will be limited to the unsafe blocks. This approach isn't unusual in Rust.3. Use either the standard library or something on crates.io that does what's given in 2. Rust's generics make it easy.This resource deals with these topics in-depth:https://rust-unofficial.github.io/too-many-lists/
1. Option 1 quickly degrades into unrefactorable mess of TypedArenas, nested Rc<RefCell>>, lifetime annotations everywhere, and the like. It is unmanageable, which is why even libraries like PetGraph do not use it.2. No, I don't need every last bit of performance. C++ performance is OK. Or any other sane language like Nim, Crystal, etc. I need async, though, which is yet another hell in Rust.3. This absolutely can't be done with standard library. There are libraries like PetGraph, which solve this particular problem (by some very unobvious approaches and bits of unsafe code), but there are many problems like it which don't have any libraries for it yet.I do have hard problems. I want a language which makes hard problems easy, and impossible problems hard. Rust is definitely _not_ such a language, and it makes me like 5 times less productive, and sucks all joy out of programming.
Use one of the many libraries that have safe abstractions over unsafe code? I don't know why people think you need to roll your own? I guess that's just what people do in c/c++, doesn't seem very productive...https://docs.rs/petgraph/latest/petgraph/
There are definitely no less libraries for C++. I am a scientific software engineer, and occasionally I do develop new things. And Rust makes writing new system-level software way harder, which I don't understand, as it is a system-level language.
I've tried several times to get into Rust and keep bouncing off it. It just feels so non-ergonomic.
The lack of default/named function arguments is what still gets me. It's such an absolute basic programmer ergonomics feature shared by most popular languages; even C++ has had defaults since forever.
It would have been nice for Rust to have Default/named/optional function arguments because the proliferation of slightly differently named functions that do the same thing would go away.
Well, what do you dislike about it?
Good question! There's no single thing, I think, and the things I dislike about it aren't even really technical criticism or the like. They're more... aesthetic? I find the syntax unpleasant, for instance. It's extremely opinionated and a few of those opinions are ones I disagree with.Also, just generally, it tends to make even simple things pretty complex. I understand why and am not really objecting to that, but it does make using it a bit like running with lead shoes.I expect that the latter part may get better as I use it more (but perhaps not -- there are other languages I'm fully competent in but dislike for similar reasons).
I share your sentiment about Rust. Fine language for sure, I just don't enjoy programming in it. Simply put, I don't like using the abstractions that the language encourages.For what it is worth, I found pursuing Zig to be a breath of fresh air. It's a promising alternative in the same space as C (and also Cpp and Rust). Checkout Andrew Kelley's introduction to the language.
Which opinions do you disagree with? For transparency, I tend to find myself agreeing with almost all of its models/abstractions.
There are a few, and they aren't something that I can't live with, of course. A great example of the sorts of things I'm talking about are Rust's insistence on camel case and snake case.
You can turn off certain linting rules in the global cargo config, but yeah I don't see why camel case shouldn't have capitals etc. either.
edit: Whoops. I mean snake case.
The beatings will continue until morale improves.
In what way? I'm not really struggling much with the mechanics or logic of it...
ChatGPT has helped me survive learning Rust.
That's the opposite of my experience. The Rust book helped a lot and going to chatGPT for additional questions usually ended up with bad answers.
> After two decades of JavaScript and decent experience with Go, this is the most significant source of frustration and friction with Rust. It’s not an insurmountable problem, but you must always be ready to deal with the async monster when it rears its head. In other languages, async is almost invisible.I am a former C and C++ programmer who lived calling into pthread almost every week for a decade. I use async rust everywhere now.I don’t get the hate that async gets. In my opinion, everyone should be using async for everything. Including stuff that’s seemingly single threaded “simple” stuff.
I think it is the infectiousness of it. Especially in embedded or wasm contexts, the predominant async may not be the async you want. Wasm being the author's use case would definitely have provided a different perspective.Similarly, I find tasks that use or reuse large buffers to avoid the performance hits from allocation, often benefit from old fashioned thread pools. Bump or shard allocators can make this work ok, but in the cases where you are cpu bound on tight loops of vectorizable operations, thread pools perform better. Async is a good tool, but there are contexts it isn't optimal for.
Recently tried writing some async Rust to compare the error handling when nested async calls are made to how errors are handled in Go, and it seemed like the trivial example I was trying to write up simply couldn't be done without involving Tokio. That barrier simply doesn't exist in Go, or C#, or Typescript.For instance, you apparently cannot `await` in the main function without a decorator you import from, you guessed it: Tokio.
You need an async runtime to run async code yes, and Rust's isn't built in. Why does that matter though? Rust has a decent package manager; add the dependency and move on.
Why are you trying to avoid Tokio lol, tokio is the defacto async runtime in rust, saying you're trying to avoid it is like saying you're trying to avoid async while writing async, somehow people act like if they merged tokio into std and instead of #[tokio::main] or whatever you had to do #[async::main] it would somehow be better.Once you stop fighting the fact that tokio = async rust for 99% of cases, things are quite smooth.
Tokio simply doesn't meet the ise case of some people doing wasm, and many people doing embedded. That isn't a huge deal, just don't use it right?  Except many otherwise usable crates seem to adopt tokio unnecessarily.
If Tokio was the final answer,https://github.com/tokio-rs/tokio-uring/wouldn't exist.
The problem that I am running into at the moment is that a few things like the rhai Engine aren't Send and I am trying to use them in an async closure. What GPT-4 suggested was creating a tokio Runtime inside the thread and then block_on(). I will try it tomorrow. (This is the first significant Rust project for me.)
The answer here is almost certainly one of these:1. Fix rhai::Engine so it is Send (if !Send is unintentional)2. Use tokio::spawn_blocking or normal threads to run the rhai::Engine bits3. Don't hold the rhai::Engine across an await point.Which one depends on rhai Engine details and what you want to accomplish.Doing a block on inside a new thread seems unlikely to do anything useful (unless there's some undisclosed detail that makes it reasonable).I encourage you to ask about this in the rhai repo in a discussion or issue.
1. Not applicable unless it is absolutely required, and not something I will consider until I have exhausted other options, since there is a reason they have not made it Send already. It will likely be quite complex and enlarge the scope.2. I am using a normal thread but when I make it async the compiler wants Send.3. The await point is in code that uses the engine. I am not sure there is another good option, since I need to use an API that has several libraries all of which are async.The block_on is to allow the tokio Runtime created in that thread to execute/poll itSo, thank you for your input, I will test out the suggestion that I mentioned above, and then maybe look into spawn_blocking if that doesn't work.
That ChatGPT suggestion is dodgy. Tokio is going to complain when you create a runtime while in async runtime, and refuse block_on in an async context.You can have multiple runtimes, but create them ahead of time, in synchronous main, and keep a Handle to them.But you probably need:https://docs.rs/tokio/latest/tokio/task/struct.LocalSet.html
> 2. I am using a normal thread but when I make it async the compiler wants Send.This is likely because you are using the multi-threaded scheduler, which requires futures to be Send, even if you’re running only a single thread. This is because Tokio is based on a “work stealing” runtime, so in “normal” operations, expects the futures themselves to be able to be shuffled around threads where necessary.For you use case, try running the single threaded executor, additionally try the “local set” executors. These do not require Send as they are statically guaranteed to be confined to the thread they are spawned on. Block on will also work.Out of curiosity though, how is the interaction with Rhai performed, are you passing around the engine, and executing the code at certain points where applicable? Do you just need certain results from it sometimes? Etc?
Right, GPT-4 explained that much about shuffling. I am trying to do all the interaction with MPSC channels but was still running into issues.I think I have a lot of good advice to go try now. Thanks.
From the rhai Engine docs: `Currently, Engine is neither Send nor Sync. Use the sync feature to make it Send + Sync.`
According to the documentation[0], enabling the "sync" feature should make the Engine Send+Sync.From a quick look at the source, it looks like it switches between using Rc/RefCells and Arc/RwLock.[0]https://docs.rs/rhai/1.16.2/rhai/#enable-special-functionali...
It being !Send means its not safe to be sent lol, that's down to the way they implemented rhai engine not rust. It's just that rust catches that it's not safe to send because of the trait bounds.
You might be able to use the LocalSet (https://docs.rs/tokio/latest/tokio/task/struct.LocalSet.html) to run !Send futures on a single thread.
> In my opinion, everyone should be using async for everything. Including stuff that’s seemingly single threaded “simple” stuff.I learned the opposite, that programmers tend to make everything unnecessarly async when it's not needed causing more complexity and mental load.
Can you please elaborate on this? What's an example of a seemingly single threaded simple task where you would turn to async?Does "use async rust everywhere now" imply "use tokio everywhere now?" Honest question.
The way closures made it easy to encapsulate code and state in an object you can run at any time, async encapsulates code and state for ability to runand pause or cancelat any time.This is handy for I/O that can be interleaved and cancelled. You can (ab)use it for other things like generators or various DIY multitasking operations. It can also be a state machine generator (e.g. AI of actors in a game).But I think OP just meant async for typical networking and DB interfaces. And yes, this usually implies the Tokio dependency.
Programming in Rust is really not like being in an abusive relationship. The compiler is trying to help out as much as possible, especially since rustc has the best error messages in the world.
The OSes want programmers to handle resources correctly, and the Rust compiler makes that task a breeze. We are in a more abusive relationship with our OSes, than the Rust compiler. How about the hardware? Doesn't that need to run assembly in a correct way? That counts as an abusive relationship as well.Rust's error messages are one of a kind. There no other compiler which comes even close.As a side note, i used latex lately, it's error messages are horrendous. What a nightmare to figure out what's wrong by inspecting the error.
Rustc is so good I learnt a lot about the language by just reading errors.
> The compiler is trying to help out as much as possible, especially since rustc has the best error messages in the world.Generally good, but man do I hate how any error in my async function causes every recursive call site to generate an error about how the Future is no longer Send and Sync. Literally an entire console scrollback of errors with the actual syntax error buried somewhere in the middle.
I believe this is in our radar and waiting on the new trait solver, but just in case if you have a repro I would appreciate a ticket to improve the diagnostic.
https://play.rust-lang.org/?version=stable&mode=debug&editio...In this case, the first two errors are clear. The next 3 provide multiple, redundant context blocks. The upshot is that this simple example results in rustc printing 11 lines of useful error messages and 86 lines of useless messages. Add to that the fact that the useful error messages need not be at the top or bottom of the error list, they can be anywhere inside of it, depending on the declaration order.
That is a different problem than the one I thought you were seeing.We do spend a lot of time trying to silence errors that are irrelevant. We also get a lot of complaints when fixing a single error produces a wave of new errors that were hidden due to failures in earlier stages. It's a balancing act.Also, specific errors are verbose in order to give people a fighting chance to fix their issue. An error that is too verbose is annoying. An error that is too terse will leave users in the cold as to what the problem was. It's yet another balancing act.I filedhttps://github.com/rust-lang/rust/issues/117233for you. Could I ask you why you didn't consider doing so when you first encountered this problem?Edit: good news, from the next stable onwards the issue you saw no longer reproduces. You only get the parse errors with your case.https://play.rust-lang.org/?version=beta&mode=debug&edition=...
> Could I ask you why you didn't consider doing so when you first encountered this problem?Thanks for looking into it. I have a filed a bug against Rust before, but that was a clear bug, not a poor error message. Remember, the only time a user sees something like this is when they are trying to do something else. The only reason I looked into it just now is because you explicitly asked.
We consider poor error messages to be bugs. I know most people don't, so I've made it one of my missions to yell it from the mountain tops to encourage people to report more often. We can't fix what we don't know about. The majority of the current good errors were a reaction to things people filed in the past.
Rust's compiler is the first one I've seen to use the wordperhaps.My main gripe is that I still don't fully comprehend lifetimes and the compiler can't really help me every time, because it (understandably) errs on the side of caution.
Whenever you see weasel words like that, it means the compiler knows that the issue you encounteredcouldbe what it is saying but the necessary metadata to figure out for sure is inaccessible to it. It's the problem with classical stage-oriented compilers. A compiler designed for diagnostics from the beginning would end up looking like a plate of spaghetti where you can call type checking from the parser, to give an example.
>It's the problem with classical stage-oriented compilers. A compiler designed for diagnostics from the beginningI'm not sure any compiler, even one "designed for diagnostics," can gather the "necessary metadata" from inside my brain based on my original intentions. If the compiler could unambiguously interpret what I meant to write, it wouldn't have needed to fail with a compilation error in the first place. Whenever I see something like "perhaps" or "maybe" in a compilation error, the information just didn't exist anywhere the compiler could possibly get to, and it's just a suggestion based on common mistakes.
As one of the main people working on Rust compiler diagnostics, I find this comparison beyond distasteful. The tooling is not capricious in its restrictions and we go out of our way to make it communicate to people with as much empathy and support as possible.
I'm sorry you're having a bad experience. I've found changing a couple habits developed in other languages helped me to have a good experience with Rust's diagnostics.1. Reading the error messages. I was used to error messages verbosely printing a lot of details which were mostly irrelevant and letting the programmer sort it out, and I developed a habit of skimming them. I had a better time with Rust when I realized it was giving me information that was mostly relevant, and that I should actually read them.2. Interpreting error messages as feedback rather than failure. I was used to error messages meaning I had done something wrong, and getting them all the time was frustrating. Watching Jon Gjengset's coding videos, I was struck that he wrote code to trigger errors deliberately in order to get feedback from the compiler. I now try to work through Rust error messages the same way I would failing unit tests; I make some small changes, I knock out the errors, and then move on to the next subtask. This keeps the number of errors small and manageable, and gets me into a tight feedback loop with the compiler.Relatedly, I encountered the idea (in a blog post I no longer remember) that the Rust compiler is more like an automated pair programming partner than other compilers. This change in mindset really helped for me; thinking of it as a friendly helper rather than a loud complainer made the work lighter. (That's why I personally don't like the 'abusive partner' metaphor, for me that mindset makes it toilsome and miserable. Also because I've had an abusive partner, and it's nothing like that, and I could do without the reminder.)3. Setting up my IDE to show me inline type annotations and error messages. This made the feedback loop tighter, I only have to drop into a terminal for complex or unfamiliar error messages. With practice I can fix most errors using a one-line summary.4. With practice, I've internalized Rust's semantics, and I've stopped painting myself into corners with unnecessarily cyclic data structures and such. I also read a blog article or maybe a tweet (which I've also forgotten) about giving yourself permission to use Box or clone and not sweating every copy or allocation. It pointed out that if you were writing Python, everything would be an Arc<T>, and you'd think nothing of it; in Rust the performance cost is explicit, so you agonize over it, but a lot of the time it's not a big deal to copy some data or to perform an allocation.
No thanks, that seems a long winded way of saying you're not welcome here unless you think exactly like me.
Wasn't my intention. I'm sorry if I came off that way, I can see how my comment might be presumptive or pretentious. My bad. You don't have to do any of that. You don't even need to write Rust in my book, it's not the one true language or anything. That's just what's working for me personally.My first six months with Rust were very painful and I struggled to write the simplest programs. (This was in fact, the first six months of my second attempt - the first time I tried to learn it, I gave up.) Eventually I learned how to work with it, and since then, it's my absolute favorite language to work in (though presently I mostly write Typescript and SQL, because I'm writing webapps). I tried to summarize what happened along the way and what changed.
I would encourage you to file tickets whenever you encounter deficiencies in the tooling, including bad diagnostics. We take them seriously. As for whether our efforts are accomplishing anything, trying out older releases can be eye opening at how much has changed.
This really is an inappropriate comparison. Can we be serious for a bit? A professional-grade tool providing professional-grade feedback is not remotely like an abusive or even turbulent relationship.
More like "this submission has errors check your work". That's the job of any compiler, Rust was made to be especially strict.If you want sugarcoating or simply rapid prototyping I'd use a dynamic or scripting language instead.
> I started writing tests in Rust as I would in any other language but found that I was writing tests couldn’t fail.This is a common refrain in C++ testing: if it compiles then it's probably correct.> Rust has accounted for so many errors that many common test cases become irrelevantIn practice, if you think this way I think it's a sign that you aren't testing the right things in those other languages. You should be testing business logic, not language stuff.If you look at your test code and think "I would test this in JavaScript, but I don't need to do that in Rust" then just delete the test.
> This is a common refrain in C++ testing: if it compiles then it's probably correct.I’ve heard this in Haskell and in Rust. I’ve never heard it applied to C++…
I think they meant Rust? Rust definitely has that property to an extent; C++ is so far from it it’s not even funny.
I’ve definitely experienced it in Haskell and Rust. I can believesomeC++ could be that way, but I’ve never experienced it, but then again those projects didn’t have useful tests either. I think with C++ a lot of this depends on domain and the quality of the code and libraries.
That used to be a joke at many places I worked at with large C/Cpp code bases. Always said tongue in cheek.
I've experienced it a bit in C++, especially after coming back from JS. But not to the degree of Rust.
No it isn't lol. C++ compiles all the time with bugs.
Is it true enough in c++ to be useful though?
A null pointer exception is a bug that breaks business logic. There's no "business logic instead of language stuff" because the language stuff is the foundation that business logic rests on. If you don't test against failure modes, what's even the point in testing?
To close the loop, Rust doesn't include a `null` type and you wouldn't encounter something comparable in idiomatic Rust (because you'd be using eg Option::map to handle None cases gracefully), so this is a class of test that would be common in Java and C that is close to irrelevant in Rust.
To be more specific, Rustdoeshave among other things:std::ptr::null() - an actual null pointer, probably the zero address on your hardware, and this isn't even an unsafe function. On the other hand, you won't find many uses for a null pointer so, I mean, congrats on obtaining one and good luck with that.std::ptr::null_mut() - a mutable null pointer, similarly unlikely to be of any use to you in safe Rust, but also not an unsafe thing to ask for.But, these are pointers, so they're not values that say, a String could take, or a Vec<String> or whatever, only actual raw pointers can be null.
And even for raw pointers you can use NonNull<T>.
Still someone might call unwrap on an Option and then run into some kind of null pointer exception
Sure, you can panic unwrapping a None, but there are two important distinctions.First, this is a controlled panic, not a segmentation fault. The language is ensuring that we don't access the null pointer, or an offset from the null pointer. Null pointer access can be exploitable in certain circumstances (eg, a firmware or kernel). Your use of "exception" suggests you're thinking about it in Java terms however, and Java is equivalent here.Second, you can only encounter this in explicit circumstances, when you have an Option<T>. Wheras in languages with a null type, any variable can be null implicitly, regardless of it's type.
>First, this is a controlled panic, not a segmentation fault.But a segmentation fault is also controlled>Your use of "exception" suggests you're thinking about it in Java terms however, and Java is equivalent here.No, I am thinking in Delphi terms. It is overspecialized to Windows userspace. Windows gives an Access Violation, and that can be caught, and Delphi throws it as exception>Second, you can only encounter this in explicit circumstances, when you have an Option<T>. Wheras in languages with a null type, any variable can be null implicitly, regardless of it's type.Delphi has both nullable  types and null-safe types
> But a segmentation fault is also controlledA segmentation fault may not happen (which is to say, we may corrupt memory or worse) if the null pointer is mapped into memory (as in an embedded or kernel context) or if it's accessed at a large offset, which results in a pointer that's mapped into memory. This may be rotten luck or it may be exploited by an attacker.> No, I am thinking in Delphi terms.Fair enough, I don't know Delphi. I'll take what you're saying about it as read.
If an exception breaks business logic, then you can test the code by testing business logic.How do null pointer exceptions arise?Inconsistent data: you have code paths that implicitly assume invariants. Trivial cases like “this field is not provided” and more complex ones like “these fields have a specific relationship”.You can often move those assumptions into the data structure in any language.Then your tests become a matter of generating and transforming data from a holistic perspective instead of micromanaging individual code paths.
A null pointer exception is a free runtime check. I really don't understand the fuss about null. The "most expansive design mistake in computer science" and whatever.
Free runtime check of what? The point is that if nulls don't exist,there is no need for a "check". Runtime or otherwise. If I write a type that models Foo, I want it to model Foo and not "Foo or null". If I want to model "Foo or no data" then I use a separate type that makes my intention clear (in Rust spelled `Option<Foo>`). Languages where nothing is precisely Foo and everything is "oh by the way this is only possibly Foo" are deeply, deeply flawed.
There is surely something wonderful about the kind of C++ programmer who figures that, since their unusable broken garbage compiled it's probably correct.Remember unlike most languages you'd be familiar with C++ has IFNDR, which has been jokingly referred to as "False positives for the question: Is this a C++ program?". A conforming C++ compiler isforbiddenfrom telling you in some† unknown number of cases that it suspects what you've written is nonsense, it just has to press on and output... something. Is it a working executable? Could be. Or maybe it's exactly like a working executable except it explodes catastrophically on Fridays. No way to know.† The ISO standard does identify these cases, but they're so vague that it's hard to pin down everything which is covered. My guess is that all or most non-trivial C++ software is actually IFNDR these days. Just say No to the entire language.
> A conforming C++ compiler is forbidden from telling you in some† unknown number of cases that it suspects what you've written is nonsense, it just has to press on and output... something.It's not quite that bad - a conforming C++ compiler is permitted to error out and not compile the program. It just doesn't have to.
Many of the cases of IFNDR are semantic constraints, especially in C++ 20 and beyond. As a result of being semantic constraints it's generally impossible to diagnose this with no false positives. The ISO standard forbids such false positives so...
Can you give a more concrete example of the kind of thing you're talking about? Like, if you try to sort something and your comparator implementation for that type is not transitive, the compiler can silently produce a broken binary?Surely in the undecidable cases the compiler is allowed to produce a binary that errors cleanly at runtime if you did in fact violate the semantic constraint, and any sane implementor would do that. (Not that any sane person would ever write a C++ compiler...)
> Like, if you try to sort something and your comparator implementation for that type is not transitive, the compiler can silently produce a broken binary?It's not merely about whether your comparisons are transitive, the type must exhibit a total ordering or your sort may do anything, including buffer overflow.> Surely in the undecidable cases the compiler is allowed to produce a binary that errors cleanly at runtime if you did in fact violate the semantic constraint,I don't think I know how to prove it, but I'm pretty sure it's going to be Undecidable at runtime too in many of these cases. Rice reduced these problems to Halting, which I'd guess means you end up potentially at runtime trying to decide if some arbitrary piece of code will halt eventually, and yeah, that's not helpful.I've written about it before, but I should spell it out: The only working alternative is to reject programs when we aren't sure they meet our constraints. This means sometimes we reject a program that actuallydoesmeet the constraints but the compiler couldn't see it.I believe this route is superior because the incentive becomes to make that "Should work but doesn't" set smaller so as to avoid annoying programmers, whereas the C++ incentive is to make the "Compiles but doesn't work" set larger since, hey, it compiles, and I see Rust's Non-Lexical Lifetimes and Polonius as evidence for this on one side, with C++ 20 Concepts and the growing number of IFNDR mentions in the ISO standard on the other side.
> the type must exhibit a total ordering or your sort may do anything, including buffer overflow.Sure. But there's no requirement for the compiler to be a dick about it, and hopefully most won't.> I don't think I know how to prove it, but I'm pretty sure it's going to be Undecidable at runtime too in many of these cases. Rice reduced these problems to Halting, which I'd guess means you end up potentially at runtime trying to decide if some arbitrary piece of code will halt eventually, and yeah, that's not helpful.At runtime can't you just run the code and let it halt or not? Having your program go into an infinite loop because the thing you implemented didn't meet the requirements is not unreasonable.I'm sympathetic to the idea that there could be a problem in this space, but without a real example of a case where it's hard for a compiler to do something reasonable I'm not convinced.> I've written about it before, but I should spell it out: The only working alternative is to reject programs when we aren't sure they meet our constraints. This means sometimes we reject a program that actually does meet the constraints but the compiler couldn't see it.> I believe this route is superior because the incentive becomes to make that "Should work but doesn't" set smaller so as to avoid annoying programmers, whereas the C++ incentive is to make the "Compiles but doesn't work" set larger since, hey, it compiles, and I see Rust's Non-Lexical Lifetimes and Polonius as evidence for this on one side, with C++ 20 Concepts and the growing number of IFNDR mentions in the ISO standard on the other side.Meh. I'm no fan of the C++ approach, but I'd still rather see C++ follow through on its strategy than half-assing it and becoming a watered-down copy of Rust. People who want Rust know where to find it.
Historically correctness wasn't seen as an important goal in C++ and so no, I don't think any of the three popular C++ stdlib implementations will do something vaguely reasonable for nonsense sort input. It's potentially faster (though bad for correctness) to just trust that this case can't happen since the programmer was required to use types with total ordering. So yes, I'd expect it to result in bounds misses in real software.
I wouldn't think you could get bounds misses without doing extra comparisons, so I'd expect real-world sort implementations to just fail to sort, which doesn't seem particularly unreasonable. But in any case, it's a huge leap from "existing C++ stdlib implementations behave badly in this case" to "the C++ standard requires every implementation to behave badly in this case".
Can you give an example of non-C++ code that a modern compiler (MSVC, clang, g++ or something) successfully compiles with no diagnostics? I’m genuinely curious. If not, this just sounds like more C++ FUD because the spec doesn’t define everything under the sun and allows a certain amount of leeway to compilers for things like emitting different error diagnostics.
Consider:#define _FOO
  int main() {}Per the C++ standard ([lex.name]/3), this program is ill-formed:> In addition, some identifiers appearing as atokenorpreprocessing-tokenare reserved for use by C++ implementations and shall not be used otherwise; no diagnostic is required. [...] Each identifier that contains a double underscore __ or begins with an underscore followed by an uppercase letter is reserved to the implementation for any use.Thus, the compiler theoretically has the liberty to emit whatever it wants for this program.Neither GCC nor Clang produces a warning under -std=c++20 -Wall -Wextra (Clang only produces a -Wreserved-macro-identifier under -Weverything), and MSVC doesn't produce a warning under /std:c++20 /Wall.In practice, most examples of ill-formed programs where compilers issue no warnings occur with discrepancies between different source files that are linked together; e.g., declaring a function as inline in one file but non-inline in another, or declaring a function with two different sets of default arguments in different files, or defining the same non-inline variable or function in different files, or defining the same inline function differently in different files.
Don't forget since C++ 20 all programs which rely on a concept but don't fulfill the (unchecked) semantic constraints of that concept are ill-formed. This allows C++ to truthfully say that C++ programs have the same properties as Rust programs in this regard, because although most real world C++ may fail those constraints and they aren't checked, as a result those aren't technically C++ programs at all so the fact they're broken and don't do what their programmers expected is magically not the fault of C++ even though the compiler seemed fine with it.
First of all, and most importantly, we're not talking about Undefined Behaviour, which happens at runtime, but about IFNDR (Ill-formed, No diagnostic required), which means at compile time your program has no meaning whatsoever because it's not a well-formed C++ program after all but your compiler doesn't tell you (and because of Rice's Theorem in many cases cannot possibly do so as it can't determine for sure itself)This is a conscious choice that C++ made, and my belief is that once you make this choice you have an incentive to make it much worse over time e.g. in C++ 11, C++ 14, C++ 17, C++ 20, and now C++ 23. Specifically, you have an incentive to allow more and more dubious code under the same rule, since best case it works and worst case it's not your fault because if it doesn't work it was never actually a C++ program anyway...Still, since you decided to talk about Undefined Behaviour, which is merely unconstrained misbehaviour at runtime, let's address that too.For the concurrency case no, humans can't usefully reason about the behaviour of non-trivial programs which lack Sequential Consistency - which is extremely likely under Undefined Behaviour. It hurts your head to even think about it. Imagine watching an avant garde time travel movie, in which a dozen characters are portrayed by the same actor, the scenes aren't shown in any particular order and it's suggested that some of them might be dreams, or implanted memories. What actually happened? To who? And why? Maybe the screenwriters knew but you've no idea after watching their movie.Today a huge proportion of software is processing arbitrary outside data, often as a service directly connected to the Internet. As a result, under Undefined Behaviour the unconstrained consequences may be dictated by hostile third parties. UB results in things like Remote Code Execution, and so yes, if they wanted to the people attacking your system certainly could turn it into a Pac man game.We should strive to engineer correct software. That we're still here in 2023 with people arguing that it's basically fine if their software is not only incorrect, but their tools deliberately can't tell because that was easier islunacy.
> First of all, and most importantly, we're not talking about Undefined Behaviour, which happens at runtime, but about IFNDRFrom the link I posted, from cpp reference, which gives a definition for what constitutes undefined behavior:>> ill-formed, no diagnostic required - the program has semantic errors which may not be diagnosable in general case… The behavior is undefined if such program is executedAnd as for the rest of your argument, you still haven’t answered the one question that matters. Is an executable file with machine code well-defined? If it is, then once you compile a C++ program, the generated binary is well-defined. And once again, all the superfluous arguments about what could happen are irrelevant when there’s no context provided. There’s lots of different types of undefined behavior. An integer overflow by itself does not make your program susceptible to remote code execution. It’s the fact that the integer overflow gets stored in a register that later gets used to write to invalid memory, and then that invalid memory has harmful code injected into it that gets executed.Weshouldstrive to engineer correct software. I agree. It’s all this hand waving about how all undefined behavior is equal that irks me. Because it’s not true, as evidenced by the example listed above about the program that’s “technically” ill-formed C++, but in practice compiles to a harmless program.Engineeringrequires anunderstandingof what could go wrong andwhy. Blindly fretting about all undefined behavior is useless and doesn’t lead to any sort of productive debates.Engineering is all about understandingtradeoffs. Which is one of the reasons the C++ spec does not define everything in the first place. The fact that in 2023 people don’t understand that all decisions in software come with atradeoffislunacy. And once again, I agree that undefined behavior is bad, but to pretend that the existence of IFNDR means the whole language is unusable is silly. People use C++ everyday, and have been for almost 40 years. I’d like more productive conversations on how rust protects the user from the undefined behavior that makes an impact, not about how it doesn’t have IFNDR because that’s irrelevant to the conversation entirely.[0]:https://en.cppreference.com/w/cpp/language/ub
> the one question that matters. Is an executable file with machine code well-defined?While you've insisted that's somehow the one thing which matters I don't agree at all. Are programmers getting paid to produce "any executable file with machine code" ? No. Their employer wanted specific executables which do something in particular.And there aren't "different types of undefined behavior" there's just one Undefined Behaviour. Maybe you've confused it withunspecifiedbehaviour ?In the integer overflow case, because that's UB (in C++) it's very common for the result to be machine code which entirely elides parts which could only happen under overflow conditions. Because overflow is UB that elision didn't change the program meaning and yet it makes the code smaller so that's a win - it didn't mean anything before in this case and it still doesn't - but of course theeffectmay be very surprising to someone like you.The excuse that "We've done it for decades therefore it can't be a bad idea" shouldn't pass the laugh test. Did you notice you can't buy new lead paint any more? Asbestos pads for ironing boards? Radium dial wristwatches? "That's a bad idea, we shouldn't do that any more" is normal and the reluctance from C++ programmers in particular shows that they're badly out of touch.
I feel like Rust finally broke the idea that programmers should be in complete control and completely conscious of everything the compiler is doing.  It hasn't been that way in decades, compilers are freaking magic.  But Rust undid a lot of that with borrowing.  People became comfortable with the compiler knowing better than them.  I just wish we could relax further:  We should never be explicitly iterating forward over a collection unless we need this behavior for the algorithm.  Things should be implicitly parallel.  Etc.  Give me rusty bash.
That seems entirely opposite to my Rust experience.Rust is quite transparent in what it does, and is very conservative with compiler magic. The language doesn’t do heap allocations, doesn’t do reference counting, it doesn’t even have implicit numeric type conversion. It won’t implicitly copy types that did not ask to be implicitly copyable, and even that is only legal for types that can be copied with a simple shallow memcpy.Rust uses zero-cost abstractions all over the place, which means it’s predictable what code they will compile to, and that will be typically something simple. Std types have well-known basic layout, so you know that e.g. iteration over a Vec is going to be a loop incrementing a pointer, and there’s no implicit parallelism.Describing borrowing as “compiler knowing better than the programmer” is a weird way of looking at it. Borrowing is like type checking. You declare a type to be temporary, and try to use it as long-lived, you get an error. It’s the same as if you declare function to return struct Foo, but returned struct Bar instead. Yes, compiler “knows better than you”, because you just wrote a bug.Borrowing still compiles to direct pointer usage without a GC (it’s literally guaranteed to be identical to a C pointer in C ABI structs and functions), and you can override lifetimes with unsafe if you think know better than the compiler.
>  We should never be explicitly iterating forward over a collection unless we need this behavior for the algorithm. Things should be implicitly parallelThere is already a crate providing parallel iterators. You just rename the iter() call and that's it. I don't agree it should be implicit though.
It’s called Rayon for anyone who wants to know.
I think "not in control of what the compiler is doing" is overstating things a little bit. In some ways, Rust gives the programmer more control than C does. For example, Rust has standardized support for inline assembly, but inline assembly in C relies on vendor-specific extensions.But to your point, theconvenient defaultsare very different. Unsafe typecasts require a lot of ceremony and careful thought in Rust, and they have to follow more rules than in C. In particular, references are all effectively "restrict" in Rust, and it's really easy to screw that up when you do unsafe cast from raw pointers to safe references, which is a big incentive not to write code like that if you have a choice.
> but inline assembly in C relies on vendor-specific extensions.Whereas Rust is a standard with multiple implementations?
I should've said "stabilized" instead of "standardized" to avoid stepping on this conversational landmine. But an important practical difference is that Rust supports inline assembly on Windows. (Correct me if I'm wrong, but I think MSVC mostly does not support inline asm.)
It does support inline assembly [1]. However, it's different than the way GCC supports inline assembly. It seems nicer, TBH.[1]:https://learn.microsoft.com/en-us/cpp/assembler/inline/inlin...
From that source:> Inline assembly is not supported on the ARM and x64 processors.
Oh, my bad. I should have read the source more closely. I hadn't realized only 32-bit x86 processors were supported.
That's hilarious. Like, the compiler team had ONE GUY that believed in and developed this feature and retired in 1999.
As someone who does a lot of unsafe rust, including tagged pointer foo, I strongly disagree.If anything I want more explicit control, alleviated with an even more expressive type system. Ideally rusts type system would just be a prolog variant imho.
Anyone that can reliably and off-the-cuff do all of these can have complete control back:https://en.wikipedia.org/wiki/Category:Compiler_optimization...Otherwise we should trust compilers to know better.
No thanks. Rust compile times are already too slow.
> Give me rusty bash.Bash with types (especially floats), fewer edge cases, functions with explicit parameters, simple command line flags...
You're skipping the most needed improvement of all: fixing the issue where scripts with unquoted variables will seem to work until they contain a space. Almost every single bash script of more than a dozen lines I've seen outside of large open-source projects fails if a user puts a space in a file path, because the programmer didn't understand the insanity of variable quoting rules! I don't know of any programming language with a more common major footgun.
Shellcheck does cover that. I think the bigger problem is people programming without warnings (in any language).edit: Although I can see that if they hadn't made string splitting the default, it would have saved a lot of headaches.
We use a Kotlin scripting variant for our own shell scripting needs at Hydraulic, it's pretty nice because we've joined it with a lot of internal APIs that make working with the filing system and network easy. It fits all those requirements and more (you can declare flags easily at the top level, it has built in progress tracking for slow operations etc).The Kotlin type system is comparable to Rust without the borrow checker. It has non-null types, generics, etc.It's not really a "product" per se but there's an old version for download and some lightweight docs here:https://hshell.hydraulic.dev/We've never worked out what to do with it. Ideas and feedback welcome. It's pretty nice to use, albeit you need to use IntelliJ to edit scripts if you want IDE features.
You can checkhttps://github.com/rust-shell-script/rust_cmd_lib
Check out nushell, the Rust of the shells.I know it’s still not 1.0. Then just get fish. At least would save some keystrokes.
Fish is an easy alternative. Thanks.
Now you have me curious - where do you see the need for floats in shell? You are more creative than myself, because I am struggling to come up with a situation where I would lean on this. A "path" type would be by far more useful to my work.
I have a script which uses wmctrl to tile windows when I press a shortcut key (for when I'm using an editor and want the editor window to take up most of the screen).I guess I could avoid floats using multiplication, but I would rather keep the code as simple as possible.
Sounds like nushell:https://www.jntrnr.com/case-for-nushell/
Arguably memory managed languages are the same or are you speaking to some specific slice of the available programming languages?
It has unpredictable performance because of lazy evaluation. Other high-level functional programming languages like OCaml, Standard ML, and Scheme can be compiled and achieve fairly high performance.
Learning when to invest in type constraints and when not to is an important lesson. It’s not unique to rust, though it might express a little differently. I’ve dealt with excessively typed c++ and excessively abstracted and typed Java and they have the same class of refactoring problems. I’ve also dealt with plenty of undertyped and under documented go, where there are specific values all over the place which turn into runtime footguns - and these can be truly dire to refactor as well, you get an earlier sense of progress but you ship bugs to users most of the time. There’s no magic answer to this set of trade offs. Rust gives you tools to mostly pick your place, on this specific axis it provides an unusually broad choice.
"Rust screams at you all day, every day, often about things that you would have considered perfectly normal in another life."A good C compiler does this when you turn on all the flags. I like languages/compilers that let you selectively disable the screaming and let you write bad code on purpose. Bad code that works but can be written fast is often better than perfect code that takes forever to write. Once you have a bad but working POC, you can make it less bad."It’s got no problem attracting new users, but it’s not resulting in dramatically improved libraries or tools. It’s resulting in one-off forks that handle specific use cases."Age has nothing to do with that. Attracting core devs is hard, and putting lots of effort into making it attractive is necessary. On top of that, cultural conventions are set by the early adopters, and a lack of convention is often just as sinful as a bad existing convention.Take Python for example. They took a lackadaisical approach to development and runtime environments, and as a result there's 50 competing ways to develop or run a Python program. Their most-used package repository, PyPI, has been a mess for years. Nobody builds on top of existing packages, names make as much sense as a random word generator, the ecosystem is rife with malware, you can't even search for a package on the command line, etc etc. None of that is the language's fault, it's the community and core team's fault for sitting on the sidelines rather than leading. Culture matters more than the tech it's centered around.(I'm not trying to pick on them, I just know their problems better. C has been around for a half century and its community never really put together half the solutions more modern languages did)
> A good C compiler does this when you turn on all the flags. I like languages/compilers that let you selectively disable the screaming and let you write bad code on purpose. Bad code that works but can be written fast is often better than perfect code that takes forever to write. Once you have a bad but working POC, you can make it less bad.Rust supports that. Just mark everything unsafe.
That doesn't really work. All unsafe lets you do is dereference pointers or call unsafe functions. That's not gonna speed your development up during prototyping.You can instead wrap everything in Arc<Mutex<T>> and .clone() liberally, though.
Always find it funny that people think unsafe {} means that rust ignores everything in the block, it just enables 4-5 additional abilities that are well documented, it's still doing most of its safety checks.
It will work if you only use raw pointers everywhere, like it's C. Don't use slices or strings; just pass a pointer to the first element of an array, and either pass its length separately or provide a sentinel value (like C's null terminated strings). Navigate balanced search trees using aliasing, raw, mutable pointers. Etc. This person compares the translation of C to Rust, literally versus idiomatically:https://cliffle.com/p/dangerust/There will probably be weird behavior, though, because Rust optimizes based on assumptions about boxes and references. For example, if you have 3 raw pointers to some object live at once, and you give some library function a mutable reference made from one of those pointers, the compiler will optimize assuming it has exclusive access to that object, and it may make incorrect assumptions.
> All unsafe lets you do is dereference pointers or call unsafe functions.And all those let you do is drop lifetimes and wave goodbye to the borrow checker. You just have to be explicit about it.(What I mean is, the borrow checker checks borrows, it checks references. In unsafe you can make a reference forget what it's referring to. Just change &'a T to &'static T, and then the borrow checker is doing nothing.)
That doesn’t turn off the overwhelming majority of Rust’s soundness checks. `unsafe` isn’t a magic “let anything fly” switch.
80% of crates have no unsafe code in them.
I'm interested in what went into this number.I checked the six most recently published crates on crates.io (blablabla, nutp, tord, g2d, testpublishtesttest, hellochi, at the time of writing). Three of those (blablabla, testpublishtesttest, and hellochi) did some variation on printing `hello world`. g2d seems like an interesting graphics library. tord provides a data structure for transitive relations, which is also neat. No crate contained over 250 lines of code. Unsurprisingly, none of them contained unsafe code.Elsewhere in this thread, it's been pointed out that as a consequence of crates.io having a global namespace, plus lax enforcement of an anti-squatting policy, there are a lot of namesquatting packages. Those presumably contain no unsafe code.tokio contains unsafe code. rand contains unsafe code. regex contains unsafe code. time contains unsafe code. (method: a smattering of packages chosen from blessed.rs; result: every one that I checked except serde containing unsafe code; epistemic status: eh -- I grepped the codebases, ignoring things that were pretty clearly tests, but might have accidentally included some example code or something that's not part of the core library? Please let me know if I've misattributed unsafe usage to one of these projects, or if I've managed to select a biased sample!)I'd certainly believe a straightforward reading of the claim "80% of crates have no unsafe code"...but that seems almost meaningless, given that a not-insignificant portion of crates contain basically no code at all? I'd be much more interested in a weighted percentage by downloads: I'd be wildly impressed if 80% of crate _downloads_ contained no unsafe code, and would be somewhat unsurprised if the number was well below 50% -- crates with more functionality would be more useful and therefore more download, but also more likely to use unsafe code, I'd imagine.Edit: I just noticed crates.io has a most-downloaded list[0] -- I might end up running some numbers on top packages there tomorrow morning, for some more solid data.[0]:https://crates.io/crates?sort=downloads
What is the fact that many foundational ecosystem crate contain unsafe code supposed to prove? That's the entire point of the language. That someone writes a really good regex crate once and then the rest of us don't have to write unsafe to use it. It seems like you have a fundamental misunderstanding about the goals and purpose of rust.
Libraries safely wrapping unsafe code in safe interfaces, and everyone reusing those safe interfaces is like, the whole point of…reusable libraries???Also, you’re replying to someone who I’m fairly sure is on one of the core Rust teams, if not closely involved, I’m somewhat more inclined to trust _them_ when they say 80% of libs don’t contain unsafe (given that it cleanly meshes with my own experience of Rust libraries).
Instead of looking at the crates themselves, you might want to check your (or others') Rust application withhttps://github.com/rust-secure-code/cargo-geigerto get a sense of effective prevalence. I also dispute that thepresenceof unsafe somewhere in the dependency tree is an issue in itself, but that's a different discussion that many more had in other sub-threads.
Don't forget to include transitive dependencies as well.
I wonder what the ratio of utilization of that 80% is compared to the 20% that do have `unsafe` all over the place.
Note that a crate havinganyunsafe and having unsafe all over the place are two different things.
No, 1/5 of Rust code contains unsafe directly. Also, "the" point (in the area of safe/unsafe) is to manage unsafety and provide safe abstractions from unsafe foundations. If you go deep enough there's always something which will be unsafe (the type system would have to able to proof the whole universe otherwise), but most programmers will not have to write such code themselves (no, most of use do not write double-linked lists each day) - they can just use it (e.g. by using the standard library). And if they have to write unsafe code the unsafe parts are restricted to certain areas of their code. Areas they can then invest extra time and care to make certain their assumptions hold true.
It could also be stated as "1/5 of crates interface with the OS, FFI, or hardware or use pointers for fancy data-structures".
Ya i'm sure "no improved libraries" is why linux and even windows have started porting components over to rust.
At the risk of getting downvoted into oblivion, that sounds a lot like TypeScript (compiler yelling at you to fix things but you just want to try an idea without perfecting it).
I'm glad to see there's a wide range of opinions here.I'm not too concerned with performance or safety (since my code hasn't been seen very often).I use rust just because it has a lot of "libraries that help me develop".While other language libraries have a poor search experience and ranking system, Rust has a great library search system.I use it because I don't have to read blog posts like C/C++ or java to find libraries that help me develop, or wade through unnecessary libraries like C# or go, I can use the rankings, and it has a good documentation system.
This has mostly been my experience too. I like using Rust because it reduces the cognitive load I have to deal with for many things (performance/safety are nice, but not a priority).As you've said, finding great libraries is easy, and so is adding/building them. I find this a nice change from e.g. Python (where there are so many way of different competing ways dealing with packaging/dependencies).Also thanks to the error handling, sum types and the like, I don't have to worry so much that I've deal with all errors, handled all enum variants, etc., the compiler takes care of that.
Some days I have misgivings, but not about the language. About the crate situation. Too many important low-level crates stuck at 0.x. I've previously written about problems with the high-performance 3D graphics libraries, but only game devs care about those.At the language level, the big problem is back references. Sometimes you do need them, and the only safe way to do them at present involves reference counts in the forward direction and weak references in the back direction. Then you have to call .borrow() and .upgrade() too much. I'd love to see a static analysis solution to that.(Rough outline of such a solution: Owning object belongs to Owner trait. Owned object belongs to Owned trait. Owned object has .owner() and .owner_mut() functions which retrieve references to the owner.
Owners probably have to be pinned, so they can't move while a back-reference exists. If an Owner changes a reference to an Owned object, the back reference is automatically updated.That's the easy part. Now figure out how to prove by static analysis that a specific use of this does not violate Rust's no-aliasing rules (N read-only, or 1 mutable). This looks do-able for the non-mutable case, because having a non-mutable reference to both owned and owner is OK. Mutability, though, is tough. Anybody thinking about this?)
> Too many important low-level crates stuck at 0.x.Is it fair to say that Rust failed to supply a robust set of standard libraries comparable to other modern languages? Or was the language aimed at level geared towards implementing rather than providing libraries? If it's truly a systems language, then what library features are essential, and what are 'nice to have'?
IMHO a lot of these 0.x libraries would be called 3..In other languages
S.They often have better quality than what I find in "mature" packages in npm or PyPi.Rust kind of has a perfectionist touch to it which makes it really hard to say "this public API is stable". So people stay at 0..way longer than normal.I'm fine with that.The lack of namespacing and heavy namesquatting is rather what's annoying.
There was a conscious decision to avoid providing a vast standard library because those inevitably become outdated with time. Building a standard library is relatively easy, maintaining for decades is hard.But it’s a trade off because there are concrete upsides to a large standard library. I wrote about this more - Rust has a small standard library (and that’s ok) -https://blog.nindalf.com/posts/rust-stdlib/
That does seem to align with my perception of where Rust wants to be: a low-level systems language. For example, the stdlib provide a time package that deals with duration and instant, sufficient to interact with file systems and such, but leaves dealing with dates, times, and all that complexity to the chrono crate.What I would encourage the Rust community to focus on is adding security-sensitive functionality to the standard library. Not the big wad of complexity that is cryptography, but a standard PRNG/RNG/CSPRNG would fit.Also, I do think it's a bit of a mistake to not at least define a relational database API. As it is we have sqlite, mysql, and postgres with similar but slightly different APIs.
Not quite.I don’t think low level languages mean you need a small standard library and high level means you need a large one. You’re pattern matching between Python, Java, Go (all large, older) and now Rust (small and newer).Rust wants to be high levelas well, allowing people to solve all kinds of problems of varying complexity in different domains. And to some extent, Rust has succeeded in empowering folks to do this. Rust has found its way into “systems” like browsers (Chromium, Firefox) and Operating Systems (Windows, Linux) but also web software, infrastructure (firecracker), developer tools (ruff, turbopack) and other domains.Like I said, the request for a larger standard library is a reasonable one. But I don’t think it’s going to happen, because Rust seems to be gaining traction in multiple domains without it. By the numbers it looks like it’s growing 10x every 3 years (https://lib.rs/stats). In such an environment, the folks at the wheel would double down on their approach rather than fundamentally rethinking it.
> Now figure out how to prove by static analysis that a specific use of this does not violate Rust's no-aliasing rules (N read-only, or 1 mutable).Out of curiosity, is there any existing language (including research languages) that can do this already?
Not that I know of. But few other languages have a borrow checker.You can do this in Rust at run time, with Rc, Weak, and .upgrade().unwrap(). If none of the .unwrap() calls fails, you did it right. If you can prove the unwrap calls can't fail, you don't need the run time checking. So the goal is to check at compile time something you can now check at run time at higher cost. That's what Rust is all about.
"Want to use an async library? There’s a chance you can’t use it outside of a specific async runtime."I complained about this here[1].  I'm told "Tokio won, it's not a problem anymore."  Wrong.  It's still a problem and it's a killer.[1]https://news.ycombinator.com/item?id=37892655
Can you help understand why somebody wouldn't use Tokio/why it didn't "win"?
Tokio isn't the fastest conceivable runtime.  Tokio isn't the smallest conceivable runtime.  Tokio isn't the simpilist conceivable runtime.  Tokio does not port to all conceivable environments.  Tokio isn't the async-std runtime.And so, for some or all of these reasons, right or wrong, various Rust libraries wed themselves to runtimes other than Tokio.You can thunk around these things, but it's miserable, yielding subtle, inscrutable code that you willnotunderstand in six months when you have to maintain it.  And the real fun begins when you need to handle Err, and all the abstraction leaks around Send and threads ruin your day; more thunking, Boxing errors (omfg) and even subtler and more inscrutable code.
Is this to say async-std is faster + smaller + simpler + more portable than Tokio?
I think what they were trying to say is that Tokio ended up being a general purpose async runtime so naturally it can't be the most optimal solution for every case. But because various libraries kind of force you into Tokio, it's very hard to use a runtime that's optimal for your specific problem. You'd have to give up on a lot of convenient libraries out there.
Yeah those are terrible responses.Tokio monoculture is a serious problem.
On the supposed "monoculture":First, I have to wonder whether any of this can be legitimately elevated to the level of a "culture."  Right now, according to GitHub "insights," tokio-rs has approximately 2.0 regular, every day contributors.  And that's the most widely used Rust async runtime.  Everything else is likely even more thin.Second, Tokio has a lot of share because it was early and aggressive in actually delivering usable async documentation and code.  I recall, years ago, reading Tokio documentation on how futures worked and grasping these concepts all the way from file descriptors one might epoll() in C, up to the Rust abstractions, and thinking "hell, I could write an executor from first principles based on this."  Tokio earned the advocates it has, as oblivious to the real state of things as some of them might be.I think the real problem is that async Rust is incomplete.  As I said elsewhere, async Rust syntax is fine.  The implications of async Rust exposed some papercuts in the language that have had to be dealt with since, but the core syntax is fine.  I believe that can be attributed to the serious minded attention that the syntax received from people way, waaay up the cognition curve.  The part that didn't get enough thought was async runtimes.  In an ideal world, one would develop a Rust library that utilizes and/or implements asynchronous calls and transparently, flawlessly run on any correctly implemented runtime alongside any other number of libraries also utilizing and/or implementing async calls.That is not the case, and the damage that's doing is severe.  For every one person, such as myself, that will dare attempt to articulate this pain and, in the process, certainly revealing clear evidence of blatant ignorance, a thousand others just silently gave up.
Yes I think we agree, though I'd quibble about the async syntax; I use it but I have philosophical concerns about it. But I do think tokio is on the whole well implemented.  But it is not a good thing for a single runtime to dominate the language like that.I've at least thought-experimented with what it would take to write my own code agnostic enough that it could run on both e.g. tokio and e.g. monoio etc. and, well, it just can't happen. Even if you find neutral/unbundled implementations of locks, channels, utilities, to depend on instead, you end up stuck at: task spawning, and any kind of I/O. The former, to me, is a glaring absence from the language standard; async should not have gone out the door without support for it.
I can't argue too much on your view of the syntax.  I employ the weasel word "fine" because my experience with it is that I have little to no trouble understanding and using async Rust syntax: I can read and write async Rust and conceptually grasp what is likely going on in the runtime.  I have to allow that perhaps it isn't sufficient, and maybe even that this is a factor in the runtime problem.But there are other, non-syntax issues, such as synchronization primitives, IO events, etc. that are clearly underspecified.  No maybes about it.
> I am a massive proponent of test-driven development. I got used to testing in languages like Java and JavaScript. I started writing tests in Rust as I would in any other language but found that I was writing tests couldn’t fail. Once you get to the point where your tests can run – that is, where your Rust code compiles – Rust has accounted for so many errors that many common test cases become irrelevant.I wonder whatkindof tests the author was writing? The test cases I write for my code is for weird edge cases I detect during testing, like parameter over or underflows, correctness of parsing functions, etc. Things that do fail. I don't get why you'd write tests for trivial things thatcan'tfail.
When writing in loosely typed languages, some folks aim for 100% line coverage, to make it more feasible to refactor down the line. Which then of course ends up being a lot of tests for fairly basic stuff that the type system could help you with...
I think such tests are pretty useless regardless of language. If you work on say a banking system testing whether getBankingStatement() returns something of type string is a waste of time. It just slows you down when you refactor its return value to a BankingStmt instance. While testing what happens in low memory conditions when a user simultaneously deposits and withdraws while another user issues a charge back against them is extremely useful.
line coverage but alsobranchcoverage. Every safe navigation operator used in "defensive" coding, ex. `foo?.bar` is actually another branch that needs to be covered if that's the metric people are using. All of those tests are unnecessary in a language where the type is known at compile-time.
My experience with folks proudly proclaiming "100% coverage" is that it's typically "just" line coverage, even if you're obviously right.
Unfortunately, those are usually the kinds of tests people write. Rust just makes the uselessness more obvious.
I never programmed in Rust, but I had enough experience in C programming to know that segmentation faults are annoying to debug. I heard Rust prevents memory management problems at compilation level, so it forces you to create safer program. Given this, I want to ask Rust programmers here: For people who have no experience in managing memory at coding stage (basically programmer who have no experience in C-like language), can such people appreciate what Rust aims to deliver?
For people who've never written C or C++, Rust's biggest selling point is usually performance. Porting code from Python to Rust for example often gives 10-100x speedups right off the bat. You could get the same speedups by porting to C too, but Rust lets you do that without giving up the memory safety and package management convenience that you're used to.Even when you don't care about performance, another issue that comes up sometimes is keeping track of mutable state. If you've ever relied on bytes instead of bytearray or tuple instead of list* to guarantee that no mutation is happening in some Python code, you know what I'm talking about. Rust can give you a similar level of control over who gets to mutate what, without making you change the type of your data or pay the cost of copies. It's basically the const/non-const distinction from C, but much stricter. Another way of saying the same thing is that Rust gives you a lot of the legibility/correctness benefits that you'd expect from a functional programming language, but you get to code in the usual imperative style.* And even then, that only prevents assignment to the elements of the tuple. You can still mutate an element internally if it's not also an immutable type.
>> Porting code from Python to Rust for example often gives 10-100x speedups right off the bat.As long as you don't do a couple of things that, while easy to remember not to do once you know them, a programmer used to languages like Python and Javascript might be oblivious to.  Things like:* Forgetting to use buffered IO wrappers* Using println!() for high-volume console printing rather than locking stdout and writing to it manually
I think so, I wrote an entire video game from scratch in Rust and my experience has been absolutely delightful. I have to manage nulls via Options, cast things explicitly, cannot do dumb stuff like modifying an array while iterating it, etcetera. It’s guiding my code in ways that I wasn’t able to myself, and eventually leading to essentially what is a bug-free game. Imagine!The experience has been far more than just borrow checking, it’s opened up my mind to a lot of concepts that my previous trials with Java, JavaScript, and Python fully obscured in arcane ways. Rust’s compiler is wonderful, and once you get past the ergonomic struggles (which I did by just going through Advent of Code), you’re set.
I’m not sure.  Looking through different Rust libraries, I tend to see three different styles, depending on previous programming experience.  Each mimics the prior experience, with benefits.* Everything is a struct with concrete types.  This is closest to C.  It benefits from the improved memory safety, without sacrificing speed.* Everything is a Box<Rc<T>>.  This is closest to dynamic garbage-collected languages, but with vastly improved performance.* Everything is an “impl Trait”.  This is closest to templated C++, but with much better ergonomics.So, while I think I agree with your specific statement that the improved memory management may only be fully appreciated by those that cut their teeth on C’s segfaults and dangling pointers, I don’t think that’s the only benefit of Rust as a language.
> * Everything is a Box<Rc<T>>. This is closest to dynamic garbage-collected languages, but with vastly improved performance.Wait, reference counting everything all the time is faster than normal garbage collection?
I think more importantly it is reference counting across threads, meaning mutexes and breaking memory barrier with large performance penalty.
I believe you're discussing 'Arc'. 'Rc' is not thread safe.
then this is not "closest to GC languages", since GC langs usually provide memory management with respect to concurrency.
It's probably slower, but unlike normal GCed languages, it's not actually anywhere close toeverything.
Many garbage collectors (e.g. CPython’s) will use reference counting as part of the process.  If a reference count hits zero, the object can be destructed, prolonging the time between mark-and-sweep passes.The performance difference, though, is mainly in switching over to a compiled language in the first place.
> Everything is a Box<Rc<T>>. This is closest to dynamic garbage-collected languages, but with vastly improved performance.Why the `Box`?
Mostly to mimic the data structures allowed in languages where objects are held by reference.  In Python, I could write a tree structure  as `namedtuple(“node”, [“lhs”, “rhs”])`.  If I tried to write a similar structure in Rust as `enum Node{Leaf, Branch(Node, Node)}`, the compiler rightfully complains that it would have an infinite size.  But the indirection introduced by Box would let it be stored as `enum Node{Leaf, Branch(Box<Node>, Box<Node>)}`.
I think what the previous poster is pointing out is that Box<Rc<Foo>> is an unnecessary double indirection.
If you're used to e.g. OCaml, and the problem you're solving does not require avoiding GC, then Rust is a more cumbersome language for no real benefit.If you've never used an ML family language then Rust might still be a breath of fresh air even if you don't care about memory management.
In my opinion, until you have spent a lot of time debugging C/C++/assembly issues (memory corruption, null pointer crashes, segfaults, build system problems, exception inception, etc),  Rust would probably seem like a total waste of time.
I dunno if it's just me but coming from typescript and c# background it honestly wasn't that hard to grasp things, Maybe it's just me but it seems so much easier to grasp than C.
In that scenario Rust can be attractive because of its high performance compared to languages with a garbage collector. No matter what Java fans will tell you, any runtime with a GC will have worse overall performance for most large codebases than a compiled language with no GC. Sure, microbenchmarks might not look too bad, but complex software is a different matter.Rust is great for services such as API endpoints, where low latency and high throughput at a low cost are more important that hot reload during development.
I heavily appreciate the simplification of the memory model. I was able to go from comfortable with typescript/js to comfortable with rust with essentially zero knowledge of manual memory allocation in just a few months.
disclaimer: I'm not a big rust programmer, but I appreciate it.I think it's a matter of perspective/background. Depending what language you're coming from you might appreciate a lot of the more modern language features, or binary size, or performance. On the other hand, you might already be working with a pretty cutting edge language with a garbage collector or other and decide that Rust has some cool benefits but not worth the switch.
Side comment but I looked at the documentation, github repo and even code for wick and I still have zero idea what it does. And I am rust developper full time...
The clippy bit is a little confusing:> It also looks like (soon) you’ll finally be able to configure global lints for a project. Until now, you had to hack your solution to keep lints consistent for projects. In Wick, we use a script to automatically update inline lint configurations for a few dozen crates.It's trivial to configure global lints percrate. The author's problem comes down to having multiple crates perproject. Which is something people do sometimes, and should be supported, but there's a big difference between the two interpretations. I would go so far as to saymostRust projects are only one crate (and so support "global" linter configuration)
I believe procedural macros always need to be defined in a separate crate, so at least all projects that use procedural macros will have multiple crates
Still, that's two global configurations to manage, where the original wording was easy to misunderstand as "you have to override linter warnings at every single line where they occur"
Do you need memory safety? Then why use Rust when you could use Java, JS, Python, etc? You can't "disable" memory safety in those languages.Do you need bare metal performance? Then why use Rust when you could use C or C++, which have much larger ecosystems, platform support, more mature tooling, etc.Do you need BOTH memory safety and baremetal performance at the same time? Then there really aren't many other options besides Rust.But what I've started wondering lately is: are there really that many situations where you actually need both of those things at the same time? C++ tends to get misused a lot, but I feel like the same thing is happening with Rust.
If you're remotely sane, you'llalwayswant memory safety. That's not really an optional property, because even in C/C++ compromising memory safety throws you straight into the land of nasal demons. The question is whether you want the compiler to ensure memory safety, or to do it completely on your own without language support.Personally, I've never met anyone who can ensure memory safety in their C/C++ without onerous restrictions even more severe than those rust imposes, but maybe you're superhuman.
And saying c++ has more mature tooling seems insane too. Anyone who has had to mess with depedency trees using git submodules and cmake, conan, bazel, vcpkg, and meson would not call the tooling, oh and hunter too!, mature.
You have no idea what tooling means in this context!
I'm willing to admit that is likely, could you enlighten me?I've done professional c++ for a couple decades. My pipelines usually were conan with some dependencies that were not. The used clang tidy and format,san, cppcheck, coverity and tested release and debug builds with clang and gcc. Coverage was sometimes just clang. But sometimes gcc as well. Tests were usually google test. The team standard IDE was vscode.Rust has rustfmt which is one standard. It has clippy which in addition to actual defects it forces commin idioms so code looks familiar. It hassan and llvm coverage. It has miri. It supports aflop for fuzzing. And it has a single tool for package management and build. Edit: IDE is still vscode and it works great.The only tooling missing for rust would be formal analysis, which is in work (and which isn't that great a story on c++ either) and gcc. A gcc front end is in work, and there is mrustc to generate c from rust, but yes, gcc front end support would be nice to get all those extra targets without the extra work.
A full 70% of security vulnerabilities are caused by memory safety issues. As professionals we need to get serious and have memory safety as a baseline requirement.
So we shouldn't use Rust at all, since Rust is not completely memory safe since it let's you disable the borrow checker. We should be serious as professionals and use safe languages like Java, JS, Python, etc.But of course there are use cases where you need memory safety guarantees and bare metal performance. In those cases, sacrificing some memory safety by using Rust is an acceptable tradeoff I think.
> Rust is not completely memory safe since it let's you disable the borrow checker.No, it doesn't. What's interesting isn't so much that random HN posters believe this sort of thing, because hey, who needs to know anything about a topic to post their opinion on a forum right? No, what's fascinating is that this applies to people like Herb Sutter in his "cpp2" language, here's Herb:> I don’t like monolithic "unsafe" that turns off checking for all rulesNobody does that. It's possible Herb knows that and is being deceitful but honestly I think it's more likely that without investigating at all Herb has just decided everybody else is an idiot...
fn trust_me_i_dont_need_a_borrow_checker<'a, 'b> (x: &'a mut u32) -> &'b mut u32 {
        unsafe { core::mem::transmute(x) }
    }

    fn main() {
        let mut owned = vec![40, 2];

        let mut_1 = trust_me_i_dont_need_a_borrow_checker(&mut owned[0]);
        let mut_2 = trust_me_i_dont_need_a_borrow_checker(&mut owned[1]);

        drop(owned);

        let undefined = *mut_1 + *mut_2;
        println!("The answer is {undefined}");
    }
If unsafe disabled the borrow checker, you wouldn't have needed that transmute. But it doesn't, so you needed the unsafe transmute to make this work.
I don't consider myself a Rust expert, but this feels like a semantic argument? You can use `unsafe` to erase lifetimes, right? I'm not saying it's a good practice, and it's not globally disabling the borrow checker or anything like that, but in theory it's possible to produce unbounded lifetimes that are incorrect. In practice it probably doesn't happen very often. Certainly less often than UB in C or C++
I don't consider this a semantic argument.The exact same code, without the transmute (just returning x directlyfrom an unsafe block), fails a type check related to borrowing. Specifically, the compiler can't see why (without a transmute) it should believe that the reference x now has a different lifetime 'b instead of 'a. Which is fair because it doesn't.The transmute is you claiming it does, and since transmute is an unsafe function that's entirely on you to make sure you're right about that. So, lying has the expected effect.The borrow checks aren't magic, they can't look into your soul - but they are running inside unsafe code too.* Edited to make explicit that the alternative is still marked unsafe and yet doesn't work
Ah, I forgot I was on Hacker News.All memory-safe languages are built on an unsafe foundation. The Java HotSpot VM isveryunsafe C++. That's just how computers work.You aren't meaningfully sacrificing memory safety by using Rust because the unsafe sections are clearly marked out. That's similar to unsafe C#, Python with ctypes, and many other memory-safe languages.
Marking code unsafe lets you write memory-safe code that the borrow checker can't verify. That increases the risk of bugs but it is not the same as disabling memory safety. It is a subtle distinction.
Don't forget safety from data races. Rust's borrow checking provides much stronger protection against those than java, go, c# etc. So we shouldn't use them either.
Beyond memory safety, Rust's other advantages over C++ are simply that it has a far better type system (by nature of ADTs), cleaner and more consistent syntax, cleaner tooling overall, and a far better module/modularity story.That, and the borrowing/safety aspects of Rust also shake out into threading/concurrency, where the compiler does a pretty good job of forcing you to adopt better practices in regards to state sharing, locking, concurrency.Cargo, though... I am coming around to thinking isn't great -- workspace support remains half-assed, especially... and crates.io is amateur-hour for reasons many people have pointed out elsewhere on this post. I have been tempted to switch my personal projects to bazel, with 3rd-party deps checked in/submoduled.
> Do you need memory safety?I think that’s an unusual way frame that requirement.All programs need to handle memory _correctly_. Very few seg fault as part of expected operation.
Segfaults are not actually even the worst outcome, corrupting the program state yet still trucking along can lead to far worse consequences.
In addition to memory safety and performance, Rust offers something that, as far as I'm aware, no other mainstream languages offer: protection from data races.And it offers those things along with a fantastic type system, and great tooling.
It's only mentioned off hand in one sentence at the end, but have people found that Rust is hard to hire for? In my experience it's relatively easy to filter for good candidates when you're hiring for Rust, whereas, just as a point of contrast, I've noticed it's more difficult to find frontend developers who are good at TypeScript (since a lot of frontend developers just use plain JavaScript).
I don't think it is unusually difficult to find Rust programmers. The challenge is finding Rust programmers who also have expertise in systems software development. Rust was designed to be a systems language but ironically it primarily seems to attract developers that do not have expertise in systems software.This isn't necessarily a problem. C++ and Rust can coexist pretty well in practice, and Rust is a good entry point for learning how to write systems software.
Sadly I have found the flip side, too: as someone with a systems software interest/background (I wouldn't say expert), the # of jobs in the Rust ecosystem that are not glorified webdev/microservicing (or worse, crypto) is actually quite small.So I guess I wouldn't be surprised that the applications are trending that way, too, as that is where growth is happening right now it seems.
That's the flip side of the same coin as your parent comment, I guess - because Rust is more accessible than C or C++, a lot of people have started using it for stuff that's not hardcore systems software, and as a result it's not as good a filter for that stuff as C and C++ are.On the other hand, we use Rust on the backend of our web based saas product, and it serves as a great filter for quality developers for us.
As an outsider, I often hear about async Rust being less than ideal. Perhaps I don't understand, because I haven't dipped my toes in the water yet... but I do most of my work in Kotlin with Coroutines, and concurrency is everywhere in the UI. I can't imagine working in a language having a major deficit in this space.Are there any efforts to overhaul or completely rethink this?
It’s pretty much the same issue all languages have, that async functions are colored. I don’t think it is unique to rust.Algebraic effects would solve this, but I don’t know any language other than OCaml that is working on that approach.
It’s not just that. There’s a few big problems with Rust async aside from the normal coloring problem that is inherent to async and not worth talking about.* The async runtime and async functions are decomposed but tightly coupled. That means while you could swap out runtimes, a crate built against one runtime can’t generally be used with another unless explicitly designed to support multiple. I believe C++ has a similar problem but no other major language I’m aware of has this problem - that’s typically because there’s only a single runtime and it’s embedded in the language. Things like timers and I/O are not interoperable because the API you use has to be for the runtime you’re running under. I believe there’s work ongoing to try to remedy this although in practice I think that’s difficult (eg what if you’re using a crate relying on epoll-based APIs but the runtime is io_uring).* async in traits. I believe that’s coming this year although the extra boxing it forces to make that work makes that not something 0-cost you can adopt in a super hot path.* async requires pinned types which makes things very complex to manage and is a uniquely Rust concept (in fact I read a conceptually better alternative proposal for how to have solved the pin/unpin problem on HN not too long ago, but that ship has long sailed I fear).* The borrow checker doesn’t know if your async function is running on a work stealing runtime or not which means there’s a lot more hoop jumping via unsafe if you want optimal performance.* async functions are lazy and require polling before they do anything. That can be a bit surprising and require weird patterns.Don’t get me wrong. The effing-mad crate is a fantastic demonstration of the power of algebraic effects to comprehensively solve coloring issues (async, failability, etc). But I think there’s stuff with runtime interop that’s also important. I don’t think anyone is yet seriously tackling improving the borrow checker for thread per core async.
Async in traits feature doesn’t use boxing (which is coming in 28 December), only async-trait crate use boxing.
Really? When I read the GitHub issue it seemed like even the standardized implementation results in boxing…
I mean... that's not really the pain that people are referring to when they are struggling with async Rust, especially when you compare it other languages like JavaScript that also have a difference between async and regular functions.
Unison [1] has algebraic effects as a first-class feature. They call them "abilities" there. You can make async about as transparent/opaque as you want it. Docs on abilities in [2].[1]:https://www.unison-lang.org/[2]:https://www.unison-lang.org/learn/language-reference/abiliti...
Does anyone actually use unison in real life?
I don't know that anybody is running a company on it yet, no. They've got a couple big milestones coming down the pike, which might make it more attractive to people.
Can't scala, haskell, (kotlin?) you just lift functions into Async?You can convert colors simply but only one way, and practically that works, functional core imperative shell, etc.
For me I am working on a side project in Rust and had very few issues, Rust felt quite straight forward up until the point where I had to mess around with async. For my domain I need to use a framework that expects you to set up a shared mutable state for the connection pooling in an opinionated way. Suddenly I encountered arc and mutex and very cryptic trait error messages for code doing way too much magic. All I wanted was to share a SQLite connection in an ugly way to get my mvp out but I was dealing with absolutely incomprehensible trait issues.In general I’ve noticed that there are a lot of code generation modules that can generate very cryptic error messages if you stay clear of their happy paths.
You would run into the same issues if you tried to do it with threads and rust too.Any kind of shared resource is a tedious experience, that's basically it's selling point.It is frustrating becasue if you go look for help, people are always condescending about global shared resources like that but there really isn't a better way.
It feels like most of the hatred for rust async is for people that try to act like Tokio isn't async rust and that for some reason you should try to randomly avoid tokio for some reason.
Maybe because you want to keep the dependency tree under control and bringing in tokio suddenly adds fifty crates you never asked for. Every crate is a potential liability!
Tokio is developed very carefully (they’ve even developed their own thread race checker for it – loom).Adding it to your project probably increases the average code quality:)
I don't doubt the code quality but most of the additional crates are not tokio's. Also statistically, any added complexity incurs more risk.
There's efforts to overhaul it, basically there's a lot of stuff that has to be more complicated (as you'd expect) if you want to add support for async somewhere, and understanding the error messages can be pretty mentally taxing when you get it wrong; and then there's a lot of cases where the async version of some pattern just doesn't work right now due to limitations in the compiler or the language itself, and hopefully it'll work someday, but in the meantime you need to use workarounds.
Here's a better explanation by somebody smarter than me about why Rust chooses what it does, what else you could choose and what the price is:https://without.boats/blog/why-async-rust/tl;dr: You can have different (nicer to program) abstractions, but you can't have them in the same language you use to write firmware for a $10 electronic device, or Linux drivers, and we already have languages like Go and Javascript whereas we did not have a safer alternative to C++.
Use Rust like ADA, or use it for OS yes.For typical applications I am learning nim, which has python syntax, c speed and size, and could be memory safe too.I really feel nim deserves more love, for that you can balance coding-speed(write like python script), size , performance and security, and cal leverage c and c++ libraries without FFI,  no other languages can have those at the same time.
Or crystal which looks more like ruby than Nim looks like python.
I've tried it a few times and it has great features on paper but to use it gets in your way too much.  I can spin up a C# dotnet project write and test the code 10 times faster than in Rust. It might not perform as fast but the hot code can be written in a small C library using code/runtime analysis tools to catch any memory safety issues.
A note on putting the hot path into C component:Writing performance-sensitive code in C/C++ and calling it via interop used to be the way to go during .NET Framework days but since then has become a performance trap.Especially for small methods, calling them through interop is a deoptimization because they cannot be inlined, and involve GC frame transition (which you can suppress) as well as an indirect jump and maybe interop stub unless you are statically linking the dependency into your AOT deployment. In case the arguments are not blittable to C - marshalling too. Of course, this is much, much faster than anything Java or Go can offer, but still a cost nonetheless.It is also complicates the publishing process because you have to build both .NET and C parts and then package them together, considering the matrix of [win, linux, macos] x [x64, arm64], it turns into quite an unpleasant experience.Instead, the recommended approach is just continuing to write C# code, except with pointer and/or ref based code. This is what CoreLib itself does for the most performance-sensitive bits[0]. Naturally, it intentionally looks ugly like in Rust, but you can easily fix it with a few extension methods[1].[0]:https://github.com/dotnet/runtime/blob/main/src/libraries/Sy...[1]:https://github.com/U8String/U8String/blob/main/Sources/Compa...
Thanks, I haven't had to do dropping to C for a while as the improvement in performance of dotnet along with features like AOT, Span<t> etc close the gap enough for the domain I work in.Good to know you can remain within the framework and get decent performance though with the unsafe pointers/refs.  Would be interesting to see a good benchmark using only C# with latest features and Rust, although I cognisant of the fact there is more to it than pure performance (binary size, dependencies, GC etc).
Rust standard library is far more conservative when it comes to vectorization and auto-vectorization is far more fragile than people think, both links - they beat it in performance significantly ;)
> I code better in other languages nowI feel this one, something about spending too much time in JS makes me not want to write clean software..
Rust is great, but one thing I’d like to see is an interpreted, dynamic, less strict version of it that could be used for prototyping and gradually typed into compiling Rust code. In other words, a new programming language doing to Rust the reverse of what Mojo is trying to do to Python.
Have you ever heard of Rune? Sounds like it might be what you're looking for.https://rune-rs.github.io/posts/rune-0-13-0/
Cool! Thanks!
I love Rust but saying your aren't sure if its worth it after three years is a red flag.
Biggest turn off for me was Rust's horrendous syntax. Dangling apostrophes, wrapping the hell out of things, etc. Just look at this Result<Arc<T, A>, Arc<dyn Any + Sync + Send, A>>. Absolutely horrendous.
That’s a shallow problem that goes away as you start using the language.Lifetimes need something to stand out as an identifier. 'a is weird, but works. Whether it could use a different ASCII sigil is a bikeshed problem.Types borrowed <> from  C++ to look less weird to C++ programmers. But this again is just a surface level issue. Semantically, the wrapper types are incredibly useful. Having all nested types spelled out is convenient when reading code – you know what you're getting and what are the standard properties of it.
As much as I love rust. Its just shocking to learn these newer languages like go didn't take any learnings from jvm and dotnet world for something simple as dep/package management
I thought the likening of the strictness of the language and compiler errors and warnings to an emotionally abusive relationship was quite offensive.I programmed in C and C++ for years, to compiler messages don't make me feel like I should be taking them personally. Sure beats having a runtime error any day.I wonder if those with that attitude have come from a background where they used dynamically typed languages or non-compiled languages more, or it is something even people with a wider experience find particularly onerous with Rust?
Why each article about project completion in Rust is read as ex-husband words about his ex-wife:- I loved here. I am still is. But we needed a divorce.
This is written by someone who has obviously written a lot of Rust code. I like its balance. It feels fair and not fanboyish like these write ups often do.
Yah, it's nice reading some balanced takes.
Re: async, rust is a down to the metal language. IE library yes, runtime no. Async implementations are all either runtimes (Javascript), or libraries that implement a runtime (Python). Under the circumstances I think it's fair that rust has less than ideal async.I still like threads, but the I'm old and uncool.
> I still like threads, but the I'm old and uncool.Hey, I resemble that remark.But I disagree with it.  Green threads give you all the advantages of async, but with less of the hairs.  In particular no special syntax or change of programming style is required.  Yet underneath green threads and async just different styles of event driven I/O, so both run at similar speeds and excel at the same tasks.  (Actually green threads should run faster, as storing state on a stack is generally faster than malloc.)I have no idea why Rust abandoned green threads in favour of async.  Actually, that's a partial lie - there have been far too many words wasted on explaining why.  The problem is the reasons they give look to be an caused by design decisions they made in their implementation.  The primary objection seems to be speed.  The current async is indeed faster than their old green thread implementation.  But that was caused by their choosing to avoid coloured code in their green threads (maybe they were copying Go?).  Other objections were similarly to do with the implementation they threw away, not green threads themselves.
> Green threads give you all the advantages of asyncThey require more memory over stackless coroutines as it stores the callstack instead of changing a single state. They also allow for recursion, but its undelimited meaning you either 1) overrun the guard page and potentially write to another Green thread's stack by just declaring a large local variable 2) enable some form of stack-probing to address that (?) or 3) Support growable stacks which requires a GC to fixup pointes (isn't available in a systems lang).> green threads should run faster, as storing state on a stack is generally faster than malloc.Stackless coroutines explicit don't malloc on each call. You only allocate the intial state machine (stack in GreenThread terms).> The primary objection seems to be speedIt's compatibility. No way to properly set the stack-size at compile time for various platforms. No way to setup guard pages in a construct that's language-level so should support being used without an OS (i.e. embedded, wasm, kernel). The current async using stackless coroutines 1) knows the size upfront due to being a compiler-generated StateMachine 2) disallows recursion (as that's a recursive StateMachine type, so users must dynamically allocate those however appropriate) which works for all targets.
> They require more memory over stackless coroutines as it stores the callstack instead of changing a single state.True, but in exchange you don't have to fight the borrow checker because things are being moved from the stack.  And the memory is bounded by the number of connections you are serving.  The overheads imposed by each connection (TCP Windows, TLS state, disk I/O buffers) are likely larger than the memory allocated to the stack.  In practice on the machines likely to be serving 1000's of connections, it's not going to be a concern.  Just do the arithmetic.  If you allowed a generous 64KB for the stack, and were serving 16K connections, it's 1GB of RAM.  A Raspberry PI could handle that, if it wasn't crushed by the 16K TCP connections.> They also allow for recursion, but its undelimited meaning you either 1) overrun the guard page and potentially write to another Green thread's stack by just declaring a large local variable 2) enable some form of stack-probing to address that (?) or 3) Support growable stacks which requires a GC to fixup pointes (isn't available in a systems lang).All true, but also true for the main stack. Linux solved it by using 1MB guard area.  On other OS's gcc generates probes if the frame size exceeds the size of the guard area.  Lets say the guard area is 16KB. Yes, that means any function having than 16KB of locals needs probes - but no function below that does.  Which in practice means they are rarely generated.  Where they are generated, the function will likely be running for a long time anyway because it takes a while to fill 16KB with data, so the relative impact is minimal.  gcc allows you to turn such probes off for embedded applications - but anybody allocating 16KB on the stack in an embedded deserves what they get.And again the reality is a machine that's serving 1000's of connections is going to be 64bit, and on a 64bit machine address space is effectively free so 1MB guard gaps, or even 1GB gaps aren't a problem.> No way to properly set the stack-size at compile time for various platforms.Yet, somehow Rust manages that for it's main stack.  How does it manage that?  Actually I know how - it doesn't.  It just uses whatever the OS gives it.  On Windows that's 1MB.  1000 1MB stacks is 1GB.  That's 1GB of address range, not memory.  Again, not a big deal on a modern server.  On embedded systems memory is more constrained, of course.  But on embedded systems the programmer expects to be responsible for the stack size and position.  So it's unlikely to be a significant problem in the real world.  But if does become a problem because your program is serving 10 of 100's of concurrent connections, I don't think many programmers would consider fine tuning the stack size to be a significant burden.> No way to setup guard pages in a construct that's language-level so should support being used without an OS (i.e. embedded, wasm, kernel).There is no way to set up the main stack without the kernel's help, and yet that isn't a problem?  That aside are you really saying replacing a malloc() with mmap() with the right flags is beyond the ken of the Rust run time library authors?  Because that is all it takes.  I don't believe it.> The current async using stackless coroutines 1) knows the size upfront due to being a compiler-generated StateMachine  2) disallows recursion (as that's a recursive StateMachine type, so users must dynamically allocate those however appropriate) which works for all targets.All true.  You can achieve a lot by moving the burden to the programmer.  I say the squawks you see about async show that burden is considerable.  Which would be fine I guess, if there was a large win in speed, or run time safety.  But there isn't.  The win is mainly saving on some address space for guard pages, for applications that typically run on 64bit machines where that address space address space is effectively an unlimited resource.The funny thing is, as an embedded programmer myself who has fought for memory I can see the attraction of async being more frugal than green threads.  A compiler that can do the static analysis to calculate the stack size a number of nested calls would use, set the required memory aside and then general code that so all the functions use it instead of the stack sounds like it could be really useful.  It certainly sounds like an impressive technical achievement.  But it's also true I've never had it before, and I've survived.  And I struggle to see it being worth the additional effort it imposes outside of that environment.
Javascript to Rust is a big step for sure. It's probably a less painful journey if you already have a background in Typescript/C++. This article has good feedback though and I hope the language evolves to address some of it in the future.
> It also looks like (soon) you’ll finally be able to configure global lints for a project. Until now, you had to hack your solution to keep lints consistent for projects. In Wick, we use a script to automatically update inline lint configurations for a few dozen crates. It took years for the Rust community to land on a solution for this, which brings us to…Wow, as the author of that feature, I'm surprised to see someone was so passionate about it.  I've found that many times I've been having to tell people why they should care about it.> I don’t know why. Maybe the pressure to maintain stable APIs, along with Rust’s granular type system, makes it difficult for library owners to iterate. It’s hard to accept a minor change if it would result in a major version bump.There is a tension between people wanting features and people not wanting to deal with version bumps.  I've seen this a lot in maintaining clap, especially when it went from unmaintained for years to having active releases.As for cargo, the compatibility guarantees are tough.  Take the lints table.  We can't throw in a first try, knowing we can fix in in a cargo 2.0.  We are tied into the rust project itself which means we have the same compatibility guarantees.  This is one reason we generally encourage trying ideas out in third-party plugins before we integrate them in directly since they can break compatibility.> You can’t even publish a crate that has local dev dependenciesYou can; cargo automatically strips them.  However, if you tell cargo that there is a version of it in the registry (by setting the version), then it must be published.  This is why when I redesigned `cargo add` for being merged into cargo, I made it so `cargo add --path ../foo --dev` will not add the `version` field.  We do need to find ways to clarify that the purpose of the version field is for looking it up in the registry.Allowing the dev dependencies to be stripped also helps with issues of circular dev-dependencies.> However, many developers break large projects down into smaller modules naturally, and you can’t publish a parent crate that has sub-crates that only exist within itself.We do have an RFC for this:https://github.com/rust-lang/rfcs/pull/3452The most complex part is the Index, figuring out how to represent it in the metadata tables we maintain so we avoid having to download every `.crate` file.I also worry there might be tech debt around assumptions of there being a single version of a package when nested packages will easily break that.> You can see the problem manifest in the sheer number of utility crates designed to simplify publishing workspaces. Each works with a subset of configurations, and the “one true way” of setting workspaces up still eludes me. When I publish Wick, it’s frequently an hour+ of effort combining manual, repetitive tasks with tools that only partially work.I'm a bit confused on this point.  While there are things to improve around publishing workspaces, I'm not sure how this relates to setting workspaces up or what problems they've had with that.  I'd also be curious what problems they had with releasing packages.  I don't think I've seen issues from them in cargo-release's Issues.
I tried Rust briefly and it had that "Ocaml" feel of solving a puzzle.
Mostly yes and good.One thing I don't appreciate is nonorthogonality of certain uses and control structures that cannot be refactored into a function despite structural equivalence without introducing a multiple borrow conflict.
I've always assumed this was because of my inexperience with the language, but I find this frustrating, too.
I think Rust is one of those excellent tools where it does well to interface into a high-level language like python.Need performance, security, and reliability? Build that part in Rust, and have the rest be executed and orchestrated in python. It also forces great design patterns in the form of encapsulation and a strong API.I think the idea of being monolingual in codebases is a silly limitation and lots of development teams would be a lot more productive if they embraced the idea of polylingual codebases.
"The Rust standard library is enormous."Years ago I tried compiling a rust sample program.  The binary size was one thing that put me off.Today, I see the issue of large binary size has been addressed.  The binary I get is sufficiently small.If this issue of ~500M standard library is fixed, e.g., if some of it is made optional not mandatory, I will give rust another try.
Rust binaries are by default nowhere close to 500MB. If they are not small enough for you, you can tryhttps://github.com/johnthagen/min-sized-rust. By avoiding the formatting machinery and using `panic_immediate_abort` you can get about the size of C binaries.
Comment is based on the rust-std package I'm currently seeing in VoidLinux.  It is over 500MB.3 packages will be downloaded:3 packages will be installed:libexecinfo-1.1_3 
  libexecinfo-devel-1.1_3 
  rust-std-1.73.0_1 

  Size to download:              136MB
  Size required on disk:         509MB
  Space available on disk:       never enough!Cheacking Debian and NetBSD it seems like the Rust standard library is smaller, much less than 500MB.The simple question is how much space is required for an installation of the Rust compiler.  On VoidLinux, it's significantly more space than for a GCC installation.  509MB is just too much for my tastes.
I definitely agree with the first negative point. Rust libraries often feel weirdly restrictive and unfinished, even after having a lot of time to mature. Somehow they just don't end up feeling that much better. I just don't understand why though, is there something about Rust that makes this a problem?
Is Rust a replacement for only C/C++ or also Java/Python/C#/TS? In the latter, I already get some memory safety which I believe is one of the biggest selling points of Rust. Are other benefits of language strong enough that we look into it to develop projects traditionally built in Java or Node?
>I also now get irrationally upset when I experience a runtime error.Had this experience in my first Rust program. It turned out Rust had silently changed the types of some variables based on some code hundreds of lines later, which caused an overflow at runtime. Spooky action at a distance!
>> I started writing tests in Rust as I would in any other language but found that I was writing tests that couldn’t fail.I'm curious if this is other's experience as well. I've only dabbled in Rust but it isn't clear to me how it would ensure that the code is correct.
It does nothing special compared to the rest of the field of strongly typed MLish languages.
> I also now get irrationally upset when I experience a runtime error.No. This is an exceedingly rational anger.
"Rust has its warts". Interesting terminology.
This is a fairly common idiom, "X has its warts." Or do you mean something else?
Can’t really accuse programmers of being creative with words and phrases. Most of them will be rehashes of blogs and memes from the last couple of decades.But maybe I’m bikeshedding by saying that.
Doesn't seem to answer my main question about Rust vs everything else which is what is the more joyful to work in?
It really depends on what your previous programming experience is, if you can state which languages you know now, someone can give a better response to this.
For what it's worth, I find refactoring in Rust a joy.
Unison language has a very elegant solution to the naming problem.
How do people prefer to compile rust programs offline.
In what way? Rust (cargo technically) might have the best support for offline compilation of any language I use. `cargo vendor` does pretty much everything I want it to.
Also you can download documentation for offline using `cargo doc` so you can easily lookup stuff during a flight. Although you do need to figure out all your dependencies ahead of time so that you download their documentation before you leave.
Just FYI, `cargo doc` doesn't download the documentation. It re-generates the documentation from source. You only need the source code to generate documentation.
<misread the code, please ignore>
To clarify, they aren'tdisablingthe lints in the section you've highlighted. `deny` makes a lint a failure instead of a warning. This is similar to `-Werror` in C. `allow` is the directive to disable a lint. Eg, I often start new or disposable projects with `#![allow(unused, dead_code)]` just to keep my IDE clean while the code is in an unpolished state.
You are correct! I misread it entirely, that's on me. I misread #![deny] as #![allow].
Rust offers you great control when you need it (to the same level of C++, basically. This is what it was designed for). And even the Carbon docs say that if you start from scratch prefer languages like Rust.
No it doesn’t. The vast majority of what is taught in a college C++ course would be either impossible or extremely difficult to do in rust. You couldn’t implement std::tuple or std::variant for instance.The carbon docs never recommend rust, they just urge you to use something already available.
"Programming in Rust is like being in an emotionally abusive relationship. Rust screams at you all day, every day, often about things that you would have considered perfectly normal in another life. Eventually, you get used to the tantrums. They become routine. You learn to walk the tightrope to avoid triggering the compiler’s temper. And just like in real life, those behavior changes stick with you forever."This is a pretty negative and unfortunate take on rust that I cannot recognize after having spent the past 2 years professionally writing backend rust.
I did write c++ before that so it's likely that it takes some experience with the pain of an unhelpful (and in some cases downright hostile) to fully understand and appreciate the so called "yelling" rust does.From my perspective every lifetime complaint the compiler has is a deeply appreciated hint that not only saves you countless hours of debugging down the line but also makes me feel confident/safe in the code which you never could achieve in a c++ codebase without making defensive copies everywhere.Being able to lend/borrow data without fear truely is rust's greatest strength and something people coming from GC languages have a hard time appreciating.
It's a bit of an oversimplification, but a little quip I've used when talking about developing in Rust vs. other languages is, it's a question of where/when do you want the pain. In Rust, it's at development time (and hiring and ramp-up time); in C++ it's at runtime; and with GC languages it's at billing time when you have to pay for that extra compute and RAM. There's no way to get rid of the pain entirely.
if it were that simple, I'd take the "billing time" payment every time. Engineers' time is the greatest cost for just about any tech business
Sometimes billing time is your customer's patience, their phone battery, or other things like that which make your product worse and give your competitors an edge.
>...which make your product worse and give your competitors an edgeI would find that argument passable if some of the biggest products from the largest companies functioned better. Performant software seems like a distant memory.
And yet the big tech companies are perpetually re-writing their whole stack, or going out of their way to create new compilers for their language in order to lower their billing time.
Salaries are dominant in early stage startups, and infrastructure costs becomes dominant as you scale (also probably a SaaS-centric oversimplification). You can get into trouble in the middle, where you have enough scale to be paying jaw dropping cloud bills, but you don't have the staff to move to a cheaper architecture and you may still need to focus on getting new features out to drive growth (or to attract investment).In startups that chasm is generally filled with VC money paid to cloud vendors, but if you're bootstrapping or not looking to be a unicorn, you probably will want to drive down infrastructure costs much earlier.
I tend to agree with you, but your aside about it being Saas-centric is really important.One need only open Microsoft Teams to see the “billing time” costs. If the billing time cost is not paid by the developers or their company, then it stop being a cost to them and it becomes an unpriced externality. Who cares,who even knows, that this app we’re writing runs slowly on regular people’s old hardware.
Rewrites in big tech are a symptom of too many people each trying to demonstrate impact that checks the boxes of an elaborate promotion process.
its depends on your app, if you run infra on 100k servers then win can be much larger than cost of engineer.Or if you write mobile app and became slow and laggy, then you lose users.
Yes but there’s a difference in who feels the pain. Compile time pain is felt by devs, who have the constitution and ability to fix such issues. Runtime pain is felt by users and can result in data loss and security issues in the wild, and is harder to debug.One kind of pain has a bigger blast radius than the other. I prefer compile time pain to runtime pain.
>From my perspective every lifetime complaint the compiler has is a deeply appreciated hint that not only saves you countless hours of debugging down the line but also makes me feel confident/safe in the codeMeh, the fact that Rust's compiler is overly strict is just a truth (All compiling programs are valid, but not all valid programs are compiling), and I find it lowkey annoying that every time someone has a problem with it, rustceans jump to the defense to the point of almost denying the OPs experience.
I mean on a case by case basis it might simply be a difference of experiences and both are valid, but on a larger scale it does look like a bit of a pattern, at least to me.Ofcourse, there restrictions aren't just a whim of a Rust core team (usually ;p ), and do come from practical limitations but regardless,  it's fair to be frustrated at them.
Indeed, I’ve been writing rust professionally since 2015 (yes before 1.0) and I would consider the first encounter with the compiler as maybe it yelling at me, because I was used to C++. But it actually taught me a lot about why the code I was writing may have seemed okay at first glance, but actually introduced a tricky corner case bug that I hadn’t considered. The borrow checker got it tho, and I had to rearchitect my code to avoid that edge case. Now the code is better, free of that bug, and I won’t make that mistake in the future.Was that the result of a process in which the compiler “abused” me? I don’t think so.
Its wild how different the perspective is depending on your backgroundThe author also wrote
>[Rust's] dev tooling leaves much to be desiredI can't even begin to comprehend such a statement. Rust's tooling ecosystem is the number one reason why I want to convince my colleagues to give it a shot. Its literal heaven coming from C++ with cmake...
Yeah, blaiming the compiler for pointing out potential runtime bugs is just shooting the messenger.
In general, the error messages are also nice and offer suggestions on how to fix the problem. Far from being yelled at, it's more akin to pair programming. "Try doing this..." "Did you mean to do this?"
Did you mean non-GC languages? GC languages by default have at least memory safety because the GC frees for you when an object is detected to no longer be accessible.
I'm not trying to shame you, but how long have you been coding? I've not yet had the urge to ask an AI for coding help, ever. The questions that are decoupled enough from a field/project that it might be able to answer seem trivial and easy just to search on.Plus, I'm way more trusting of a Stack Overflow post or even a blog post than what AI generates. I mean, AI hallucinates all the time or generates things that are subtly wrong, so unless you can write the code yourself how can you trust the generated stuff?
I'm pretty shocked by the grandparent, but on reflection, I think this is the future.InThe Grapes of Wrath, Steinbeck writes about the travails of a family's trip to California in search of work during the Great Depression in the 1930s. Tom Joad, the father, fixes the compression in his blown engine by wrapping a copper wire around the cylinder, then running the motor until it melts and recreates the seal. It's such an ingenious hack, and reflects such deep knowledge of how an engine works, that it's stuck with me for decades.Today, I bet fewer than 5% of vehicle owners even know how to check their tire pressure. But it's not like fewer people are driving, or cars are more likely to be found by the side of the road with a blown engine—it's just far less necessary to know these things. I think programming will go this way, too.
While it's a nice story, unfortunately it would appear as though Steinbeck didn't do enough research and thought the 1925 Dodge was built much like a Model T: <https://forums.aaca.org/topic/134313-the-grapes-of-wrath/>
Hah, this is great. Guess I'm going to have to update my analogy bank.
Copper melts at over 1000C that seems questionable.
Might have been bronze or tin—I read the book a long time ago!  That said, burning gasoline or kerosine can be over 2000°C[0].[0]https://en.wikipedia.org/wiki/Adiabatic_flame_temperature
steel melts around 1600, the engine would blow up waaay before.the problem with that story is that if the "seal" is made from a simple material that melts by the engine heat, then it will not seal for long. (or at all.) but likely it's not what Steinbeck wrote.
At what temperature does copper soften enough to squish into a seal shape?I seem to remember my dad shimming a cylinder that had lost compression with a copper ring; I was a kid so I don't remember any details except it wasn't intended to melt, and whatever it was intended to do worked and we saw the car still being driven around town fifteen or twenty years after he sold it.
it's possible that the car got a replacement part eventually :)copper becomes ductile between 300-600 C (https://www.engineeringtoolbox.com/docs/documents/1353/tempe...)piston ring seals are usually made of cast iron or steel. copper would probably work too for a while, it's good at conducting heat, there's ample cooling in engines, so it wouldn't melt, just wear out very quickly ... and then the engine performance degrades as the sealing gets worse and worse (and it starts to eat oil, soot gets everywhere, exhaust becomes visible), mpg goes down, but ... the car would probably run. (loss of 1 out of 4 pistons is not a catastrophic failure)
It's a rubber duck that talks back. Chat Gpt is amazing for programming. I'm not OP but I've been coding since 2009.
I've been coding since I was 8, so... 30 years, about 17 professionally.I'm not averse to new tools at all, but I've yet to see where I would want copilot or chatgpt. The problems I work on daily, like most professional devs, are very specific to how I adapt a large proprietary codebase to do new things to fit specific business requirements, or working with designers and project managers to figure out how we should solve these intricate problems together. AI can't help with that. It'd take a 20 page prompt for it to roughly understand the business even.It can help with toy problems like how to write a well known algorithm, but given that these are well known algorithms and it's basically just copying from open source repo's (with scary legal ambiguity), it's of little use to what I actually do day to day.I'm amused that as a lead you'd "give me a warning ". I've literally never worked with a lead or manager that cares what tools people use, only that the work is good. Actually, if anything a lot of workplaces are asking people to seek approval before using AI, because of the many thorny issues (copyright being one of many)(BTW, I do use chat gpt, just not for coding. It's useful for creative tasks or summaries. I still google what it says because it does make shit up)
How do you deal with NDAs and privacy issues? Do you not work on any code which is not OK to share with Microsoft?
> If I was your team lead I'd give you a warning, same as I would if you didn't use an IDE or source control.I really think you mix upa) common rules as they are needed to work together and (like style or source control)
b) local tooling / someone is organizing his own workspaceincluding an dictator-like "MY way of working is the best!" attitude after disovering whatever works out for YOU. If I was your team lead, I guess I would give you a warning. :-DAdditionally, I guess your programming problems are very generic.
I tried for a long time for chatgpt to help me write a simple function that generated a random array and then summed along the columns. Could not do it.Pasting in an error message, made chatgpt spit out another version of the code with some other error.
Go to ChatGPT and type "write a simple function that generated a random array and then summed along the columns".Run it.  If there is an error, either debug it or ask ChatGPT to take a different approach.There's something wrong if you can't get it to do this.
This is just horrendous. So instead of writing this trivial piece of code yourself you get an AI to write it for you. Then instead of reading and understanding the code you just run it to see what happens. Is there a problem? Just try again, or immediately grab a debugger, because everyone knows that nobody could possibly read and understand a trivial two-line function!Yes, there's something wrong here. But it isn't "not using chatgpt"...
There's something more wrong if you need it to do this
Of course that works, but that's not exactly a task that's likely to trip me up or be a bottleneck in my coding efficiency. The things that are are typically either of sufficient complexity i don't even know how to begin describing it to ChatGPT in a useful way, or require enough domain knowledge it's not worth the effort.Of course, it's still an issue if ChatGPT can't generate trivial rust code, but that seems unrelated to the quality of the language itself.
ChatGPT 4 has worked great for Rust for me.
When I tried it a while back it had no grasp of the hard parts of Rust - of which there are many.Not knowing the hard parts is not a workable outcome.
Did you try ChatGPT 3.5 or 4? There’s a world of difference. Whats an example of a question it failed?I understand Rust pretty well. I can totally see ChatGPT not being able to help with complex lifetime issues. I’ve never asked it such things.
This is such a well written post. No fluff, gets straight to point while still offering some context, easy to skim through and get the main points. Bravo, top notch technical communication.
This is a very good article that doesn't shy away from downsides. Below are my personal not-so-humble opinions.> Rust has a great developer experience. Its type system is very powerful and allows you to encode complex invariants about your system in the type system.Usually this means: we have three people doing type-level magic, no one understands it, and when they inevitable quit no one can understand how this works and why it takes weeks to add a small change.> Related to the previous point, the Rust community is still relatively small. It is hard to find developers with professional Rust experience.This directly correlates with what was written previously: "Many developers enjoy working with Rust. It is the most admired language for the 6th year in a row". Enjoyment often comes from early adopters, and people trying the language for some side projects.I'll admit, however, that Rust seems to have crossed the chasm in the adoption cycle.> Rust has a famously steep learning curve. It is a complex language with many advanced features.Combined with "It is hard to find developers with professional Rust experience" and "mostly training their developers on the job",stay away from it unless you know exactly what you are doing.> more than 2/3 of respondents are confident in contributing to a Rust codebase within two months or less when learning Rust.This is ahugeamount of time. However, unclear: is this due to the language, due to being thrust into a new domain/role/job, or both.
You can skip type system magic, and have people just keep introducing bugs that it would prevent over and over, writing more tests trying to prevent it, never quite succeeding, but overall "feeling productive" and "being agile" along the way.Having said that - yeah, making good apis and abstractions that prevent mistakes takes time and some skill, and pays off gradually proportional to the scale and longevity of the project. And for certain things is not worth it. Being able to make a good judgment if enforcing something at the compile time / runtime / at all is worth it is part of the skill.
> You can skip type system magic, and have people just keep introducing bugs that it would prevent over and over, writing more tests trying to prevent it, never quite succeeding, but overall "feeling productive" and "being agile" along the way.There's a middle ground, and I was specifically responding to the quoted bit: "Its type system is very powerful and allows you to encode complex invariants about your system in the type system."Once people start "encoding complex invariants in the type system" it becomes an unholy mess only one or two people on the team understand. Usually an ad-hoc unspecified poorly thought-out type-level DSL dozens of level deep.
> You can skip type system magic, and have people just keep introducing bugs that it would prevent over and overPersonally, I found even Haskell's type system easier and nicer to use than fiddling with _lifetimes_ in Rust types. Everything else in Rust is falling nice into place, but lifetimes are painful, magical and very annoying.
The survey toward the bottom was interesting; ownership and lifetimes showing up as the hardest things to learn for new users.  And those are exactly the things that GC solves, or that were historically been involved in majority of security vulnerabilities.
The actual data toward the top was also interesting; the cost of GC is high and Rust eliminates it.
The cost of GC is only high as in the cost of living in modern society is. Sure, you can technically live in the forest and build/hunt/harvest everything for yourself, but unless you have very specific reasons for that, having a house and going to the supermarket is the sane default option.
Easy to learn, safe, fast: pick two
That also depends on GC, and the language, and the implementations of the GC.E.g. in Erlang GC is mostly negligible [1] (but you can put undue pressure on it, and on the underlying OS), there are realtime GCs for Java, etc.But yeah the cost of GC is never zero.[1] citation needed
> That also depends on GC, and the language, and the implementations of the GC.Nothing depends on no GC.I'm not anti-GC.  I earn most of my living using GC languages.  But there comes a time when the cost of power and hardware outweigh the value of GC.  When that time comes Rust is an excellent way to solve it.  I am, however, very "anti" the "no such time exists" position.  That has never been and will never be true.
Smaller amount of time than the equivalent in C/C++ probably.
> Usually this means: we have three people doing type-level magic, no one understands it, and when they inevitable quit no one can understand how this works and why it takes weeks to add a small change.This is how it is in all typed languages I've used. There will always be trivial propositions which the compiler cannot check and bending around that often means ridiculous type magic. Such is the life of library & framework authors.
Are there actual jobs in Rust? This is not snark, btw. I love Rust and I am currently learning it. Genuinely curious, since I have not seen a lot of listings for it, if any.
Not a direct answer, but I do get a decent amount of contracting work for Rust. Mostly for 2-3 year old projects where the original Rust developer has moved on and they need a small fix or feature change.
Do you have any leads you'd be comfortable with sharing?
I mostly work with local clients born out of my networking.
https://www.rustjobs.fyi
Plenty in crypto.
A few others.Not enough to pay well enough, it reminds me of node.js in the early days.I'm active in the community, do rust events but I can't find something that pays more than js consulting with untouchable companies.I guess at some point I'll have to decide between money and my soul
My current and previous jobs have been in Rust. They're definitely out there.
Recently I decided to try Rust at work as well, after using it a little as a hobby, just to replace a basic shell script with it at first. While reliability, ergonomics, and other positive sides either do not beat Haskell (which I use for most programs, except for a few small shell scripts or [PL/pg]SQL functions) or it does not matter here, I similarly ran into that "immature ecosystem" issue: apparently people are still supposed to run a nightly build or rustup, but not a compiler from stable system's repositories, let alone libraries. It was that way when Rust was really new, which was understandable, but it is odd to run into that now, and also as the article mentions, even with basic libraries: I ended up using eprintln! instead of a logging library (fortunately used it with systemd, which picks up stderr output, and did not really need to set syslog levels or additional fields), env.args instead of an argument parsing library.Mostly agreed with the conclusion, too: the language still looks good, especially as a C alternative, and hopefully it will be usable in a more stable setting. Gradually trying it out does not feel like a pivotal decision though, that sounds overly dramatic.
Using Rust without using the features provided by Cargo is akin to buying an electric car and asking for all the electronics to be removed.Rust libraries will never be shipped by your distro’s package manager. Maybe a few exceptions for things that also have C bindings, but it will never be the default.
Many Rust libraries are shipped by distro package mangers, right now. But in general, those packages are intended to be used to build the Rust programs that are packaged in the distro, and not for general use. So it is going to be a painful way to try to write programs using Rust's ecosystem, as it is with basically every other non-C or C++ language.
It’s painful with c and c++ as well, the tool chain/libraries a distributor provides are almost never the ones you want to develop with as they are often ancient
> I similarly ran into that "immature ecosystem" issue: apparently people are still supposed to run a nightly build or rustup, but not a compiler from stable system's repositories, let alone libraries.What languages/ecosystems is this not the case? Even with C/C++ you probably shouldn't be relying on your distro's package management for library and toolchain support.Also, you do not need nightly unless there is some very shiny and new feature that you need that isn't on stable yet.
With C, I comfortably rely on the distribution's package management, even though it is not a rolling release or anything of that sort (Debian stable). Actually not sure how that would be the case with C, if one does not try to make things incompatible intentionally: the language and the major libraries' APIs are pretty stable there.With Haskell (used for most tasks at work) I get the tools (GHC and Cabal) and most of the dependencies from Debian stable repositories, though loading missing ones from Hackage (but slowly moving towards not relying on Hackage at all). And keeping sources compatible with package versions from Debian repositories from version 9 to 12 (4 major versions, 6 years apart). With shell scripts, sticking to POSIX; with SQL ones, avoiding extensions and also doing fine.
We have very different experiences, I haven't worked on a production C/C++ project in the last decade that didn't vendor dependencies somehow. Debian stable is especially unreliable. In fact I can't think of a time I haven't had issues when working on a team greater than 1 or shipping builds because distro packaged libraries aren't reliable.Also, why is it immature for Rust to ship a toolchain and package manager through a sidechannel, but not Haskell?
> why is it immature for Rust to ship a toolchain and package manager through a sidechannel, but not Haskell?Haskell also feels less mature to me than C, with fewer POSIX functions being readily available, but as mentioned above, with Haskell (in my experience; the experiences indeed seem to differ) it is "one or two dependencies have to be pulled from Hackage across multiple projects and system versions", while in Rust it is rather "I failed to pull common logging and argument parsing dependencies on a single up-to-date stable system, and apparently one is supposed to install and update its compiler, package manager, and libraries separately from the rest of the system". Though some use ghcup or Stack, which also aim working without a system package manager, but at least a system package manager is a viable option.
You didn't have an up to date system if you use Debian stable. They do not keep their packages up to date.It just seems weird to blame Rust for a problem you had with your package manager, when every modern ecosystem I can think of eschews distro package managers because of these problems.
This appears to highlight differences in our perspectives: while working with (and supporting software for) 4 most recent major Debian releases, the latest stable one feels like a fresh one to me, especially if it is updated to the latest available package versions (and minor release). The packages are not supposed to be cutting edge there, but "stable".I also don't mean to blame Rust's ecosystem (let alone the language itself) in the sense of complaining about it, though talking about this feels that way, and I thought it might be useful to clarify: it appears to aim less "stable" and more "cutting edge" (or "experimental") versions and practices than "stable" system distributions do, and than more mature ecosystems tend to do. Likewise, I wouldn't call having a slightly older compiler version in system repositories a problem with package manager: this is a useful approach for getting a stable system, relatively well-tested and with predictable changes. Not every system has to be this way, but in some cases it is useful, some people (myself included) generally prefer those. And unfortunately those fail to play together smoothly at the moment, but I view it as an issue arising between those and their approaches, not as a problem of one of those.
Let me ask a more foundational question then, what is the virtue of a "stable" system?In my mind, it's that updating a dependency doesn't break existing installations, or knowing that an existing install isn't going to get borked by an update.And this is not something that is applicable to ecosystems like Rust, where it's not really possible to break a Rust program because another Rust program needs a newer version of the same dependency that happens to be incompatible with the older version. In fact, you can compileoneRust program that links against multiple versions of the same dependency at incompatible versions without issue.So the entire notion of the Debian model of package management doesn't really apply to Rust, and there's not any benefit to keeping an older version of the toolchain around. There are only negatives.And Rust has strong stability guarantees. A newer toolchain will not break compiles of older code. Nor will Cargo's cache break compiles with an existing lockfile because another package needed different incompatible versions of the same dependency. It's designed to be stable from first principles, in a way that C and C++ builds are not.This is kind of why you're only going to have a bad time if you want to use the system package manager to manage your Rust packages. It's not built for the same problem domain, and over constrained for the design space.
> Let me ask a more foundational question then, what is the virtue of a "stable" system?Not introducing breaking changes too often (so that you have to adjust configuration and custom software relatively infrequently), while applying security patches and other bugfixes, and being well-tested to work together are the first ones I think of. With "breaking changes" including changes to configuration, file formats, command-line interfaces, notable behavior, as well as library interfaces. Well, I think it mostly amounts to "knowing that an existing install isn't going to get borked by an update".Supporting multiple dependency versions and stability guarantees indeed must help with avoidance of breaking changes in libraries, assuming the latest compiler version (or a dependency restriction: either compatible packages in system repositories or if there was such dependency resolution in Cargo), though probably not so much with fixes (I imagine there is less motivation to maintain stable branches and apply fixes to those then) and with integration testing. Besides, not all software is written in Rust: other packages and ecosystems must be taken into account as well. Likely more varied ecosystems can be handled more smoothly with NixOS or GuixSD, but I am not risking to use them on anything that should be reliable yet (maybe it is the time to look into those again though). But this kind of poor compatibility with stable systems does not seem necessary, especially for a language that is supposedly a safer alternative to C, while C is about as well-integrated into--and compatible with--common (POSIX) systems as it gets. Though then again, above it was noted that our experiences with C differ, but this is how I see it.
Feel free to use stable, plenty of libraries target stable.At the beginning I was using stable without many problems.I switched to nightly to access the last language features and I have no reason not to use it (I've never encountered a nightly bug in 4 years)Haskell is my favourite language (if we forget prelude, exceptions, strings and a few other warts) but Rust wins hands down on pragmatism and getting things done.
The tooling (cargo vs stack) is way better and there are more production ready libraries to do cool things.
> env.args instead of an argument parsing library.I'm sorry do you not usehttps://github.com/clap-rs/clap?
This is the one I tried to use, but failed to, since one of its dependencies required a rustc version newer than what I have here (1.63.0), and cargo was not able to pick the latest compatible version, but suggested that I do that manually instead. Which surprised me as well, since I keep hearing about it being nice, yet resolving dependencies is something other package managers (and Cabal in particular) tend to do. I tried to find what is the last version of that package supporting my compiler version, failed to do it quickly (how is one supposed to go around such a task, by the way?), and gave up.
It appears both clap 2 and clap 3 have packages in bookworm. Were you trying to use them from crates.io instead of apt? Clap is on version 4 there.> how is one supposed to go around such a task, by the way?There is not great tooling for this, because most people use the latest stable when starting a new project, and then rust being backwards compatible means things Just Work into the future. A vanishingly small number of folks use builds significantly older than that, since upgrading is generally trivial, and newer compilers have faster build times and better error messages.
Oh, I have not tried using it from system repositories: I tried that with another library (in a hobby project) before, had issues with that, been told and generally gathered that it is easier to pull dependencies with cargo, so went straight to that this time. I see that librust-clap-dev would pull 157 other packages with it though, but will look more closely into it: I would actually prefer getting dependencies from system repositories, thanks for pointing it out.As for newer compilers, I prefer to depend on system repositories and package manager for updates, and to stick to stable branches, so that things do not change too often. I see the appeal of rolling release distributions and cutting edge software, but not feeling comfortable using it for things that are supposed to be reliable.
So to be clear, I do not recommend that you use the rustc provided by Debian for general development. But if that’s what you want to do, by trying to mix a rustc from Debian with packages from the general ecosystem, it is going to be the worst of both worlds. I would ignore crates.io if I were trying to do what you’re trying to do. You’ll have less access to packages overall, and be using older versions, but they’re at least known to work with each other and that specific rustc version.
I'm fascinated by that description since it's the total opposite of my experience using it. I'd love to see what happened if you have a repo.
I'm simply intrigued at this point.
They are using a rustc from August of 2022. If you installed that version, made a new project, and asked for the latest clap, it would not shock me at all if rustc were too old.EDIT: from clap itself:> We will support the last two minor Rust releases (MSRV, currently 1.70.0)So yeah, 1.63.0 is going to be quite old.
I see!
Steps to reproduce, once you have cargo and rustc from Debian stable repositories: cargo init && cargo add clap && cargo run. The following happens:error: package `anstream v0.6.4` cannot be built because it requires rustc 1.70.0 or newer, while the currently active rustc version is 1.63.0
    Either upgrade to rustc 1.70.0 or newer, or use
    cargo update -p anstream@0.6.4 --precise ver
    where `ver` is the latest version of `anstream` supporting rustc 1.63.0
For what is worth, you can usehttps://lib.rsto see the earliest version a crate supports. For Rust 1.63.0, you will have to rely on Clap 4.0.32 from December 2022, instead of anything newer (which only support 1.64.0+):https://lib.rs/crates/clap/versionsFor anstream, the situation seems more difficult for you, as it doesn't seem that there's any (non-yanked?) release that supports <1.64.0:https://lib.rs/crates/anstream/versions
Thanks! I was looking for a page like that on docs.rs, crates.io, and possibly on lib.rs as well, but missed it; that is likely to be useful in the future. Actually now I see it on crates.io as well, <https://crates.io/crates/anstream/versions>. Or maybe I saw it before, and just have not found versions <= 1.63.
Rust looks nicer and nicer. Is anyone familiar with RAM/Memory requirements as compared to c?Every microcontroller project I've worked on, as we approach maturity, goes through a round of freeing up ram and code space. Usually deleting strings, removing debug functionality, or shortening datatypes.. etcCan I write rust code with the same footprint as c code?
My employer does embedded Rust. We built our own little OS, Hubris, as the foundation of those projects. A no-op task in Hubris ends up at like 100 bytes, last I measured.https://hubris.oxide.computer/You still have to like, actively think about binary size in order to get things to be that small. But the smallest x86_64 binary rustc has ever produced is 137 bytes. How small your program is up to you, not Rust.EDIT: Oh yeah, I left a similar comment with more details about a year ago:https://news.ycombinator.com/item?id=34032824
You might enjoy this blog post:https://darkcoding.net/software/a-very-small-rust-binary-ind...It illustrates the steps to take Rust from 3.6MiB executable to 400 bytes, by stripping more and more things away, and changing things.
Also see min-sized-rust repo[1], which also has this blog post at the bottom (along with others)[1]https://github.com/johnthagen/min-sized-rust
thank you! I am currently enjoying it
You definitely can use rust in an embedded space.  I rather liked having traits and proper types instead of a giant mess of integer constants.  In general I think a lot of the so-called bloat you see with Rust binaries is due to a combination of not using a shared standard library and generics – the former is a non-issue in an embedded context and the latter is well under your control.Sure, ELF includes a lot of fluff but you're not deploying ELF on a microcontroller.
yeah I think I just need to write some stuff to figure it out.I was mostly trying to figure a 1:1 comparison. For example, If I write a Feature Control module in c and in rust, using the same design, are outputs similar?seems like either no one has a good sense of that comparison, or it's a bad comparison and I don't understand why.What I'm trying to avoid is having a space-saving task be "rewrite rust module X in c to save code memory"
IMO it would be good to familiarize yourself with the rust quirks/features (check out the rust book) and then poke at some of the embedded specific groups.  Once you get a handle on the common types and patterns it's probably easier to find the information you're looking for, e.g.:https://github.com/rust-lang/rust/issues/46213In general Rust chases a "zero cost abstraction" ethos, so a lot of the type system niceties have no code or memory cost because the heavy lifting is done at compile time, not run time.  For instance using specific traits for each GPIO pin ensures you won't accidentally apply some meaning meant for another pin, but the compiler will compile it right down to integers anyhow.Things like options (how Rust deals with "null" values) are enums and usually incur a one byte penalty, but in some cases they can be compiled down to no overhead at all.
> it's a bad comparison and I don't understand whyDifferent languages are different, and so it's tough to compare. You don't generally write Rust code in the same way you write C, and so a "using the same design" constraint on a comparison means that some folks will not consider it to be an accurate one.In general, similar constructs have the same amount of overhead, that is, zero. Rust has additional features that are useful that can increase code size if you're not careful, but getting that back down doesn't necessarily mean abandoning Rust, but itmaylead to "write the Rust closer to C." I am thinking of generics specifically here, monomorphization can blow up your code size, but you could either not use generics or use a few techniques to minimize it.
I used Rust for my latest embedded project based on an MSP430 from Texas Instruments. The specific model has 128 bytes of ram, and it fits there quite neatly. Same for the flash.This was quite the great experience!
That’s 128KB, right?
Nope, the B was not a typo. It has 128 bytes of RAM.The specific model is an MSP430G2231 [1] with 128 Bytes of RAM and 2kB of flash.1:https://www.ti.com/lit/ds/symlink/msp430g2231.pdf
In the MSP430 family? Not likely.
Going off topic, but the size of the programming language communities is a good source for shuting down the Kotlin folks on how the language is taking over the world.17.5 million users versus about 6 million, basically the ones being driven by Google to Kotlin on Android.Back to topic, I feel Rust is a great language for production on scenarios where having automatic memory management is forbidden, like in high integrity computing, GPGPU code, micro-controllers and such.Everywhere else, a mix of automatic memory mangement, value types and eventually linear typing, are a much ergonomic approach.
The benchmark link doesn't work for me. (Blame my adblocker??) The graphics in the article are interesting but don't include a way to identify which are Rust/Java/Go/Python. Maybe you're supposed to assume they come in the order given, but the x-axis is time... could definitely be clearer. (Also apparently not from the OP, just the cited article.)
Also, this kind of throughput in Java 11 in 2021 while Java 17 was already out is a bit meh.Nowadays, with Java 21 and virtual threads, results might be quite different (and the default GC has changed as well).I agree with the graphs being unreadable. The tables in the benchmark article are easier to read.
Also, not using ZGC when latency is the focus just strikes me as unserious."Benchmarked on JDK 11, with G1"
The first link is missing a "7" at the end, that's why it 404s. The second one works though:https://medium.com/star-gazers/benchmarking-low-level-i-o-c-..."Rust, Go, Java, Python" in order, left to right, yes.
There's an oddity in that article...the C++ p99.9 is lower than its p99.  Am I crazy or should that not be possible?
That is confusing to me as well, yes.
Author here. The link is fixed thanks to M3t0r on GitHub:https://github.com/corrode/corrode.github.io/pull/6The source code of the blog is open source. Contributions like these are very welcome.
> And the whole crate terminology is just stupid. What am I, a dock worker or software designer?Of all the reasons to complain about a programming language, the package manager not being elitist enough is certainly an original one.
> Meaningless error messages, unreadable syntaxes, forced structures, no explanation why the solution to certain errors is importing some lib.The compiler has pretty good error messages, `rustc --explain` exists, "unreadable syntax" is a common complaint from people that expect everything to be C-like or Python (or are just trolling), "forced structures" is explained by Rust being a statically typed programming language.> You write backend code as of you were writing frontend code, which is not enjoyable.No idea what's this about.> You always have to think about who owns what.If your code is well-structured this is a non-issue. The types of people that complain about ownership are the ones that write messy code with chaotic inter-dependencies and unclear semantics.And besides, you have to do that anyway in e.g. C++, only it doesn't enforce it, which leads to programmer error, which is worse. Or you can use reference counting if you have skill issue.> Compile times are long.Compared to what? They aren't much longer when comparing apples to apples: C++ with static analysis tools and Valgrind will have pretty much the same compile times. Again, a bold general statement that doesn't really say much.> What do you gain in performance compared to Go? Not a while lot, and you pay with wasted time aka increased development time and more complicated thought process.Performance in what? For non compute-intensive tasks you can obviously pick any language you are comfortable with. Obviously there's no point using C++ to serve a static site when a simple Python server will do. In benchmarks, Rust just murders Go in performance, so you are objectively wrong if you are talking about raw performance.> that means it's a propaganda postBased on your wacky arguments, I'd say that your comment is in fact propaganda.
> What am I, a dock worker or software designer?You really must hate this thing we use instead of VMs nowadays.
Rust is a really frustrating language for me: I understand the safety it provides but find the pain of actually using it makes it uncompelling. Plus, the Rewrite it in Rust movement is very off-putting
Rust is a frustrating language for me too.I never saw the need for it, really. I just stuck with the language constructs in C++ that makes it basically impossible for memory leaks/use after free/use outside of bounds to occur or if they do occur, explode loudly in debug environments. I haven't used new/delete in a personal project in like a decade; longer than Rust has been around.Now I'm working on a project where the main developer is...a cowboy. Everything is insane. Not only is new/delete everywhere, but so is malloc/free. In C++ code. You have to navigate to where the thing is allocated to figure out whether to use free or delete. Everything leaks, everything crashes, everything races, everything deadlocks.Oh and the guy is my boss.So on the one hand, rust might fix these problems, on the other hand, rust is a non-starter.So now what. I still don't need rust because I don't code like a crazy person. And the people who do code like crazy people will never use it anyway because it doesn't let them...express themselves.
I am yet to see someone who can't make memory safety mistakes in C++. You might want to start a tutorial series on how to do that. If this skill can be taught that is, and isn't genetic.
Memory safety issues in C++ have two main causes. One is object lifetime. The other is pointers. If at all possible you want to design your program such that object lifetime is completely obvious and predictable. Use sentinels and tombstones instead of null pointers. Use arenas wherever possible. During debug use an allocator that doesn't reuse memory (just mark the pages as no access so you will segfault when trying to read/write in previously freed memory). When object lifetime is complex you can give objects a "color" during allocation and then make rules that you can verify that objects of one color can never have pointers to objects of another color, or that an object can never contain a pointer to a younger object. You can eliminate entire categories of memory problems this way. Instead of pointers use indices and a getter function. In debug mode the getter can check if the right locks are held, scan the heap for incorrect pointers, check for ownership flags, etc. Actually take advantage of the virtual memory tools provided to you by the operating system. Threadlocal memory. Fork tasks into different processes. Actually use mprotect and the like.Zero memory safety mistakes is a tall order. But the overwhelming majority of memory errors we see in the wild can be easily prevented by good practices. And for the memory errors that do happen stack protection flags make a big difference (https://developers.redhat.com/articles/2022/06/02/use-compil...).
nobody is perfect, but some people create mnay less leaks than others. Modern C++ is the rules those who create few leaks follow.
I don't claim to never make memory safety mistakes in C++. I just claim that it's very rare. The overwhelming majority of my bugs are bugs in business logic.At my day job, I work on a project that's 75% C++ and 25% C#. In the code that we've shipped, when there's a crash in code that I've written, (as opposed to business logic bugs) it's usually a memory safety mistake in C#. There was aninterestingarchitectural choice written a decade before I joined the company where most classes have a synchronous constructor, then an asynchronous initializer, then an asynchronous uninitializer, then a destructor that gets run by the GC. There's no end to bugs relating to crashes because the initializer hasn't been run yet or the uninitializer has already been run.When I get C++ bugs put across my desk in code that we've shipped to customers, it's usually a bug somewhere else. For instance, the last crash dump that we've gotten from customers in C++ is because a we called a Windows UTF-8/16 conversion function. The Windows function itself is all raw pointer nonsense, so we put a pretty wrapper around it so you put a std::string_view in and get a std::wstring out, or you put a std::wstring_view in and get a std::string out. Well, it turns out Windows is a fucking dogshit operating system. If you initialize a thread "wrong", ie, by calling the C11 function thrd_create, and your locale is set to a CJK language, it will ignore you when you tell it the code page of the multibyte string is UTF-8 and will assume it's the system locale's code page, and will call abort() when it hits a UTF-8 sequence. (instead of perhaps returning an error or null pointer) Those are the sorts of C++ crash bugs that I deal with.My 'secret' to dealing with memory in C++ is to not deal with it. Make the STL do everything. Make RAII do everything. Can this object be POD with constexpr accessors? Do that. Can these methods be const? Do that. Can these objects live in a STL/boost container? Do that. Do they need to live in a unique_ptr/shared_ptr instead? Fine I guess but it would really be better off as a value instead. Does this class need to have a special destructor/copy constructor/move constructor? Find some other way to do it. If you must, try to find some other way to do it anyway. If youmust, spend like 10x as much time scrutinizing it, the way a Rust programmer would do with unsafe. If thing must have special destructor/copy/move constructors, factor out all of the things that need special consideration into a class with the barest minimum. If it must have a special destructor, explicitly delete the copy/move constructors/operators if you can. Avoid indexing into arrays; use range based for loops, or <algorithm> stuffs like transform, reduce, or transform_reduce. The solution isn't to use vector::at() (which does bounds checks) instead of vector::operator[] (which doesn't) the solution is to not use indexes at all.
Interesting suggestions.How do you "hook' a function, like you said about malloc,free, main and exit?I guess it means intercept calls to it and do something additional to what it already does, something like Python decorators, but how do you do it in C or C++? I used C a lot (but not C++),  but much earlier, and don't remember any method of hooking. atexit(), or something like it?
Given that they mention ifdef, I guess they just mean something like `#define malloc(x) (tracing_malloc((x))) ` in every place except the one where the tracing version is defined.
hungarian standardizes procedure/function names anyway (typed and capitalized), so while you're changing the name, it gives you "a place to stand" to do the other things you want to do.for normal/average operating environments, I prefer to just indirect through an extra procedure call, gives you a place to put a breakpoint, and then if you need streamlined performant code you can #define it all away. But, if you plan to #define it all away, make sure that is a regular part of your work flow beforehand. you can have a procedure version, a heavyweight define and a lightweight define (and use your defines inside your procedure to test them there). On a regular basis you need to make sure your infrastructure is all doing what you think it is.Same is true for main(), use it for setting up infrastructure, have it call Main() which is "your main".if you are on a large enough project you can budget time for tools, the actual "__main.asm" code that calls C main() is also accessible and you can hook away in there too. Have to do it for all compilers, and track compilers, but on the scale of a large project, that's not the end of the world.
Why do that with the preprocessor rather than the `--wrap` flag? That's what most malloc libraries do.
I should take this to the security team although I have a hunch that they'll think I am full of shit. What with the CVE count never going down with asan, ubsan, tsan and all kinds of guidelines, analyzers, tests and what not.
Hungarian notation has never been proven to reduce errors compared to strong types, and the CppCoreGuidelines tell you not to use it. clang-tidy can largely automate Hungarian notation, at least.
the goal of hungarian is to ease/automate the cognitive burden on the programmer while in the act of reading or writing code, it's the semantic notion, not the syntactic
> I still don't need rust because I don't code like a crazy person.This is not a foolproof argument because safety problems can easily result from unforeseen interactions among parts of the code that all seem to be OK and not "crazy" locally.  A significant benefit of something like the borrow checker is that it can suss out these problematic interactions in a comprehensive way, even at the cost of forbidding some code patterns that would be perceived as safe in most cases.  (Idiomatic use of Rust then requires you to either rewrite such code or stick it in an unsafe block and figure out what the preconditions are for it to be used safely.)
I'm new to Rust, but wouldn't it be possible for the "C++ boss" to start writing Rust code like below? Here I think we have a multi-threading race condition that can lead to a crash (?)use std::sync::Arc;
  use std::thread;
  use std::time::Duration;
  
  fn main() {
      let shared_data = Arc::new(42); // Create an Arc
      let weak_ref = Arc::downgrade(&shared_data); // Create a Weak reference
  
      let thread_handle = thread::spawn(move || {
          // Simulate some work
          println!("Thread Data: {}", shared_data);
          thread::sleep(Duration::from_millis(10));
          // The Arc is dropped at the end of this thread
      });
  
      // Give the other thread a little time to start up (this is part of the race condition)
      thread::sleep(Duration::from_millis(10));
  
      // Try to upgrade the Weak reference and unwrap directly in the print statement
      println!("Weak Data: {}", weak_ref.upgrade().unwrap());
  
      // Wait for the other thread to finish
      thread_handle.join().unwrap();
  }
Sure, that does seem to be a race condition that can crash. I'm not sure how valuable this example is though, because it's not very intricate at all: a Weak reference can be invalidated (duh!)The fix is trivial: just use an Arc instead of a Weak. In addition, `upgrade().unwrap()` should be a sizable red flag (like any unwrap, really) since fallibility is kind of the entire thing of Weak.
Thanks!But Weak can be needed in case you have self-referential structures, right?I was wondering about this in the context of the C++ programmer in post above who likes to use both new/delete and malloc/free in his code.Sure, Rust will give him far fewer ways to screw up. But if he can't be asked to at least not use malloc/free in C++, he probably won't be too careful about unwrap() either?My point here is mainly that a good programming language won't make good programmers out of bad ones.
> But Weak can be needed in case you have self-referential structures, right?Well, technically, no, you can just use Arc and leak memory all over the place :^) but that's not very useful either. Most self-referential structures need some kind of "owning" thing too though. For example, a graph could use Weak for the edges, but in order to keep vertices alive you need e.g. a Vec<Arc<Node>>. Then, if upgrading fails, you know that your edge leads to a deleted vertex (and as such should be considered nothing, hence Option).> Sure, Rust will give him far fewer ways to screw up. But if he can't be asked to at least not use malloc/free in C++, he probably won't be too careful about unwrap() either?There's one big advantage of messing up with unwrap vs malloc/free: unwrap 'only' crashes your program (and can even be caught in some scenarios), whereas use-after-free can do literally anything. Unwrap is also much easier to debug because you usually get a clear stack-trace, and the program semantics have been well-defined at all points.> My point here is mainly that a good programming language won't make good programmers out of bad 
ones.Very true! But I think the point of Rust advocates tends to be more along the lines of "a bad programming language makes a bad programmer out of a decent one". It is very easy to misuse C++, so mistakes are made with it way more often. 'Dangerous' constructs do exist in Rust, but are generally far less pervasive, making it easier for the programmer to understand what they are doing.Saying Rust has no benefits over C++ because you can mess up in both is like saying that anti-lock brakes are useless because you can still understeer by pressing the accelerator too hard (sorry for the car analogy, I had to). Preventing entire classes of mistakes is valuable, even if other classes are still possible. (If it's worth the cost is of course another question. My personal opinion is yes, although that's especially for memory safety and a bit less for race safety.)
> Saying Rust has no benefits over C++Sorry, that wasn't my intent. It was more to point out that bad programmers are surprisingly inventive when it comes to write bad code. New languages are an improvement, but not a panacea.
Rust does not protect against race conditions, since these are mere logic errors that don't impact memory safety.  This program can panic when unwrap() fails, but that's also a safe operation.
Most race conditions are prevented by Rust thanks to its "alias XOR mutable" paradigm that prevents having multiple mutable references and enforces the presence of locking or atomics. Not all, but the words "fearless concurrency" aren't meaningless either.
What kind of solution would you propose to folks like your boss?One positive aspect I see about "rewrite it in Rust" is that you can tosomedegree expect a random Rust project to not leak and crash and expose vulnerabilities quite as much as a random C++ project. It's silly, but "written in Rust" acts somewhat as a badge of safetyandperformance, whereas "written in Java" and "written in C++" each only carry one of the two.Of course, developer skill is also huge. You can write slow Rust code or fast Java code, yadda yadda.
That example is really difficult, because between the lines it sounds like it has been working sufficiently well despite the cowboy style, substituting methodical error-avoidance with that special kind of brilliance of super deep code knowledge and remembering all the pitfalls. Very difficult situation.Regarding "rewrite in Rust", I believe that it's a smaller part of theappealof Rust than it appears based on the amount of code actually written: the main excitement is from people who never really ventured from heap+gc languages into manual memory management but who love theideaof being able to write gc-less native code. And many of them would rather write it slowly, one borrow-check at a time, than with all the memory bugs they created dipping their feet in naive C/++. Those people rarely write much Rust, but their excitement infects some in malloc/free land and for them a rewrite is super attractive because it skips the entire explorative part of software development that is really not the strong point of Rust.(yes, this is pure projection, not only was I describing what draws me to Rust, I also failed to pick up on the codebase of my previous boss, too much "how can we make this entire thing less slow and error prone" and too little "cram in requirement X, even if it might turn out to become requirement Z because it pushed the codebase over the edge to terminal unmaintainability")
> the entire explorative part of software development that is really not the strong point of RustThis is what keeps me orbiting but never quite landing on Rust. Things I'm pretty damn sure are safe come back red-stamped, and once I've painted things the way Rust deigns, I find I've lost my appetite. When desire finally returns, I find the fixes I've made to enable compilation also disallow the changes I wanted in the first place.For all its faults and runtime bloat, I find myself going for Go on new things I would've attempted in Rust before. Though, I've never tried Zig; I wonder how that is...
You can do exploratory programming in Rust, it's just heavy on boilerplate code such as .clone() and Rc<RefCell<>> which would be avoided when writing more idiomatically.  Rust even includes support for dynamically typed references and downcasting via the Any trait.  It's not as dynamic as Python/Ruby/JS etc. but it's not that far off either.
Java is slow is a really old myth. It was once upon a time. Ofc there are caveats but looking at your average developer ... You will be fine.On the other hand I would forbid an average developer the use of c/c++ and similar. It is just not worth it.
How is a software written in Java having less assurances in terms of leaks/crashes etc compared to Rust? All Rust gives you is a borrow checker that isn't very smart, but means you don't need GC/VM, so you gain a bit of performance compared to Java.But if it's not software that needs to go fast, then Rust is not adding anything for you. And if you considered Java to begin with you probably don't need top tier performance.
The parent didn’t suggest Java is less safe; their point is “Java is safe; C++ is fast; Rust is both” and they just phrased it unclearly
The most notable advantage of Rust compared to GC languages is low and stable memory use andpredictableperformance, that will not generally drop due to some random GC pause.  Both of these can be of interest even wrt. software that doesn't "need to go fast" in any absolute sense.
This is a persistent myth that’s only true if your performance model requires persistent latency and, even then, only if you’re careful to pay attention to how much is freed or allocated as you change scopes. The lifetime tracking features of Rust’s type system have non-negligible impacts on the sorts of abstractions you can make.
Sure, there is one abstraction that effectively requires GC, namely a general graph of spaghetti references where you can't possibly predict in advance or "pay attention" to" how much is freed or allocated as you change scopes".  Many GOFAI problems look like that which is why GC was initially developed in the context of LISP, the most prominent language for GOFAI.  But for most real-world programs you can do vastly better than that.
>> What kind of solution would you propose to folks like your boss?How do you want to play this boss? I can see you’re focussing more on the bigger picture and the code is just a means to an end, given that,  how about you delegate technical leadership on the codebase to me to let you focus on the product & commercial aspects?If no - maybe words come back to the effect of “it’s my pet/child, how very dare you” yadda yadda - then I can’t see a happy path beyond “thanks for the opportunity, all the best for the future” but there’s certainly room for many mediocre outcomes short of parting ways if that’s preferred.If yes - “hey, we don’t have infinite money and we prob can’t afford to hire the help to do this to a gold standard so how about we agree these commercial milestones (once change delivery falls below X days on average, or once feature Y that you always wanted lands in prod, or once the defect rate drops below Z per week etc etc) - I get bonus $$$”
> What kind of solution would you propose to folks like your boss?Rewrite it in C#. It’s safer than Rust, because VM. Both standard and third party libraries are often way better. With modern versions  of the language, GC allocations are avoidable if that’s what needed for performance reasons. C interop is equally simple.
C# is not more safe than Rust is and falls to prevent null pointer exceptions and modified collection exceptions.
> C# is not more safe than RustBy design, Rust requires unsafe code to implement any non-trivial data structures (except trivial POD types). This applies to both Rust standard library, and third-party crates.The issue is not a theory, security bugs actually happened in reality. Here’s an example about the Rust standard library:https://shnatsel.medium.com/how-rusts-standard-library-was-v...By contrast, thanks to the VM and the GC, C# allows to implement very complicated data structures without any unsafe code or unmanaged interop. The standard library is also implemented in idiomatic memory-safe subset of the language. For example, here’s the hash map:https://source.dot.net/#System.Private.CoreLib/src/libraries...> falls to prevent null pointer exceptions and modified collection exceptionsYes indeed, but these exceptions are very unlikely to cause security bugs in the software.
> Rust requires unsafe code to implement any non-trivial data structuresThat seems like a gross overstatement.https://github.com/rust-lang/rust/blob/master/library/std/sr...CTRL-F: unsafeOnly one result, an optional utility function: "pub unsafe fn get_many_unchecked_mut"
That's a wrapper around the actual implementation (which lives in an external package). Notice "use hashbrown::hash_map as base;" at the top.There's far more unsafe there:https://github.com/rust-lang/hashbrown/blob/f2e62124cd947b5e...
The entire JIT, garbage collector and most of the C#'s VM are all implemented in C++. This has caused various issues in the past which are exploitable from managed code. The amount of unsafe code used to implement C# vastly outweighs the amount in Rust's standard library.
If you are going that way, Rust's reference compiler is dependent on LLVM, fully written in C++, and the C++ semantics of bitcode have broken Rust's code generation multiple times, forcing regressions and newer compiler releases with desactivated optimization features.Also plenty of crates are bindings to C and C++ libraries with nice unsafe blocks.Then was that Axium drama.
Hmm? Dotnet on Linux uses LLVM for codegen so that seems to be a wash. Lots of nuget packages are wrappers around native libraries as well.
Yeah, doesn't make Rust's dependency on C++ go away for its safety.The point is the "look at what I say, not what I do", when talking about safe languages and dependencies into C and C++ libraries and compiler toolchains.
Which doesn't really have anything to do with GP's incorrect assertion that C# is somehow safer than Rust.
It has to do with yours incorrect assertion that using C++ in the runtime is a disadvantage for C# in regards to Rust, which equally depends on C++, in both of its compilers toolchains, rustc and gcc-rs.When Rust gets fully bootstrapped in self hosted toolchain you'll have a point.
I think you've missed my point entirely but that's fine.
> The amount of unsafe code used to implement C# vastly outweighs the amount in Rust's standard library.According to bing.com chat,https://github.com/dotnet/runtimehas 3.5M LOC, andhttps://github.com/rust-lang/rusthas 6M LOC. The right panel ofhttps://github.com/dotnet/runtimesays 80% of the .NET runtime is written in C#.This makes me wonder, do you happen to have a link for your “vastly outweighs” statement?
The "link" is just the repos rather than asking AI to hallucinate an answer. Rust's repo contains 2.2M LOC. The dotnet runtime contains 1.5M lines of C++.Now if we remove in tree tests from the totals, we arrive at 1.5M lines of C++ (most tests are written in C# as you would expect) and 1.7M lines of Rust.However, this does not exclude safe Rust code. I don't have a tool off hand that can provide a precise count of lines of unsafe code but we can get some general estimates. There are 1958 instances of "unsafe fn" out of 103,205 instances of "fn ". Further there are 11,545 instances of "unsafe " in the Rust repo while there are 10,768 instances of "unsafe " in the runtime repo.Given that unsafe functions comprise less than 2% of all functions in the Rust repo, I think my claims are reasonable.
Not necessarily VM, depending on how it gets deployed.
Could you expand on how to avoid using GC in C#?
Don’t create new objects, instead use stack and/or unmanaged heap.This reduces the expressive power of the language, for example LINQ from the standard library is probably out because based on the delegates which require memory allocations.Still, the language is very usable even without GC allocations. For example, that library re-implements a subset of ffmpeg for Raspberry Pi4 running 32-bit Linux, with no memory allocations in runtime:https://github.com/Const-me/Vrmac/tree/master/VrmacVideo
Value types (structs), stack allocated arrays, spans, native memory allocation, arenas.You can also enable the warnings/errors that complain about missing using declarations for class and structs with the Dispose pattern.
Hell is other people’s code. Of course our code is perfect, and we would never write a buffer overflow or issue that would be solved by memory safety. But I find consistently that other people seem to, and then I’m forced to contribute to the same code base.
GP isn't wrong though. There genuinely aretotalhell codebases. Not everyone is as dedicated to their craft like Mozart was. There are levels. And some teams and individuals do indeed produce better outcomes because not only they know how but also show how.
It might not help you today with your immediate problem but think about it this way:You become the boss or responsible for some product.
If you decide at the beginning to start off using Rust or rewrite some ancient, unmaintained library using Rust, then you prevent people like your cowboy developer to mess stuff up with this category of faults.Either you would not hire him in the first place because he never came to grips with Rust so you only end up with developers on your team that understand and actively chose the tradeoffs that Rust offers.
If the cowboy developer is the boss they can still just wrap everything in unsafe blocks.  But I think I'd take that over the C++ new/delete/malloc/free salad.
At least `unsafe` blocks tend to raise other people's eyebrows rather quickly. The word itself is telling you to take a double take after all.Some rather "questionable" C/C++ code can, and are missed during code review sessions. One could put the blame on code reviewers, but let's be honest, code reviewing is a mindnumbing task for many of us.
Please write a book about this. I'd want to read it!
I'm not a C++ programmer,  but aren't there plenty of "Modern C++" books out there already?
I meant about the experience
It's honestly unfortunate that rust has been sold so hard on memory safety, so that when C++ folk don't spend tons of time in memory issues they think rust is pointless.I don't want rust for memory safety. I want it for things like proc macros, a sane module system, a good and accepted error handling system, destructive move, constrained generics, unified static and dynamic polymorphism, language level customization points, and many more things.
Rust was a language that I firmly embraced for my own projects for about 2 years, then I eventually came to the conclusion that the benefits it gave me weren't really that useful for the things I was working on, and I switched away to other languages that I personally enjoy using more.
Which languages do you enjoy more?
Rust pissed me off until I stopped fighting it. When I finally gave up and started doing things its way, it became a lot more fun. And `cargo clippy` is flat-out helpful for learning Rust’s idioms.While I’m not yet out to rewrite all the things in Rust, I understand the appeal of rebooting archaeological projects with a modern approach.
The thing is, I just don’t want to write programs the way Rust wants me to. Among statically typed languages, Java is the closest to what I want to use but my true love is Common Lisp. With the arrival of Coalton, I can get the best of both worlds: a type system with nice properties for the rare program that would benefit from them and CL for the majority of programs.
Then I guess you don't have to write Rust? It seems like it doesn't solve any new problems for you so don't feel forced or pressured to use it (for any technology, really), and I say this as someone who really likes and uses Rust.
Yeah, what’s frustrating is (a) I wanted to like it; (b) it’s taking up a lot of the job market relative to other alternative languages I’d rather use; and (c) I like the language Graydon describes as “the language I wanted”https://graydon2.dreamwidth.org/307291.html
Seems like you want something like OCaml then.
B is exactly how I've felt about, in order: C, C++, Java, C#, Javascript.  I spent almost 20 years writing languages I did not like because I couldn't find jobs in anything else.Rust saved some of us from a lifetime of exactly the problems you have with Rust, maybe let us have this one :)
So, the reason Rust took the direction it did is that alotof people want a language specifically like this, while there were already plenty of languages roughly in the ballpark Graydon wanted. I don't have a clear use for one of those languages, I might use it in some cases anyway, but I wascompelledby Rust, it's more or less exactly what I needed.I can have a proper type system like an ML,andtouch the metal like C? Yes please.
Alright, so when I’m appointed Lord Emperor, we’ll all be writing CL. Until then, I’m digging Rust. It’s like garbage collection, but where you can always tell exactly when a thing is going to be collected.
Unless you happen to be using something like Rust/WinRT and to avoid the usual stop the world cascade deletion when smart pointers in a complex data structure all reach 0, have a background thread collecting those smart pointers.
There’s no plausible scenario in which I’d ever write a single line of Rust/WinRT.
Doesn't change the fact it isn't always obvious.
Yeah, there’s enough ways that rust makes really tedious choices in generics, type system stuff, and its particular flavors of affine memory as a resource logic that I’m considering building my own wee language.
As far as specific complaints go, async rust seems to be a trap: I’ve heard of several companies adopting it and then regretting the decision six months later because of the failure of that abstraction to adequately abstract.
For more anecdata, I have been working professionally with async rust for three years and don’t understand why people complain so much about it. It solves the problem well, it provides predictable performance, and most of the time it’s straightforward to write and reason about.
It's difficult to avoid, right? If you are writing a network server or client that manages a lot of connections, you can either use the popular async executor or you can stray far from the beaten path.
Rust is for people who stick around, can come over hurdles,  can take in new concepts and see the overall benefits. It has a steep learning curve that pays off.For me there are three reasons why Rust is suitable for many usecases:- performance- safety- static binary compilation with targeting different cpu architectureAfter spending majority of my time with Python and Java in the last 10 years these are things i really learned to appreciate.
> Rust is for people who stick around, can come over hurdles, can take in new concepts and see the overall benefitsSpeaking as someone who is learning Rust and really liking it, I just want to note that this comment is sort of emblematic of what is wrong with the Rust community. It comes off as pretty condescending—"Rust is for the people who are smart and don't give up easily, if you're less smart or give up easily you should really go find a language for wimps".
Sorry i do not want to sound condescending. I was just explaining my own experience. The first time I wanted to learn Rust I failed because I gave up.
Performance and static binary compilation are available in 40-year-old languages, not forgetting Dlang, which is the central topic of this post.The only reason left to really use Rust is safety.
And the safety reason is also fulfilled with Ada/SPARK2014 as an alternative to Rust with a longer legacy in high-integrity applications.
Performance isn’t a problem for Java for just about any business application most programmers will work on and, if it is, you can usually figure out how to optimize Java to hit your performance target.  Safety is also not a problem in Java. And fat jars remain the single best way to deploy an application I’ve seen in just about any ecosystem (and nix is working out pretty well to bring their benefits to the rest of the programming world).
Even better than fat jars are jlink‘ed images, maybe even wrapped in a nice shell using jpackage. Bundling the JDK and stripping it of unneeded modules eliminates so many types of issues. All courtesy of your JDK.
I have the exact opposite experience. In fact for a while I lived on optimizing Java projects to meet with performance numbers even my junior Rust code can beat easily. Most Java devs have no idea how to write performant software.
Hopefully with Valhalla landing, memory footprint can also go down enough.
I've had the same experience - I spent 6 months last year really digging into Rust and came to the conclusion that for the software I'm writing it's trying to save me from problems that I just don't run into enough to make it worth it.I ended up jumping over to Zig and have been really enjoying it.  I ported the same hobby 2D game engine project from C++ to Rust, and then over to Zig.  A simple tile map loader and renderer took me about a week to implement in Rust and 3 hours in Zig.  The difference was a single memory bug that took 15 minutes to figure out.
the frustrating thing for me has been trying to "port over" C++-isms or Python-isms both fail from one direction or another.I've found that data structures with _lots of helper methods_ (thinking about things like `Result` in particular) tend to be nice. You do have to learn about Rust-specific things to figure out how to nicely structure your code for everything to work. But the payoff is less pain.There are still a lot of futzy ownership questions, and even when you write out your supposedly performant and cool system, easy outs like cloning end up hiding in your system leading to some awkward performance questions. Fortunately the systems are merely slow, and it tends to show up in profiling.
